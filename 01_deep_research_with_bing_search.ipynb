{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Projects, and the OpenAI Agents SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Azure OpenAI to work with OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents import (\n",
    "    set_default_openai_client,\n",
    "    set_tracing_disabled,\n",
    "    OpenAIChatCompletionsModel\n",
    ")\n",
    "\n",
    "# setup settings\n",
    "from openai import AsyncAzureOpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Use the synchronous client instead of the async one\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AOAI_KEY\"),\n",
    "    api_version=os.environ.get(\"AOAI_API_VERSION\", \"2024-02-01\")\n",
    ")\n",
    "\n",
    "# Configure SDK\n",
    "set_default_openai_client(openai_client)\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "reasoningModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"reasoningModel\"), \n",
    "    openai_client=openai_client\n",
    ")\n",
    "\n",
    "chatModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    openai_client=openai_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models for Research Workflow\n",
    "\n",
    "The following Pydantic models define the structured data used throughout our research process:\n",
    "\n",
    "1. **ResearchTask** - Represents an individual research task with specific search queries\n",
    "2. **ResearchPlan** - Contains the overall plan with research objectives and tasks\n",
    "3. **Citation** - Stores source information for proper attribution\n",
    "4. **ComprehensiveResearchReport** - Defines the structure of the final research output\n",
    "5. **PeerReviewFeedback** - Contains structured feedback on report quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResearchTask(BaseModel):\n",
    "    id: Optional[str] = Field(None, description=\"Unique identifier for the task\")\n",
    "    subtopic: str = Field(..., description=\"Subtopic to research\")\n",
    "    search_queries: List[str] = Field(..., description=\"List of search queries to explore this subtopic\")\n",
    "    completed: bool = Field(..., description=\"Status of task completion\")\n",
    "\n",
    "class ResearchPlan(BaseModel):\n",
    "    query: str = Field(..., description=\"The original user query that prompted this research\")\n",
    "    objective: str = Field(..., description=\"The overall research objective, clearly defined\")\n",
    "    success_criteria: List[str] = Field(..., description=\"Criteria to determine when the research is sufficiently complete.\")\n",
    "    related_topics: List[str] = Field(..., description=\"List of related topics that may be useful for the research.\")\n",
    "    research_tasks: List[ResearchTask] = Field(..., description=\"List of specific research tasks to complete. Each task focuses on a subtopic.\")\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "\n",
    "class ComprehensiveResearchReport(BaseModel):\n",
    "    objective: str = Field(..., description=\"The original research objective\")\n",
    "    research_report: str = Field(..., description=(\n",
    "        \"Comprehensive research report in markdown. \"\n",
    "        \"It should be structured with meaningful headings and subsections, but emphasize **fully-developed paragraphs**. \"\n",
    "        \"It should be long and detailed, and it should fully addresses the objectives, \"\n",
    "        \"and the various subtopics required to achieve the success criteria. \"\n",
    "        \"Use bullet points or lists **only** when they genuinely improve clarity (e.g., summarizing key data). \"\n",
    "        \"Tables and other data visualizations are encouraged. \"\n",
    "        \"The research report should always be long and detailed.\\n\\n\" \n",
    "        \"For citations, please use the IEEE (Institute of Electrical and Electronics Engineers). \"\n",
    "        \"How it works:\\n\\n\"\n",
    "        \"   1. In the text, use numbered citations in brackets [1].\\n\"\n",
    "        \"   2. At the end of the report, provide a list of citations in the format \"\n",
    "        \"(the list should ONLY contain the sources used in the free text of the research report. \"\n",
    "        \"Do NOT list sources which are not cited in the free text of the research report.):\\n\\n\"\n",
    "        \"       [1] Title of the source, URL.\"\n",
    "    ))\n",
    "    citations: List[Citation] = Field(..., description=(\n",
    "        \"List of citations (title and URL), corresponding to references actually used in research_report. \"\n",
    "        \"Do not add references that are not cited within the text.\"\n",
    "    ))\n",
    "    identified_gaps: Optional[List[str]] = Field(default=None, description=\"Identified information gaps.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Suggestions for additional research.\")\n",
    "\n",
    "class PeerReviewFeedback(BaseModel):\n",
    "    overall_feedback: str = Field(..., description=\"General feedback on the report.\")\n",
    "    strengths: List[str] = Field(..., description=\"Aspects of the report that are well done.\")\n",
    "    suggested_improvements: List[str] = Field(..., description=\"Specific suggestions to improve clarity, completeness, accuracy, or structure.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Additional research queries that could strengthen the report.\")\n",
    "    is_satisfactory: bool = Field(..., description=\"Indicates if the report meets all quality standards and no further revisions are needed.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "The research workflow is powered by two types of agents:\n",
    "\n",
    "1. **Azure AI Agents** - Created using Azure AI Projects for web search capabilities\n",
    "2. **OpenAI Agents** - For specialized research tasks\n",
    "\n",
    "Let's configure each type of agent with their specific instructions and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will ***create*** an **Azure AI Agent**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.ai.agents.models import BingGroundingTool\n",
    "\n",
    "# import datetime\n",
    "# current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# bing_connection = project_client.connections.get(\n",
    "#     name=os.getenv(\"BING_CONNECTION_NAME\")\n",
    "# )\n",
    "\n",
    "# bing_tool = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "# bing_search_agent = project_client.agents.create_agent(\n",
    "#     name=\"bingSearchAgent\",\n",
    "#     description=\"Agent to perform web searches using Bing.\",\n",
    "#     model=os.getenv(\"chatModel\"),\n",
    "#     temperature=0.5,\n",
    "#     tools=bing_tool.definitions,\n",
    "#     instructions=f\"\"\"\n",
    "# You are a helpful research assistant.\n",
    "\n",
    "# Today's date is {current_date}.\n",
    "\n",
    "# Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "# When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "# Provide a comprehensive answer based on the search results.\n",
    "#     \"\"\".strip()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have an Azure AI Agent, run this cell to update it's instructions with today's date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful research assistant.\n",
      "\n",
      "Today's date is 2025-06-05.\n",
      "\n",
      "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
      "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
      "Provide a comprehensive answer based on the search results.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "bing_search_agent.instructions = f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(bing_search_agent.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenAI Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    Agent,\n",
    "    ModelSettings\n",
    ")\n",
    "\n",
    "chatModelSettings=ModelSettings(\n",
    "        max_tokens=32768,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "    \n",
    "    You are an expert research planner specializing in creating detailed research plans your task is to analyze a user's research query and create a structured research plan.\n",
    "    with the following components:\n",
    "    \n",
    "    1. DOMAIN CLASSIFICATION:\n",
    "       Classify the query into a fitting domain (e.g., technology, business, etc.).\n",
    "       The Domain is not included in the output, but it is important for the other components in the research plan.\n",
    "       The domain should be a single word (e.g., technology, business, etc.).\n",
    "       \n",
    "    2. RESEARCH OBJECTIVE:\n",
    "       Create a clear, comprehensive objective statement for the research\n",
    "       \n",
    "    3. SUBTOPICS:\n",
    "       Generate relevant subtopics that should be explored to thoroughly answer the query (Important. generate no less than 5 subtopics)\n",
    "       \n",
    "    4. SEARCH QUERIES:\n",
    "       For each subtopic, provide search queries that will yield valuable results (Important. It's better to generate more queries than less queries, but at least 3 queries per subtopic)\n",
    "       \n",
    "    5. SUCCESS CRITERIA:\n",
    "       List the criteria that will determine when the research is complete (Important. generate no less than 4 success criteria)\n",
    "       Take all of the above into account (e.g., the domain, objective, subtopics, and search queries) to create the success criteria.\n",
    "       \n",
    "    6. RELATED TOPICS:\n",
    "       suggest related topics that may be useful for the research (Important. generate no less than 3 related topics)\n",
    "    \n",
    "    Ensure each subtopic is thorough and directly relevant to the research query.\n",
    "    The search queries should be specific enough to return high-quality results.\n",
    "    \"\"\".strip(),\n",
    "    model=chatModel,\n",
    "    output_type=ResearchPlan,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "summary_agent = Agent(\n",
    "    name=\"SummaryAgent\",\n",
    "    instructions=(\n",
    "        \"You are a comprehensive research summarization specialist. Your task is to **synthesize information from combined search result content** related to a specific subtopic (which will be mentioned in the input prompt). \"\n",
    "        \"Create a **single, coherent, detailed, and information-rich summary** that:\\n\\n\"\n",
    "        \"1. Extracts ALL important facts, statistics, findings, and insights **relevant to the specified subtopic** from the combined text.\\n\"\n",
    "        \"2. Preserves specific numbers, percentages, dates, and technical details whenever present.\\n\"\n",
    "        \"3. Includes industry-specific terminology and concepts that add depth to the research.\\n\"\n",
    "        \"4. **Synthesizes** the key arguments and conclusions from the provided sources. If sources present different perspectives or data, try to capture that nuance.\\n\"\n",
    "        \"5. Provides thorough explanations rather than superficial overviews, integrating information smoothly.\\n\"\n",
    "        \"6. For technical content, preserves methodologies, technical specifications, and implementation details.\\n\"\n",
    "        \"7. For comparative content, maintains all sides of the comparison with their specific attributes.\\n\\n\"\n",
    "\n",
    "        \"**Acknowledge that the input combines information potentially from multiple search results.** Your goal is to create a unified summary focused on the overall subtopic, not just list summaries of individual parts.\\n\\n\"\n",
    "\n",
    "        \"Remember that your summary serves as the foundation for generating a comprehensive research report. The quality and depth of the final research report depends directly on how comprehensive and well-synthesized your summary is. Ensure it captures the essence of all provided content relevant to the subtopic.\\n\\n\"\n",
    "\n",
    "        \"FORMAT YOUR SUMMARY AS:\\n\"\n",
    "        \"## Key Insights\\n\"\n",
    "        \"- [Most critical takeaway #1]\\n\"\n",
    "        \"- [Most critical takeaway #2]\\n\"\n",
    "        \"- [Most critical takeaway #3]\\n\"\n",
    "        \"- [Optional: Most critical takeaway #4]\\n\\n\"\n",
    "        \"## Extensive Synthesis\\n\"\n",
    "        \"Write a thorough, multi-paragraph synthesis that:\\n\"\n",
    "        \"- Integrates all important facts, statistics, findings, and insights relevant to the subtopic.\\n\"\n",
    "        \"- Preserves specific numbers, percentages, dates, and technical details.\\n\"\n",
    "        \"- Explains methodologies, technical specifications, and implementation details where relevant.\\n\"\n",
    "        \"- Highlights agreements, disagreements, and nuances between sources.\\n\"\n",
    "        \"- Uses industry-specific terminology and concepts.\\n\"\n",
    "        \"- Provides context, background, and implications for the findings.\\n\"\n",
    "        \"- Maintains logical flow: start with an overview, then go into specifics, and conclude with implications or open questions.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    output_type=str,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    instructions=(\n",
    "        \"## General Instructions\\n\"\n",
    "        \"You are a meticulous research analyst specializing in creating **long, comprehensive, authoritative** reports. \"\n",
    "        \"Your goal is to produce **in-depth, highly detailed** content that thoroughly analyzes all aspects of the research topic. \"\n",
    "        \"Furthermore, you must also demonstrate subject matter expertise with nuanced insights, technical details, and sophisticated analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Style & Format:\\n\"\n",
    "        \"- **Default to paragraphs.** Present your findings in cohesive, well-structured paragraphs rather than excessive bullet points.\\n\"\n",
    "        \"- **Use bullet points sparingly.** Only use them when they add genuine clarity—e.g., summarizing key data.\\n\"\n",
    "        \"- **Structure** the report with a clear hierarchy, but avoid excessive nesting. Aim for a balanced structure:\\n\"\n",
    "        \"   - Use main sections and occasional subsections where needed.\\n\"\n",
    "        \"   - Avoid over-fragmentation by limiting sub-subsections unless absolutely necessary.\\n\"\n",
    "        \"   - Favor broader thematic groupings to maintain narrative flow and reduce section clutter.\\n\"\n",
    "        \"   - With that said, if a subtopic would benefit from a sub-subsection, feel free to add it.\\n\"\n",
    "        \"- **Data visualizations** (e.g., tables, charts, diagrams) in Markdown are encouraged wherever they enhance understanding.\\n\"\n",
    "        \"- Maintain a logical, flowing structure so each subsection builds upon the prior sections.\\n\"\n",
    "        \"- **Citations:** Use IEEE style: [1], [2], etc. Provide a 'References' section at the end of your report with only the sources cited in the text.\\n\\n\"\n",
    "        \n",
    "        \"### Long & Comprehensive Requirement:\\n\"\n",
    "        \"- The final report must be the equivalent of **10 to 12 pages** of substantive text, approximately **7000-9000 words**.\\n\"\n",
    "        \"- Each major section should have **extensive exploration** (ideally 800-1000 words per section).\\n\"\n",
    "        \"- Ensure thorough coverage of the topic with **well-developed paragraphs**, plenty of detail, and rigorous analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Depth Requirements:\\n\"\n",
    "        \"- Include **quantitative data**, statistics, and specific examples to support your arguments.\\n\"\n",
    "        \"- Compare and contrast **multiple perspectives** on complex topics.\\n\"\n",
    "        \"- Integrate ideas across sections for a cohesive, synthesized analysis rather than isolated observations.\\n\\n\"\n",
    "        \n",
    "        \"### Workflow\\n\"\n",
    "        \"- When given the research objective and content, develop a **long-form narrative** with detailed explanations.\\n\"\n",
    "        \"- If PeerReviewAgent provides feedback, revise thoroughly, addressing all points.\\n\"\n",
    "        \"- Once feedback is marked satisfactory, present the final report.\\n\\n\"\n",
    "        \n",
    "        \"### Important Guidelines\\n\"\n",
    "        \"- Retain high-quality content in any revision.\\n\"\n",
    "        \"- If feedback highlights missing info, propose specific research queries.\\n\"\n",
    "        \"- Avoid unnecessary repetition.\\n\\n\"\n",
    "\n",
    "        \"**REMINDER**:\"\n",
    "        \"Your output should be a single, cohesive Markdown document that reads like a well-developed academic or professional paper, with minimal use of bullet points. \"\n",
    "        \"Prefer broader thematic sections over excessive fragmentation. \"\n",
    "        \"Sub-subsections may be used where helpful, but structure should remain balanced and readable. \"\n",
    "        \"Lastly, do not forget to include the references section at the end of the report.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=ComprehensiveResearchReport,\n",
    ")\n",
    "\n",
    "peer_review_agent = Agent(\n",
    "    name=\"PeerReviewAgent\",\n",
    "    instructions=(\n",
    "        \"You are a critical yet constructive peer reviewer evaluating research reports. \"\n",
    "        \"Your goal is to provide detailed, actionable feedback using a structured evaluation framework.\\n\\n\"\n",
    "        \n",
    "        \"## Evaluation Framework:\\n\"\n",
    "        \"1. COMPLETENESS (0-10): Does the report thoroughly cover all aspects of the research topic?\\n\"\n",
    "        \"   - Are all required subtopics adequately addressed?\\n\"\n",
    "        \"   - Is there sufficient depth in each section (500+ words per major section)?\\n\"\n",
    "        \"   - Are there any obvious gaps or missing perspectives?\\n\\n\"\n",
    "        \n",
    "        \"2. CLARITY & STRUCTURE (0-10): Is the report well-organized and clearly written?\\n\"\n",
    "        \"   - Does it have a logical flow with clear sections and subsections?\\n\"\n",
    "        \"   - Are complex concepts explained in accessible language?\\n\"\n",
    "        \"   - Does it use formatting effectively (headings, lists, tables)?\\n\\n\"\n",
    "        \n",
    "        \"3. EVIDENCE & SUPPORT (0-10): Is information well-supported?\\n\"\n",
    "        \"   - Are claims backed by data, statistics, or authoritative sources?\\n\"\n",
    "        \"   - Are citations used appropriately and consistently?\\n\"\n",
    "        \"   - Does it include multiple perspectives when appropriate?\\n\\n\"\n",
    "        \n",
    "        \"4. ANALYSIS & INSIGHT (0-10): Does the report provide valuable analysis?\\n\"\n",
    "        \"   - Does it go beyond summarizing to provide meaningful insights?\\n\"\n",
    "        \"   - Does it connect ideas across different sections?\\n\"\n",
    "        \"   - Does it identify implications and future directions?\\n\\n\"\n",
    "        \n",
    "        \"## Response Guidelines:\\n\"\n",
    "        \"- For each criterion, provide a score (0-10) and specific feedback citing examples from the report\\n\"\n",
    "        \"- In your overall assessment, calculate a total score (0-40)\\n\"\n",
    "        \"- Reports scoring 32+ (80%) can be marked as satisfactory\\n\"\n",
    "        \"- For reports below 32, provide clear, prioritized improvement suggestions\\n\"\n",
    "        \"- Be constructive and specific - point to exact sections that need improvement\\n\"\n",
    "        \n",
    "        \"\\n\\n## Important Rules:\"\n",
    "        \"\\n- If the report meets all quality standards (score ≥32), simply confirm this by changing the is_satisfactory field to true and hand it back to ResearchAgent.\"\n",
    "        \"\\n- Always perform a handoff to ResearchAgent for final report generation.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=PeerReviewFeedback,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hand-offs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent.handoffs = [peer_review_agent]\n",
    "peer_review_agent.handoffs = [research_agent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"183pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 182.68\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.790802 0.790802) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 1999.03,-227 1999.03,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1090.29,-8C1090.29,-8 1746.54,-8 1746.54,-8 1752.54,-8 1758.54,-14 1758.54,-20 1758.54,-20 1758.54,-203 1758.54,-203 1758.54,-209 1752.54,-215 1746.54,-215 1746.54,-215 1090.29,-215 1090.29,-215 1084.29,-215 1078.29,-209 1078.29,-203 1078.29,-203 1078.29,-20 1078.29,-20 1078.29,-14 1084.29,-8 1090.29,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"1418.42\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.86,-72.6C133.43,-72.24 159.62,-72.4 216.49,-73.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.32,-76.59 226.37,-73.22 216.41,-69.59 216.32,-76.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.46,-71.88C370.78,-71.43 396.13,-71.62 445.49,-72.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.18,-75.92 455.23,-72.59 445.29,-68.92 445.18,-75.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M926.04,-92.25C926.04,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 926.04,-55.75 926.04,-55.75 932.04,-55.75 938.04,-61.75 938.04,-67.75 938.04,-67.75 938.04,-80.25 938.04,-80.25 938.04,-86.25 932.04,-92.25 926.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;summary -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.28,-69C638.59,-68.14 669.02,-68.56 725.16,-70.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.73,-73.76 734.83,-70.57 724.94,-66.76 724.73,-73.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1188.54,-92.25C1188.54,-92.25 1098.29,-92.25 1098.29,-92.25 1092.29,-92.25 1086.29,-86.25 1086.29,-80.25 1086.29,-80.25 1086.29,-67.75 1086.29,-67.75 1086.29,-61.75 1092.29,-55.75 1098.29,-55.75 1098.29,-55.75 1188.54,-55.75 1188.54,-55.75 1194.54,-55.75 1200.54,-61.75 1200.54,-67.75 1200.54,-67.75 1200.54,-80.25 1200.54,-80.25 1200.54,-86.25 1194.54,-92.25 1188.54,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M881.86,-55.34C964.88,-21.4 990.44,-20.14 1081.1,-51.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.86,-54.82 1090.45,-54.83 1082.17,-48.22 1079.86,-54.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"1012.17\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1416.54,-52.25C1416.54,-52.25 1327.04,-52.25 1327.04,-52.25 1321.04,-52.25 1315.04,-46.25 1315.04,-40.25 1315.04,-40.25 1315.04,-27.75 1315.04,-27.75 1315.04,-21.75 1321.04,-15.75 1327.04,-15.75 1327.04,-15.75 1416.54,-15.75 1416.54,-15.75 1422.54,-15.75 1428.54,-21.75 1428.54,-27.75 1428.54,-27.75 1428.54,-40.25 1428.54,-40.25 1428.54,-46.25 1422.54,-52.25 1416.54,-52.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1200.81,-63.21C1253.32,-53.35 1281.27,-48.19 1303.85,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1304.14,-47.88 1313.43,-42.79 1302.99,-40.97 1304.14,-47.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"1257.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1650.69,-105.94C1650.69,-105.94 1584.14,-78.56 1584.14,-78.56 1578.59,-76.28 1578.59,-71.72 1584.14,-69.44 1584.14,-69.44 1650.69,-42.06 1650.69,-42.06 1656.24,-39.78 1667.34,-39.78 1672.89,-42.06 1672.89,-42.06 1739.44,-69.44 1739.44,-69.44 1744.99,-71.72 1744.99,-76.28 1739.44,-78.56 1739.44,-78.56 1672.89,-105.94 1672.89,-105.94 1667.34,-108.22 1656.24,-108.22 1650.69,-105.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1211.83,-72.2C1443.6,-66.13 1499.16,-65.21 1583.06,-69.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1212.08,-68.69 1202.17,-72.45 1212.26,-75.69 1212.08,-68.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.68,-37.82C1526.04,-44.45 1562.55,-47.76 1598.61,-56.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.31,-59.39 1607.86,-58.37 1598.98,-52.59 1597.31,-59.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"1500.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"1925.91\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1748.73,-72.86C1794.97,-72.28 1822.55,-72.05 1845.08,-72.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1844.92,-75.66 1854.95,-72.24 1844.98,-68.66 1844.92,-75.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"1803.67\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1f948f84af0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "plan = await Runner().run(\n",
    "    starting_agent=planner_agent,\n",
    "    input=user_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is classical machine learning?',\n",
       " 'What is deep learning?',\n",
       " 'What is generative AI?',\n",
       " 'Core concepts of classical machine learning, deep learning, and generative AI']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.final_output.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Subtopics: 100%|██████████| 5/5 [03:06<00:00, 37.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.final_output.research_tasks, desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            message = project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=formatted_query,\n",
    "            )\n",
    "\n",
    "            # Process the run\n",
    "            run = project_client.agents.runs.create_and_process(\n",
    "                thread_id=thread.id,\n",
    "                agent_id=bing_search_agent.id\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 20\n",
      "\n",
      "Actually total search queries: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.final_output.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 5/5 [00:58<00:00, 11.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    all_agent_responses_for_subtopic, unique_citations_for_subtopic = collect_responses_and_citations(subtopic_result)\n",
    "\n",
    "    # --- Summarize the combined agent responses ONCE per subtopic ---\n",
    "    content_to_summarize = \"\\n\\n---\\n\\n\".join(all_agent_responses_for_subtopic)\n",
    "\n",
    "    subtopic_summary = \"No content found to summarize for this subtopic.\" # Default value\n",
    "    if content_to_summarize:\n",
    "        summary_prompt = f\"Summarize the following information related to the subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content_to_summarize}\"\n",
    "        try:\n",
    "            summary_response = await Runner().run(\n",
    "                starting_agent=summary_agent,\n",
    "                input=summary_prompt\n",
    "            )\n",
    "            subtopic_summary = summary_response.final_output # Adjust based on actual response structure\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}': {e}\")\n",
    "            subtopic_summary = f\"Error during summarization for subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}'. Details: {e}\"\n",
    "            # Depending on requirements, you might want to raise the exception, log it, or handle it differently\n",
    "\n",
    "    # --- Convert set of tuples back to list of dictionaries (or Citation objects) ---\n",
    "    citations_list = [\n",
    "        {\"title\": title, \"url\": url}\n",
    "        for title, url in unique_citations_for_subtopic\n",
    "    ]\n",
    "\n",
    "    # --- Append the consolidated result ---\n",
    "    mapped_chunks.append({\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"), # Use .get for safety\n",
    "        \"summary\": subtopic_summary,\n",
    "        \"citations\": citations_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResearchPlan(query='What are the differences between classical machine learning, deep learning and generative AI?', objective='To comprehensively analyze and articulate the key differences, overlaps, and unique characteristics of classical machine learning, deep learning, and generative AI, including their definitions, methodologies, applications, strengths, and limitations.', success_criteria=['Clear definitions and explanations of classical machine learning, deep learning, and generative AI are provided.', 'Key differences and similarities between the three approaches are identified and explained.', 'Examples of real-world applications for each approach are included.', 'Strengths and limitations of each approach are discussed.', 'A comparative summary or table is created to visually distinguish the three approaches.'], related_topics=['Supervised vs. unsupervised learning', 'Neural networks and their architectures', 'AI ethics and responsible AI development'], research_tasks=[ResearchTask(id=None, subtopic='Definitions and Core Concepts', search_queries=['What is classical machine learning?', 'What is deep learning?', 'What is generative AI?', 'Core concepts of classical machine learning, deep learning, and generative AI'], completed=False), ResearchTask(id=None, subtopic='Methodologies and Algorithms', search_queries=['Common algorithms in classical machine learning', 'Deep learning architectures and methods', 'Generative AI models and techniques', 'Comparison of machine learning and deep learning algorithms'], completed=False), ResearchTask(id=None, subtopic='Applications and Use Cases', search_queries=['Applications of classical machine learning', 'Deep learning use cases in industry', 'Generative AI real-world applications', 'Case studies comparing classical ML, deep learning, and generative AI'], completed=False), ResearchTask(id=None, subtopic='Strengths and Limitations', search_queries=['Advantages and disadvantages of classical machine learning', 'Strengths and weaknesses of deep learning', 'Limitations of generative AI', 'Challenges in implementing each AI approach'], completed=False), ResearchTask(id=None, subtopic='Comparative Analysis and Summary', search_queries=['Comparison between classical machine learning and deep learning', 'How does generative AI differ from deep learning?', 'Table comparing classical ML, deep learning, and generative AI', 'Visual summary of AI approaches'], completed=False)])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan.final_output, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "final_answer = await Runner().run(\n",
    "    starting_agent=research_agent,\n",
    "    input=(\n",
    "        \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "        \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "        \"a cohesive, academic-style paper:\\n\\n\"\n",
    "        f\"{research_input_prompt}\\n\\n\"\n",
    "        \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    "    ),\n",
    "    max_turns=21 # 5 turns are needed for a full collaboration between ResearchAgent and PeerReviewAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Final Research Report\n",
    "\n",
    "After the ResearchAgent and PeerReviewAgent complete their collaborative process, we extract the final research report from the agent outputs. The report includes:\n",
    "\n",
    "1. A clearly defined research objective\n",
    "2. Multiple sections covering all identified subtopics\n",
    "3. In-depth analysis with facts, statistics, and insights\n",
    "4. Proper citations using IEEE format\n",
    "5. A comprehensive references section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import HandoffCallItem\n",
    "import json\n",
    "\n",
    "def extract_research_report(final_answer):\n",
    "    # If final output is from ResearchAgent, get the report directly\n",
    "    if hasattr(final_answer.final_output, \"research_report\"):\n",
    "        return final_answer.final_output.research_report\n",
    "    \n",
    "    # If final output is from PeerReviewAgent, find the latest research report from ResearchAgent\n",
    "    for item in reversed(final_answer.new_items):  # Start from end to get the latest\n",
    "        if isinstance(item, HandoffCallItem) and item.agent.name == \"ResearchAgent\":\n",
    "            try:\n",
    "                args = json.loads(item.raw_item.arguments)\n",
    "                if \"research_report\" in args:\n",
    "                    return args[\"research_report\"]\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                continue\n",
    "    \n",
    "    # If we couldn't find a report\n",
    "    raise ValueError(\"No research report found in the conversation history\")\n",
    "\n",
    "research_report = extract_research_report(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Report Presentation\n",
    "\n",
    "The completed research report is displayed below in Markdown format. The report represents a comprehensive analysis of the original query, incorporating insights from multiple web sources and structured in an academic format with proper citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# A Comprehensive Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Definitions, Methodologies, Applications, Strengths, and Comparative Perspectives\n",
       "\n",
       "## Introduction\n",
       "\n",
       "The rapid evolution of artificial intelligence (AI) over recent decades has produced a rich tapestry of methodologies, each tailored to specific data types, problem domains, and operational constraints. Among the most prominent paradigms are classical machine learning, deep learning, and generative AI. These approaches, while sharing foundational principles rooted in data-driven learning, diverge significantly in their technical underpinnings, application domains, and transformative potential. This report provides an in-depth, integrated analysis of these three paradigms, exploring their core concepts, methodologies, real-world applications, strengths, and limitations. By synthesizing insights from academic literature, industry case studies, and comparative analyses, the report aims to clarify the nuanced distinctions and overlaps among these approaches, offering a comprehensive reference for practitioners, researchers, and decision-makers.\n",
       "\n",
       "## 1. Definitions and Core Concepts\n",
       "\n",
       "### 1.1 Classical Machine Learning\n",
       "\n",
       "Classical machine learning (ML) refers to a suite of foundational algorithms and statistical models designed to uncover patterns and relationships within structured datasets. These methods are grounded in mathematical rigor and are typically divided into supervised and unsupervised learning. Supervised learning involves training models on labeled input-output pairs, with algorithms such as linear regression, logistic regression, decision trees, and support vector machines (SVMs) being prominent examples. Unsupervised learning, by contrast, seeks to identify structure in unlabeled data through clustering (e.g., k-means) and dimensionality reduction (e.g., principal component analysis, PCA) techniques. A defining characteristic of classical ML is its reliance on manual feature engineering, wherein domain experts select and transform variables to optimize model performance. This approach emphasizes interpretability, efficiency, and robust evaluation using metrics like accuracy, precision, recall, and cross-validation. Classical ML is particularly well-suited for structured data and scenarios where transparency and lower data requirements are critical [1][2][3][4][5].\n",
       "\n",
       "### 1.2 Deep Learning\n",
       "\n",
       "Deep learning represents a paradigm shift within AI, leveraging multi-layered artificial neural networks to automatically learn hierarchical representations from raw, often unstructured data. The term \"deep\" refers to the presence of multiple processing layers, each extracting increasingly abstract features from the input. Deep learning excels in domains such as image and speech recognition, natural language processing, and complex pattern recognition. Key architectures include convolutional neural networks (CNNs) for spatial data, recurrent neural networks (RNNs) for sequential data, and transformers for tasks requiring attention mechanisms. The core mechanism enabling deep learning is backpropagation, which iteratively adjusts network weights based on error gradients. Unlike classical ML, deep learning minimizes the need for manual feature engineering, instead discovering salient features autonomously. This capability has led to breakthroughs in fields previously inaccessible to traditional algorithms [1][2][3][4][5].\n",
       "\n",
       "### 1.3 Generative AI\n",
       "\n",
       "Generative AI is a specialized class of models designed to create novel content—such as text, images, music, and code—by learning the underlying distributions of training data. Unlike traditional predictive models, which focus on classification or regression, generative AI emphasizes the synthesis of new, original data. The core technologies driving generative AI include generative adversarial networks (GANs), variational autoencoders (VAEs), diffusion models, and large language models (LLMs) such as GPT. These models employ advanced training techniques, including adversarial learning and latent variable modeling, to produce outputs that are increasingly indistinguishable from human-generated content. Generative AI also introduces the concept of prompt engineering, wherein carefully crafted inputs guide models to produce desired outputs, a technique especially relevant for LLMs. The rise of generative AI is transforming creative and productive domains, enabling new forms of automation and augmentation [1][4].\n",
       "\n",
       "### 1.4 Interplay and Evolution\n",
       "\n",
       "The evolution from classical ML to deep learning and generative AI reflects a trajectory of increasing model complexity, data requirements, and creative potential. While classical ML remains indispensable for structured, interpretable tasks, deep learning has unlocked new frontiers in perception and understanding of complex data. Generative AI, in turn, is revolutionizing creative industries by automating and augmenting content creation. The interplay among these paradigms continues to shape the trajectory of AI research and deployment, with hybrid systems increasingly leveraging the strengths of each approach.\n",
       "\n",
       "## 2. Methodologies and Algorithms\n",
       "\n",
       "### 2.1 Classical Machine Learning Algorithms\n",
       "\n",
       "The methodological foundation of classical machine learning lies in a diverse array of algorithms, each tailored to specific data types and problem complexities. Linear regression and logistic regression are among the most fundamental, providing transparent models for continuous and binary outcomes, respectively. Decision trees and random forests offer interpretable, tree-based structures for both classification and regression, with random forests enhancing robustness through ensemble learning. Support vector machines (SVMs) excel in high-dimensional spaces, optimizing the separation between classes. K-nearest neighbors (KNN) adopts a non-parametric approach, relying on the proximity of data points, while naive Bayes leverages probabilistic reasoning for tasks such as text classification. Unsupervised algorithms like k-means clustering and PCA facilitate data exploration and dimensionality reduction, respectively. Gradient boosting machines, including XGBoost and AdaBoost, sequentially improve predictions by correcting previous errors, achieving high accuracy in structured data tasks. These algorithms are typically implemented using open-source libraries and are favored for their interpretability, efficiency, and effectiveness with smaller datasets [6][7][8][9].\n",
       "\n",
       "### 2.2 Deep Learning Architectures and Techniques\n",
       "\n",
       "Deep learning methodologies are characterized by their use of artificial neural networks with multiple layers, enabling the automatic extraction of hierarchical features from raw data. Feedforward neural networks (FNNs) serve as the basic building blocks, while convolutional neural networks (CNNs) are specialized for grid-like data such as images, extracting spatial features through convolutional layers. Recurrent neural networks (RNNs), and their advanced variants like long short-term memory (LSTM) and gated recurrent units (GRU), are tailored for sequential data, maintaining memory of previous inputs for tasks such as language modeling and time series analysis. Transformers, leveraging self-attention mechanisms, have revolutionized natural language processing by enabling parallel processing of sequences and capturing long-range dependencies, as exemplified by models like BERT and GPT.\n",
       "\n",
       "Training deep neural networks relies on the backpropagation algorithm, which computes gradients of loss functions with respect to model parameters and updates them using optimization techniques such as stochastic gradient descent (SGD). Regularization methods—including dropout, batch normalization, and weight decay—are essential for preventing overfitting and improving generalization. Transfer learning, wherein pre-trained models are fine-tuned on new tasks, and hyperparameter optimization strategies further enhance deep learning performance and adaptability. The scalability and flexibility of deep learning architectures have made them indispensable for tasks involving unstructured, high-dimensional data [6][7][8][9].\n",
       "\n",
       "### 2.3 Generative AI Methodologies\n",
       "\n",
       "Generative AI introduces specialized algorithms designed to create new, realistic data. Generative adversarial networks (GANs) pit a generator against a discriminator in a competitive training process, producing highly realistic outputs. Variational autoencoders (VAEs) introduce probabilistic latent variables, enabling the generation of new, similar data samples. Diffusion models, such as denoising diffusion probabilistic models (DDPMs), iteratively refine noise into structured outputs, achieving state-of-the-art results in image generation. Transformer-based generative models, notably GPT for text and DALL-E for images, employ attention mechanisms to generate coherent and contextually relevant outputs. Autoregressive models (e.g., PixelRNN, WaveNet) generate data sequentially, conditioning each new element on previous outputs, while flow-based models (e.g., RealNVP, Glow) learn invertible mappings for efficient sampling and exact likelihood estimation.\n",
       "\n",
       "The training of generative models often involves unsupervised or self-supervised learning paradigms, with loss functions tailored to the specific architecture: adversarial loss for GANs, reconstruction loss for autoencoders, and likelihood-based losses for VAEs and flow models. Advanced techniques such as attention mechanisms, latent variable modeling, and iterative refinement are central to recent breakthroughs, enabling the synthesis of high-quality, diverse, and realistic data. These methodological advances have positioned generative AI at the forefront of artificial creativity and automation [6][7][8][9].\n",
       "\n",
       "### 2.4 Methodological Distinctions and Overlaps\n",
       "\n",
       "While classical ML, deep learning, and generative AI each employ distinct methodologies, there is considerable overlap in foundational principles. All three rely on data-driven learning, optimization of objective functions, and iterative refinement of model parameters. The primary distinctions lie in data requirements, feature engineering, interpretability, computational demands, and the range of applicable tasks. Classical ML emphasizes manual feature engineering and interpretability, deep learning automates feature extraction and excels with unstructured data, and generative AI extends deep learning architectures to content creation and synthesis. The choice of methodology is dictated by the nature of the data, the complexity of the task, and resource availability.\n",
       "\n",
       "## 3. Applications and Use Cases\n",
       "\n",
       "### 3.1 Classical Machine Learning Applications\n",
       "\n",
       "Classical machine learning remains foundational for structured data tasks across a range of industries. In healthcare, classical ML algorithms are used for disease diagnosis and prognosis, such as predicting diabetes or cancer risk, and for clustering patient data to tailor personalized treatment plans. The finance sector leverages logistic regression and decision trees for credit scoring, fraud detection, stock market prediction, and portfolio optimization. Marketing and retail benefit from clustering methods for customer segmentation, churn prediction, and recommendation systems. In manufacturing, regression and classification models enable predictive maintenance and defect detection, enhancing operational efficiency. Classical ML also underpins natural language processing (NLP) tasks such as spam detection and sentiment analysis, as well as document clustering and topic modeling. In image processing, these algorithms support object recognition and pattern detection, particularly in medical imaging. These approaches are favored for their interpretability, computational efficiency, and effectiveness with smaller datasets, and are often the starting point before transitioning to more complex deep learning models, especially in regulated or resource-constrained environments [10][11][12][13][14][15][16][17][18][19][20][21].\n",
       "\n",
       "### 3.2 Deep Learning Applications\n",
       "\n",
       "Deep learning has transformed industries by enabling advanced analysis of unstructured data—images, audio, and text—where classical ML often falls short. In healthcare, deep learning models analyze X-rays, MRIs, and CT scans to detect diseases such as cancer and neurological disorders with higher accuracy than classical ML. They also accelerate drug discovery by predicting molecular interactions and enable personalized medicine through comprehensive patient data analysis. In finance, deep learning powers real-time fraud detection, algorithmic trading, and nuanced risk assessment by modeling complex, high-dimensional data. Retailers utilize deep learning for personalized recommendation systems, predictive inventory management, and customer sentiment analysis from social media and reviews. Manufacturing applications include predictive maintenance using sensor data and automated visual inspection systems for quality control. Agriculture benefits from deep learning in crop monitoring and yield prediction, optimizing resource allocation and improving outcomes. The transportation and automotive sectors leverage deep learning for autonomous vehicles—processing sensor and camera data for navigation and obstacle avoidance—and for traffic prediction and route optimization. Security applications include facial recognition for surveillance and authentication, as well as anomaly detection in cybersecurity. Deep learning’s ability to model complex, nonlinear relationships and extract features from raw data has made it indispensable for tasks requiring high accuracy and automation, albeit often at the cost of interpretability and higher computational demands [10][11][12][13][14][15][16][17][18][19][20][21].\n",
       "\n",
       "### 3.3 Generative AI Applications\n",
       "\n",
       "Generative AI is rapidly expanding into creative, conversational, and automation-driven applications. In search and information retrieval, companies such as Google integrate generative AI to produce AI-generated overviews and summaries, increasing user engagement and the relevance of search results. Conversational agents and virtual assistants, powered by generative AI, handle complex queries, maintain contextual conversations, and automate customer service and scheduling. Content creation is a major domain, with AI tools generating text, images, music, and videos for applications ranging from automated news writing and marketing copy to graphic design and video game development. In healthcare, generative AI creates synthetic medical data and images for training, augments datasets, and assists in diagnostics and personalized treatment planning. Education benefits from AI-driven tutoring systems and content generators that personalize learning materials and simulate exam questions. Generative AI also transforms software development, with tools like GitHub Copilot suggesting code snippets, automating repetitive tasks, and generating entire functions from natural language descriptions. In product design and prototyping, generative design tools produce optimized prototypes by exploring multiple design variations based on specified constraints. Legal and financial services utilize generative AI for drafting documents, summarizing contracts, and generating reports, streamlining operations and reducing manual workload [10][11][12][13][14][15][16][17][18][19][20][21].\n",
       "\n",
       "### 3.4 Comparative Case Studies and Industry Nuances\n",
       "\n",
       "Comparative analyses highlight that classical ML is optimal for structured, well-defined problems, deep learning excels with unstructured and complex data, and generative AI is pioneering new frontiers in content generation and user interaction. For example, in healthcare diagnostics, classical ML predicts patient outcomes from structured records, deep learning analyzes medical images for disease detection, and generative AI generates synthetic images for training and drafts clinical reports. In marketing, classical ML segments customers, deep learning personalizes recommendations, and generative AI creates tailored ad content, enhancing engagement and conversion rates. In search, classical ML ranks results, deep learning enables semantic search and intent understanding, and generative AI delivers direct answers and content generation, as seen in advanced platforms like Azure AI Search. The synergy between these approaches is increasingly evident, with hybrid systems leveraging the interpretability of classical ML, the representational power of deep learning, and the creativity of generative AI.\n",
       "\n",
       "### 3.5 Impact Assessment Matrix Across Industries\n",
       "\n",
       "The following table summarizes the impact of each AI paradigm across key industries:\n",
       "\n",
       "| Industry        | Classical ML         | Deep Learning           | Generative AI                  |\n",
       "|-----------------|---------------------|-------------------------|-------------------------------|\n",
       "| Healthcare      | Risk prediction, diagnosis | Medical imaging, drug discovery | Synthetic data, report drafting |\n",
       "| Finance         | Credit scoring, fraud detection | Algorithmic trading, risk modeling | Automated reporting, document generation |\n",
       "| Retail/Marketing| Customer segmentation, churn | Personalization, sentiment analysis | Ad content, product descriptions |\n",
       "| Manufacturing   | Predictive maintenance, defect detection | Visual inspection, process optimization | Design prototyping, synthetic data |\n",
       "| Education       | Student performance prediction | Adaptive learning, grading | Content generation, tutoring systems |\n",
       "| Transportation  | Route optimization, demand prediction | Autonomous vehicles, traffic analysis | Simulation, scenario generation |\n",
       "\n",
       "## 4. Strengths and Limitations\n",
       "\n",
       "### 4.1 Classical Machine Learning\n",
       "\n",
       "Classical ML algorithms are celebrated for their interpretability, efficiency, and strong performance on structured data with smaller datasets. Decision trees and linear regression, for instance, provide transparent, easily understood decision-making processes, enabling practitioners to trace and justify predictions. These models are computationally lightweight, requiring less memory and processing power compared to deep learning, making them ideal for deployment on smaller datasets or less powerful hardware. Training times are typically short, and classical ML often achieves strong results on structured/tabular data where relationships are relatively straightforward. Another significant advantage is their lower data requirement; classical ML can perform well even with limited data, whereas deep learning models generally necessitate vast datasets to avoid overfitting and achieve high accuracy. However, these strengths are counterbalanced by notable limitations. Classical ML models struggle with unstructured data types such as images, audio, or free-form text, where the relationships are complex and high-dimensional. Their predictive power is often capped by their limited expressiveness, meaning they may fail to capture intricate patterns present in the data. Furthermore, classical ML typically requires extensive manual feature engineering—crafting input variables based on domain expertise—to extract meaningful signals from the data, a process that is both time-consuming and reliant on human intuition. Scalability can also be an issue; algorithms like k-nearest neighbors become computationally expensive as dataset size grows. As a result, in many modern applications, classical ML models reach a performance plateau, after which only more sophisticated techniques, such as deep learning, can provide further improvements [22][23][24][25][26][27][28][29][30][31][32].\n",
       "\n",
       "### 4.2 Deep Learning\n",
       "\n",
       "Deep learning, characterized by multi-layered neural networks such as CNNs and large language models (LLMs), has revolutionized AI by achieving state-of-the-art results in domains like image recognition, speech processing, and natural language understanding. These models excel at learning complex, hierarchical representations directly from raw data, eliminating the need for manual feature engineering. Their scalability allows them to leverage massive datasets, often improving performance as more data becomes available. End-to-end learning enables deep learning systems to map inputs to outputs in a flexible, task-agnostic manner, and with proper regularization, these models can generalize well to unseen data. Despite these strengths, deep learning comes with substantial limitations. Training deep neural networks requires enormous labeled datasets and significant computational resources, such as GPUs or TPUs, which can be prohibitive for smaller organizations or niche applications. The \"black box\" nature of deep learning architectures poses challenges for interpretability and transparency, making it difficult to understand or trust their decision-making processes. Deep learning models are also susceptible to adversarial attacks—small, often imperceptible perturbations in input data can result in dramatically incorrect outputs. Overfitting is a persistent risk, especially when data is insufficient or regularization is inadequate. Furthermore, deep learning systems can inadvertently learn and amplify biases present in training data, raising concerns about fairness and ethical deployment. They also struggle with causal reasoning, excelling at pattern recognition but failing to infer underlying mechanisms or cause-effect relationships [22][23][24][25][26][27][28][29][30][31][32].\n",
       "\n",
       "### 4.3 Generative AI\n",
       "\n",
       "Generative AI, particularly large language models and image generators, has demonstrated remarkable capabilities in content creation and automation. These models can produce coherent text, realistic images, and other media by learning patterns from vast corpora of training data. However, their limitations are significant. Generative AI often lacks deep understanding or reasoning abilities, excelling only at well-defined, narrow tasks and struggling with complex, multi-dimensional societal issues. The quality and representativeness of training data are critical; biased or incomplete data leads to skewed, inappropriate, or even harmful outputs. A major concern is \"hallucination,\" where models generate plausible-sounding but factually incorrect or fabricated information, undermining reliability in high-stakes applications. Generative models also have limited contextual awareness and memory, which can result in inconsistent or irrelevant outputs in extended interactions. Ethical and security risks are pronounced: generative AI can be misused for misinformation, deepfakes, and malicious content, and raises issues around privacy, copyright, and the amplification of harmful stereotypes. When faced with ambiguity or incomplete information, these models often default to generic or vague responses, highlighting their limitations in nuanced reasoning and decision-making [22][23][24][25][26][27][28][29][30][31][32].\n",
       "\n",
       "### 4.4 Symbolic AI and Hybrid Approaches\n",
       "\n",
       "Symbolic AI, or rule-based systems, are highly interpretable and transparent, making them effective in domains with clear, well-defined rules. Their reasoning processes can be easily traced and audited, which is valuable in regulated or safety-critical environments. However, symbolic AI faces scalability challenges; encoding exhaustive rules for complex, real-world problems is labor-intensive and often infeasible. These systems are inflexible, struggling with ambiguity, exceptions, and evolving knowledge, as rules must be manually updated. Knowledge acquisition requires significant expert input, further limiting their adaptability and scalability. Hybrid approaches seek to combine the reasoning capabilities of symbolic AI with the pattern recognition strengths of machine learning and deep learning, aiming to improve robustness and explainability in complex applications. However, integrating these paradigms remains an active area of research due to the inherent complexity of blending symbolic reasoning with data-driven learning [22][23][24][25][26][27][28][29][30][31][32].\n",
       "\n",
       "### 4.5 Cross-Cutting AI Implementation Challenges\n",
       "\n",
       "Across all AI paradigms, common implementation challenges include ensuring data privacy and security, navigating regulatory and ethical considerations, integrating AI with existing systems, and addressing the need for skilled personnel. Addressing these challenges often requires both technical solutions—such as explainable AI methods and improved data quality—and organizational strategies, including robust governance frameworks and ongoing staff training. The choice of AI approach depends heavily on the specific task, data characteristics, and operational constraints. Understanding these strengths and limitations is essential for effective, responsible, and context-appropriate AI deployment, and ongoing research continues to address many of these challenges, particularly around interpretability, fairness, and scalability.\n",
       "\n",
       "## 5. Comparative Analysis and Summary\n",
       "\n",
       "### 5.1 Comparative Table\n",
       "\n",
       "A comparative analysis of classical machine learning, deep learning, and generative AI reveals a spectrum of approaches within artificial intelligence, each tailored to specific types of data, computational environments, and problem domains. The following table summarizes the key differences and overlaps:\n",
       "\n",
       "| Aspect                | Classical ML      | Deep Learning           | Generative AI                        |\n",
       "|-----------------------|------------------|------------------------|--------------------------------------|\n",
       "| Data Requirements     | Small/Medium     | Large                  | Massive, often self-supervised       |\n",
       "| Feature Engineering   | Manual           | Automatic              | Automatic, complex representations   |\n",
       "| Model Complexity      | Simple           | Complex (deep networks)| Very complex (LLMs, GANs, diffusion) |\n",
       "| Interpretability      | High             | Low                    | Lowest                              |\n",
       "| Computational Power   | Low/Moderate     | High                   | Very high                           |\n",
       "| Output                | Predictions      | Predictions, patterns  | Novel content (text, images, etc.)   |\n",
       "| Use Cases             | Tabular data     | Vision, audio, NLP     | Content generation, creative tools   |\n",
       "\n",
       "### 5.2 Hierarchical Breakdown of AI Paradigms\n",
       "\n",
       "A hierarchical view of AI paradigms further clarifies their relationships:\n",
       "\n",
       "- **Artificial Intelligence**\n",
       "  - **Symbolic AI (Rule-Based Systems)**\n",
       "  - **Machine Learning**\n",
       "    - **Classical Machine Learning**\n",
       "    - **Deep Learning**\n",
       "      - **Generative AI**\n",
       "\n",
       "### 5.3 Timeline of Major Developments\n",
       "\n",
       "| Year/Period | Major Development                                 |\n",
       "|-------------|---------------------------------------------------|\n",
       "| 1950s-1980s | Symbolic AI, expert systems                       |\n",
       "| 1990s       | Classical ML algorithms (SVM, decision trees, etc.)|\n",
       "| 2006        | Deep learning resurgence (Hinton et al.)          |\n",
       "| 2012        | CNN breakthrough (ImageNet competition)           |\n",
       "| 2014        | GANs introduced                                   |\n",
       "| 2017        | Transformers (Vaswani et al.)                     |\n",
       "| 2018-2020s  | LLMs (GPT, BERT), diffusion models, generative AI |\n",
       "\n",
       "### 5.4 Synthesis and Future Directions\n",
       "\n",
       "The choice between classical ML, deep learning, and generative AI depends on the nature of the data, the complexity of the task, the need for interpretability, and available computational resources. Classical ML remains relevant for structured, interpretable tasks with limited data, while deep learning and generative AI dominate domains involving unstructured data and creative content generation, albeit with greater resource demands and challenges in model transparency. Symbolic and hybrid approaches continue to play important roles in domains where explainability and logical reasoning are critical, pointing toward a future where integrated AI systems leverage the strengths of multiple paradigms. As generative AI matures, its role in automating complex tasks, enhancing creativity, and improving decision-making will expand, while classical and deep learning methods will remain essential for foundational tasks and as components within larger AI systems. The ongoing convergence of these paradigms, coupled with advances in explainability, fairness, and scalability, will shape the next generation of AI solutions.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] Why Is Deep Learning Actually Called “Deep”? - aievo.co.uk, https://aievo.co.uk/why-is-deep-learning-actually-called-deep/\n",
       "\n",
       "[2] Classic and Adaptive machines - GeeksforGeeks, https://www.geeksforgeeks.org/classic-and-adaptive-machines/\n",
       "\n",
       "[3] Classic Machine Learning Methods - SpringerLink, https://link.springer.com/protocol/10.1007/978-1-0716-3195-9_2\n",
       "\n",
       "[4] AI Mode in Google Search: Updates from Google I/O 2025 - The Keyword, https://blog.google/products/search/google-search-ai-mode-update/\n",
       "\n",
       "[5] Classical Machine Learning Models | ageron/handson-ml3 | DeepWiki, https://deepwiki.com/ageron/handson-ml3/4-classical-machine-learning-models\n",
       "\n",
       "[6] Deep Learning vs. Machine Learning: Everything You Need to Know, https://pg-p.ctme.caltech.edu/blog/ai-ml/deep-learning-vs-machine-learning\n",
       "\n",
       "[7] Deep Learning (DL) vs Machine Learning (ML): A Comparative Guide, https://www.datacamp.com/tutorial/machine-deep-learning\n",
       "\n",
       "[8] Machine Learning and Deep Learning: A Comparative Review, https://link.springer.com/chapter/10.1007/978-981-33-6307-6_15\n",
       "\n",
       "[9] Difference Between Machine Learning and Deep Learning, https://www.geeksforgeeks.org/difference-between-machine-learning-and-deep-learning/\n",
       "\n",
       "[10] Introducing AI Max for Search campaigns - The Keyword, https://blog.google/products/ads-commerce/google-ai-max-for-search-campaigns/\n",
       "\n",
       "[11] Up to 40% better relevance for complex queries with new agentic ..., https://techcommunity.microsoft.com/blog/azure-ai-services-blog/up-to-40-better-relevance-for-complex-queries-with-new-agentic-retrieval-engine/4413832\n",
       "\n",
       "[12] 20 Deep Learning Applications in 2024 Across Industries, https://www.pickl.ai/blog/deep-learning-applications/\n",
       "\n",
       "[13] Classic machine learning methods - arXiv.org, https://arxiv.org/pdf/2310.11470\n",
       "\n",
       "[14] Agentic Retrieval - Azure AI Search | Microsoft Learn, https://learn.microsoft.com/en-us/azure/search/search-agentic-retrieval-concept\n",
       "\n",
       "[15] Top 20 Applications of Deep Learning in 2025 Across Industries, https://www.mygreatlearning.com/blog/deep-learning-applications/\n",
       "\n",
       "[16] A Guided Tour Through Classical Machine Learning Algorithms, https://learn.mathnai.com/module/ml/guided-tour-classical-ml-algorithms/\n",
       "\n",
       "[17] Top 50 Deep Learning Use Case & Case Studies in 2025 - AIMultiple, https://research.aimultiple.com/deep-learning-applications/\n",
       "\n",
       "[18] AI Mode in Google Search: Updates from Google I/O 2025 - The Keyword, https://blog.google/products/search/google-search-ai-mode-update/\n",
       "\n",
       "[19] Deep Learning Use Cases – A Roadmap to Digital Transformation, https://www.matellio.com/blog/deep-learning-business-use-cases/\n",
       "\n",
       "[20] Machine Learning Theory and Applications: Hands-on Use Cases with ..., https://ieeexplore.ieee.org/book/10444091\n",
       "\n",
       "[21] Classic machine learning methods - arXiv.org, https://arxiv.org/pdf/2310.11470\n",
       "\n",
       "[22] Comprehensive Overview of the Opportunities and Challenges in AI, https://ieeexplore.ieee.org/document/10169722\n",
       "\n",
       "[23] Understanding The Limitations Of Generative AI - Forbes, https://www.forbes.com/councils/forbestechcouncil/2024/05/09/understanding-the-limitations-of-generative-ai/\n",
       "\n",
       "[24] Strengths and weaknesses of deep learning models for face recognition ..., https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/iet-bmt.2017.0083\n",
       "\n",
       "[25] Key Concepts and Considerations in Generative AI, https://learn.microsoft.com/en-us/azure/developer/ai/gen-ai-concepts-considerations-developers\n",
       "\n",
       "[26] The Top 5 challenges implementing AI — and how to overcome them, https://www.glideapps.com/blog/challenges-implementing-ai\n",
       "\n",
       "[27] What are the limitations of generative AI? - AiOps Redefined!!!, https://www.theaiops.com/what-are-the-limitations-of-generative-ai/\n",
       "\n",
       "[28] Bridging the gaps: Overcoming challenges of implementing AI in ..., https://www.sciencedirect.com/science/article/pii/S2666634025000935\n",
       "\n",
       "[29] Assessing the Strengths and Weaknesses of Large Language Models - Springer, https://link.springer.com/article/10.1007/s10849-023-09409-x\n",
       "\n",
       "[30] 6 AI Implementation Challenges And How To Overcome Them, https://elearningindustry.com/ai-implementation-challenges-and-how-to-overcome-them\n",
       "\n",
       "[31] 10 Major Challenges of Generative AI & How to Overcome Them, https://www.theiotacademy.co/blog/challenges-of-generative-ai/\n",
       "\n",
       "[32] Deep Learning Models for Face Recognition: A Comparative Analysis, https://link.springer.com/chapter/10.1007/978-3-030-32583-1_6\n",
       "\n",
       "[33] Generative AI vs Machine Learning vs Deep Learning Differences - Redblink, https://redblink.com/generative-ai-vs-machine-learning-vs-deep-learning/\n",
       "\n",
       "[34] Generative Ai And Deep Learning: Delving Into The Difference, https://learnaiinfo.com/difference-between-generative-ai-and-deep-learning/\n",
       "\n",
       "[35] Generative AI vs Traditional AI: Key Differences in ML and DL - K21Academy, https://k21academy.com/ai-ml/deep-learning-ml-generative-ai/\n",
       "\n",
       "[36] AI, ML, DL, and Generative AI Face Off: A Comparative Analysis, https://synoptek.com/insights/it-blogs/data-insights/ai-ml-dl-and-generative-ai-face-off-a-comparative-analysis/\n",
       "\n",
       "---\n",
       "\n",
       "This report has sought to provide a comprehensive, integrated analysis of classical machine learning, deep learning, and generative AI, elucidating their definitions, methodologies, applications, strengths, limitations, and comparative distinctions. The ongoing evolution and convergence of these paradigms will continue to shape the future of AI research, deployment, and societal impact."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(research_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Workflow Visualization\n",
    "\n",
    "Below we can see the detailed steps in the research and review process, showing how the ResearchAgent and PeerReviewAgent collaborated to produce the final report. This visualization helps us understand how many iterations were required to meet quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 AGENT WORKFLOW: 'Create an exceptionally comprehensive, **paragraph-focused** and detailed research report using the following content. **Minimize bullet points** and ensure the final text resembles a cohesive, academic-style paper:\n",
      "\n",
      "{\n",
      "  \"objective\": \"To comprehensively analyze and articulate the key differences, overlaps, and unique characteristics of classical machine learning, deep learning, and generative AI, including their definitions, methodologies, applications, strengths, and limitations.\",\n",
      "  \"aggregated_summaries\": [\n",
      "    {\n",
      "      \"subtopic\": \"Definitions and Core Concepts\",\n",
      "      \"summary\": \"Acknowledging that the input combines information potentially from multiple search results, here is a unified summary focused on the subtopic 'Definitions and Core Concepts' for classical machine learning, deep learning, and generative AI.\\n\\n---\\n\\n## Key Insights\\n- **Classical machine learning** encompasses foundational, statistically-driven algorithms for structured data, emphasizing interpretability a'\n",
      "\n",
      "\n",
      "================================================================================\n",
      "👤 AGENT: ResearchAgent\n",
      "--------------------------------------------------------------------------------\n",
      "  💬 OUTPUT: {\"objective\":\"To comprehensively analyze and articulate the key differences, overlaps, and unique...\n",
      "\n",
      "================================================================================\n",
      "🏁 FINAL OUTPUT:\n",
      "--------------------------------------------------------------------------------\n",
      "# A Comprehensive Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Definitions, Methodologies, Applications, Strengths, and Comparative Perspectives\n",
      "\n",
      "## Introduction\n",
      "\n",
      "The rapi...\n"
     ]
    }
   ],
   "source": [
    "from common.helper import pretty_print_agent_workflow\n",
    "pretty_print_agent_workflow(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson-deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
