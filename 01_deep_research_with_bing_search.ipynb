{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Projects, and the OpenAI Agents SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Azure OpenAI to work with OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents import (\n",
    "    set_default_openai_client,\n",
    "    set_tracing_disabled,\n",
    "    OpenAIChatCompletionsModel\n",
    ")\n",
    "\n",
    "# setup settings\n",
    "from openai import AsyncAzureOpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Use the synchronous client instead of the async one\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AOAI_KEY\"),\n",
    "    api_version=os.environ.get(\"AOAI_API_VERSION\", \"2024-02-01\")\n",
    ")\n",
    "\n",
    "# Configure SDK\n",
    "set_default_openai_client(openai_client)\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "reasoningModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"reasoningModel\"), \n",
    "    openai_client=openai_client\n",
    ")\n",
    "\n",
    "chatModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    openai_client=openai_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models for Research Workflow\n",
    "\n",
    "The following Pydantic models define the structured data used throughout our research process:\n",
    "\n",
    "1. **ResearchTask** - Represents an individual research task with specific search queries\n",
    "2. **ResearchPlan** - Contains the overall plan with research objectives and tasks\n",
    "3. **Citation** - Stores source information for proper attribution\n",
    "4. **ComprehensiveResearchReport** - Defines the structure of the final research output\n",
    "5. **PeerReviewFeedback** - Contains structured feedback on report quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResearchTask(BaseModel):\n",
    "    id: Optional[str] = Field(None, description=\"Unique identifier for the task\")\n",
    "    subtopic: str = Field(..., description=\"Subtopic to research\")\n",
    "    search_queries: List[str] = Field(..., description=\"List of search queries to explore this subtopic\")\n",
    "    completed: bool = Field(..., description=\"Status of task completion\")\n",
    "\n",
    "class ResearchPlan(BaseModel):\n",
    "    query: str = Field(..., description=\"The original user query that prompted this research\")\n",
    "    objective: str = Field(..., description=\"The overall research objective, clearly defined\")\n",
    "    success_criteria: List[str] = Field(..., description=\"Criteria to determine when the research is sufficiently complete.\")\n",
    "    related_topics: List[str] = Field(..., description=\"List of related topics that may be useful for the research.\")\n",
    "    research_tasks: List[ResearchTask] = Field(..., description=\"List of specific research tasks to complete. Each task focuses on a subtopic.\")\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "\n",
    "class ComprehensiveResearchReport(BaseModel):\n",
    "    objective: str = Field(..., description=\"The original research objective\")\n",
    "    research_report: str = Field(..., description=(\n",
    "        \"Comprehensive research report in markdown. \"\n",
    "        \"It should be structured with meaningful headings and subsections, but emphasize **fully-developed paragraphs**. \"\n",
    "        \"It should be long and detailed, and it should fully addresses the objectives, \"\n",
    "        \"and the various subtopics required to achieve the success criteria. \"\n",
    "        \"Use bullet points or lists **only** when they genuinely improve clarity (e.g., summarizing key data). \"\n",
    "        \"Tables and other data visualizations are encouraged. \"\n",
    "        \"The research report should always be long and detailed.\\n\\n\" \n",
    "        \"For citations, please use the IEEE (Institute of Electrical and Electronics Engineers). \"\n",
    "        \"How it works:\\n\\n\"\n",
    "        \"   1. In the text, use numbered citations in brackets [1].\\n\"\n",
    "        \"   2. At the end of the report, provide a list of citations in the format \"\n",
    "        \"(the list should ONLY contain the sources used in the free text of the research report. \"\n",
    "        \"Do NOT list sources which are not cited in the free text of the research report.):\\n\\n\"\n",
    "        \"       [1] Title of the source, URL.\"\n",
    "    ))\n",
    "    citations: List[Citation] = Field(..., description=(\n",
    "        \"List of citations (title and URL), corresponding to references actually used in research_report. \"\n",
    "        \"Do not add references that are not cited within the text.\"\n",
    "    ))\n",
    "    identified_gaps: Optional[List[str]] = Field(default=None, description=\"Identified information gaps.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Suggestions for additional research.\")\n",
    "\n",
    "class PeerReviewFeedback(BaseModel):\n",
    "    overall_feedback: str = Field(..., description=\"General feedback on the report.\")\n",
    "    strengths: List[str] = Field(..., description=\"Aspects of the report that are well done.\")\n",
    "    suggested_improvements: List[str] = Field(..., description=\"Specific suggestions to improve clarity, completeness, accuracy, or structure.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Additional research queries that could strengthen the report.\")\n",
    "    is_satisfactory: bool = Field(..., description=\"Indicates if the report meets all quality standards and no further revisions are needed.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "The research workflow is powered by two types of agents:\n",
    "\n",
    "1. **Azure AI Agents** - Created using Azure AI Projects for web search capabilities\n",
    "2. **OpenAI Agents** - For specialized research tasks\n",
    "\n",
    "Let's configure each type of agent with their specific instructions and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will ***create*** an **Azure AI Agent**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.ai.agents.models import BingGroundingTool\n",
    "\n",
    "# import datetime\n",
    "# current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# bing_connection = project_client.connections.get(\n",
    "#     name=os.getenv(\"BING_CONNECTION_NAME\")\n",
    "# )\n",
    "\n",
    "# bing_tool = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "# bing_search_agent = project_client.agents.create_agent(\n",
    "#     name=\"bingSearchAgent\",\n",
    "#     description=\"Agent to perform web searches using Bing.\",\n",
    "#     model=os.getenv(\"chatModel\"),\n",
    "#     temperature=0.5,\n",
    "#     tools=bing_tool.definitions,\n",
    "#     instructions=f\"\"\"\n",
    "# You are a helpful research assistant.\n",
    "\n",
    "# Today's date is {current_date}.\n",
    "\n",
    "# Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "# When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "# Provide a comprehensive answer based on the search results.\n",
    "#     \"\"\".strip()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have an Azure AI Agent, run this cell to update it's instructions with today's date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful research assistant.\n",
      "\n",
      "Today's date is 2025-06-03.\n",
      "\n",
      "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
      "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
      "Provide a comprehensive answer based on the search results.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "bing_search_agent.instructions = f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(bing_search_agent.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenAI Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    Agent,\n",
    "    ModelSettings\n",
    ")\n",
    "\n",
    "chatModelSettings=ModelSettings(\n",
    "        max_tokens=32768,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "    \n",
    "    You are an expert research planner specializing in creating detailed research plans your task is to analyze a user's research query and create a structured research plan.\n",
    "    with the following components:\n",
    "    \n",
    "    1. DOMAIN CLASSIFICATION:\n",
    "       Classify the query into a fitting domain (e.g., technology, business, etc.).\n",
    "       The Domain is not included in the output, but it is important for the other components in the research plan.\n",
    "       The domain should be a single word (e.g., technology, business, etc.).\n",
    "       \n",
    "    2. RESEARCH OBJECTIVE:\n",
    "       Create a clear, comprehensive objective statement for the research\n",
    "       \n",
    "    3. SUBTOPICS:\n",
    "       Generate relevant subtopics that should be explored to thoroughly answer the query (Important. generate no less than 5 subtopics)\n",
    "       \n",
    "    4. SEARCH QUERIES:\n",
    "       For each subtopic, provide search queries that will yield valuable results (Important. It's better to generate more queries than less queries, but at least 3 queries per subtopic)\n",
    "       \n",
    "    5. SUCCESS CRITERIA:\n",
    "       List the criteria that will determine when the research is complete (Important. generate no less than 4 success criteria)\n",
    "       Take all of the above into account (e.g., the domain, objective, subtopics, and search queries) to create the success criteria.\n",
    "       \n",
    "    6. RELATED TOPICS:\n",
    "       suggest related topics that may be useful for the research (Important. generate no less than 3 related topics)\n",
    "    \n",
    "    Ensure each subtopic is thorough and directly relevant to the research query.\n",
    "    The search queries should be specific enough to return high-quality results.\n",
    "    \"\"\".strip(),\n",
    "    model=chatModel,\n",
    "    output_type=ResearchPlan,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "summary_agent = Agent(\n",
    "    name=\"SummaryAgent\",\n",
    "    instructions=(\n",
    "        \"You are a comprehensive research summarization specialist. Your task is to **synthesize information from combined search result content** related to a specific subtopic (which will be mentioned in the input prompt). \"\n",
    "        \"Create a **single, coherent, detailed, and information-rich summary** that:\\n\\n\"\n",
    "        \"1. Extracts ALL important facts, statistics, findings, and insights **relevant to the specified subtopic** from the combined text.\\n\"\n",
    "        \"2. Preserves specific numbers, percentages, dates, and technical details whenever present.\\n\"\n",
    "        \"3. Includes industry-specific terminology and concepts that add depth to the research.\\n\"\n",
    "        \"4. **Synthesizes** the key arguments and conclusions from the provided sources. If sources present different perspectives or data, try to capture that nuance.\\n\"\n",
    "        \"5. Provides thorough explanations rather than superficial overviews, integrating information smoothly.\\n\"\n",
    "        \"6. For technical content, preserves methodologies, technical specifications, and implementation details.\\n\"\n",
    "        \"7. For comparative content, maintains all sides of the comparison with their specific attributes.\\n\\n\"\n",
    "\n",
    "        \"**Acknowledge that the input combines information potentially from multiple search results.** Your goal is to create a unified summary focused on the overall subtopic, not just list summaries of individual parts.\\n\\n\"\n",
    "\n",
    "        \"Remember that your summary serves as the foundation for generating a comprehensive research report. The quality and depth of the final research report depends directly on how comprehensive and well-synthesized your summary is. Ensure it captures the essence of all provided content relevant to the subtopic.\\n\\n\"\n",
    "\n",
    "        \"FORMAT YOUR SUMMARY AS:\\n\"\n",
    "        \"## Key Insights\\n\"\n",
    "        \"- [Most critical takeaway #1]\\n\"\n",
    "        \"- [Most critical takeaway #2]\\n\"\n",
    "        \"- [Most critical takeaway #3]\\n\"\n",
    "        \"- [Optional: Most critical takeaway #4]\\n\\n\"\n",
    "        \"## Extensive Synthesis\\n\"\n",
    "        \"Write a thorough, multi-paragraph synthesis that:\\n\"\n",
    "        \"- Integrates all important facts, statistics, findings, and insights relevant to the subtopic.\\n\"\n",
    "        \"- Preserves specific numbers, percentages, dates, and technical details.\\n\"\n",
    "        \"- Explains methodologies, technical specifications, and implementation details where relevant.\\n\"\n",
    "        \"- Highlights agreements, disagreements, and nuances between sources.\\n\"\n",
    "        \"- Uses industry-specific terminology and concepts.\\n\"\n",
    "        \"- Provides context, background, and implications for the findings.\\n\"\n",
    "        \"- Maintains logical flow: start with an overview, then go into specifics, and conclude with implications or open questions.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    output_type=str,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    instructions=(\n",
    "        \"## General Instructions\\n\"\n",
    "        \"You are a meticulous research analyst specializing in creating **long, comprehensive, authoritative** reports. \"\n",
    "        \"Your goal is to produce **in-depth, highly detailed** content that thoroughly analyzes all aspects of the research topic. \"\n",
    "        \"Furthermore, you must also demonstrate subject matter expertise with nuanced insights, technical details, and sophisticated analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Style & Format:\\n\"\n",
    "        \"- **Default to paragraphs.** Present your findings in cohesive, well-structured paragraphs rather than excessive bullet points.\\n\"\n",
    "        \"- **Use bullet points sparingly.** Only use them when they add genuine clarity—e.g., summarizing key data.\\n\"\n",
    "        \"- **Structure** the report with a clear hierarchy, but avoid excessive nesting. Aim for a balanced structure:\\n\"\n",
    "        \"   - Use main sections and occasional subsections where needed.\\n\"\n",
    "        \"   - Avoid over-fragmentation by limiting sub-subsections unless absolutely necessary.\\n\"\n",
    "        \"   - Favor broader thematic groupings to maintain narrative flow and reduce section clutter.\\n\"\n",
    "        \"   - With that said, if a subtopic would benefit from a sub-subsection, feel free to add it.\\n\"\n",
    "        \"- **Data visualizations** (e.g., tables, charts, diagrams) in Markdown are encouraged wherever they enhance understanding.\\n\"\n",
    "        \"- Maintain a logical, flowing structure so each subsection builds upon the prior sections.\\n\"\n",
    "        \"- **Citations:** Use IEEE style: [1], [2], etc. Provide a 'References' section at the end of your report with only the sources cited in the text.\\n\\n\"\n",
    "        \n",
    "        \"### Long & Comprehensive Requirement:\\n\"\n",
    "        \"- The final report must be the equivalent of **10 to 12 pages** of substantive text, approximately **7000-9000 words**.\\n\"\n",
    "        \"- Each major section should have **extensive exploration** (ideally 800-1000 words per section).\\n\"\n",
    "        \"- Ensure thorough coverage of the topic with **well-developed paragraphs**, plenty of detail, and rigorous analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Depth Requirements:\\n\"\n",
    "        \"- Include **quantitative data**, statistics, and specific examples to support your arguments.\\n\"\n",
    "        \"- Compare and contrast **multiple perspectives** on complex topics.\\n\"\n",
    "        \"- Integrate ideas across sections for a cohesive, synthesized analysis rather than isolated observations.\\n\\n\"\n",
    "        \n",
    "        \"### Workflow\\n\"\n",
    "        \"- When given the research objective and content, develop a **long-form narrative** with detailed explanations.\\n\"\n",
    "        \"- If PeerReviewAgent provides feedback, revise thoroughly, addressing all points.\\n\"\n",
    "        \"- Once feedback is marked satisfactory, present the final report.\\n\\n\"\n",
    "        \n",
    "        \"### Important Guidelines\\n\"\n",
    "        \"- Retain high-quality content in any revision.\\n\"\n",
    "        \"- If feedback highlights missing info, propose specific research queries.\\n\"\n",
    "        \"- Avoid unnecessary repetition.\\n\\n\"\n",
    "\n",
    "        \"**REMINDER**:\"\n",
    "        \"Your output should be a single, cohesive Markdown document that reads like a well-developed academic or professional paper, with minimal use of bullet points. \"\n",
    "        \"Prefer broader thematic sections over excessive fragmentation. \"\n",
    "        \"Sub-subsections may be used where helpful, but structure should remain balanced and readable. \"\n",
    "        \"Lastly, do not forget to include the references section at the end of the report.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=ComprehensiveResearchReport,\n",
    ")\n",
    "\n",
    "peer_review_agent = Agent(\n",
    "    name=\"PeerReviewAgent\",\n",
    "    instructions=(\n",
    "        \"You are a critical yet constructive peer reviewer evaluating research reports. \"\n",
    "        \"Your goal is to provide detailed, actionable feedback using a structured evaluation framework.\\n\\n\"\n",
    "        \n",
    "        \"## Evaluation Framework:\\n\"\n",
    "        \"1. COMPLETENESS (0-10): Does the report thoroughly cover all aspects of the research topic?\\n\"\n",
    "        \"   - Are all required subtopics adequately addressed?\\n\"\n",
    "        \"   - Is there sufficient depth in each section (500+ words per major section)?\\n\"\n",
    "        \"   - Are there any obvious gaps or missing perspectives?\\n\\n\"\n",
    "        \n",
    "        \"2. CLARITY & STRUCTURE (0-10): Is the report well-organized and clearly written?\\n\"\n",
    "        \"   - Does it have a logical flow with clear sections and subsections?\\n\"\n",
    "        \"   - Are complex concepts explained in accessible language?\\n\"\n",
    "        \"   - Does it use formatting effectively (headings, lists, tables)?\\n\\n\"\n",
    "        \n",
    "        \"3. EVIDENCE & SUPPORT (0-10): Is information well-supported?\\n\"\n",
    "        \"   - Are claims backed by data, statistics, or authoritative sources?\\n\"\n",
    "        \"   - Are citations used appropriately and consistently?\\n\"\n",
    "        \"   - Does it include multiple perspectives when appropriate?\\n\\n\"\n",
    "        \n",
    "        \"4. ANALYSIS & INSIGHT (0-10): Does the report provide valuable analysis?\\n\"\n",
    "        \"   - Does it go beyond summarizing to provide meaningful insights?\\n\"\n",
    "        \"   - Does it connect ideas across different sections?\\n\"\n",
    "        \"   - Does it identify implications and future directions?\\n\\n\"\n",
    "        \n",
    "        \"## Response Guidelines:\\n\"\n",
    "        \"- For each criterion, provide a score (0-10) and specific feedback citing examples from the report\\n\"\n",
    "        \"- In your overall assessment, calculate a total score (0-40)\\n\"\n",
    "        \"- Reports scoring 32+ (80%) can be marked as satisfactory\\n\"\n",
    "        \"- For reports below 32, provide clear, prioritized improvement suggestions\\n\"\n",
    "        \"- Be constructive and specific - point to exact sections that need improvement\\n\"\n",
    "        \n",
    "        \"\\n\\n## Important Rules:\"\n",
    "        \"\\n- If the report meets all quality standards (score ≥32), simply confirm this by changing the is_satisfactory field to true and hand it back to ResearchAgent.\"\n",
    "        \"\\n- Always perform a handoff to ResearchAgent for final report generation.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=PeerReviewFeedback,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hand-offs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent.handoffs = [peer_review_agent]\n",
    "peer_review_agent.handoffs = [research_agent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"183pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 182.68\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.790802 0.790802) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 1999.03,-227 1999.03,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1090.29,-8C1090.29,-8 1746.54,-8 1746.54,-8 1752.54,-8 1758.54,-14 1758.54,-20 1758.54,-20 1758.54,-203 1758.54,-203 1758.54,-209 1752.54,-215 1746.54,-215 1746.54,-215 1090.29,-215 1090.29,-215 1084.29,-215 1078.29,-209 1078.29,-203 1078.29,-203 1078.29,-20 1078.29,-20 1078.29,-14 1084.29,-8 1090.29,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"1418.42\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.86,-72.6C133.43,-72.24 159.62,-72.4 216.49,-73.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.32,-76.59 226.37,-73.22 216.41,-69.59 216.32,-76.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.46,-71.88C370.78,-71.43 396.13,-71.62 445.49,-72.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.18,-75.92 455.23,-72.59 445.29,-68.92 445.18,-75.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M926.04,-92.25C926.04,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 926.04,-55.75 926.04,-55.75 932.04,-55.75 938.04,-61.75 938.04,-67.75 938.04,-67.75 938.04,-80.25 938.04,-80.25 938.04,-86.25 932.04,-92.25 926.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;summary -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.28,-69C638.59,-68.14 669.02,-68.56 725.16,-70.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.73,-73.76 734.83,-70.57 724.94,-66.76 724.73,-73.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1188.54,-92.25C1188.54,-92.25 1098.29,-92.25 1098.29,-92.25 1092.29,-92.25 1086.29,-86.25 1086.29,-80.25 1086.29,-80.25 1086.29,-67.75 1086.29,-67.75 1086.29,-61.75 1092.29,-55.75 1098.29,-55.75 1098.29,-55.75 1188.54,-55.75 1188.54,-55.75 1194.54,-55.75 1200.54,-61.75 1200.54,-67.75 1200.54,-67.75 1200.54,-80.25 1200.54,-80.25 1200.54,-86.25 1194.54,-92.25 1188.54,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M881.86,-55.34C964.88,-21.4 990.44,-20.14 1081.1,-51.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.86,-54.82 1090.45,-54.83 1082.17,-48.22 1079.86,-54.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"1012.17\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1416.54,-52.25C1416.54,-52.25 1327.04,-52.25 1327.04,-52.25 1321.04,-52.25 1315.04,-46.25 1315.04,-40.25 1315.04,-40.25 1315.04,-27.75 1315.04,-27.75 1315.04,-21.75 1321.04,-15.75 1327.04,-15.75 1327.04,-15.75 1416.54,-15.75 1416.54,-15.75 1422.54,-15.75 1428.54,-21.75 1428.54,-27.75 1428.54,-27.75 1428.54,-40.25 1428.54,-40.25 1428.54,-46.25 1422.54,-52.25 1416.54,-52.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1200.81,-63.21C1253.32,-53.35 1281.27,-48.19 1303.85,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1304.14,-47.88 1313.43,-42.79 1302.99,-40.97 1304.14,-47.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"1257.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1650.69,-105.94C1650.69,-105.94 1584.14,-78.56 1584.14,-78.56 1578.59,-76.28 1578.59,-71.72 1584.14,-69.44 1584.14,-69.44 1650.69,-42.06 1650.69,-42.06 1656.24,-39.78 1667.34,-39.78 1672.89,-42.06 1672.89,-42.06 1739.44,-69.44 1739.44,-69.44 1744.99,-71.72 1744.99,-76.28 1739.44,-78.56 1739.44,-78.56 1672.89,-105.94 1672.89,-105.94 1667.34,-108.22 1656.24,-108.22 1650.69,-105.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1211.83,-72.2C1443.6,-66.13 1499.16,-65.21 1583.06,-69.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1212.08,-68.69 1202.17,-72.45 1212.26,-75.69 1212.08,-68.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.68,-37.82C1526.04,-44.45 1562.55,-47.76 1598.61,-56.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.31,-59.39 1607.86,-58.37 1598.98,-52.59 1597.31,-59.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"1500.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"1925.91\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1748.73,-72.86C1794.97,-72.28 1822.55,-72.05 1845.08,-72.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1844.92,-75.66 1854.95,-72.24 1844.98,-68.66 1844.92,-75.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"1803.67\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x20bab8b7670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "plan = await Runner().run(\n",
    "    starting_agent=planner_agent,\n",
    "    input=user_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is classical machine learning?',\n",
       " 'Definition of deep learning in AI',\n",
       " 'What is generative AI?',\n",
       " 'Foundational principles of classical ML, deep learning, and generative AI',\n",
       " 'Overview of AI paradigms: classical ML, deep learning, generative AI']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.final_output.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics: 100%|██████████| 5/5 [04:25<00:00, 53.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.final_output.research_tasks, desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            message = project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=formatted_query,\n",
    "            )\n",
    "\n",
    "            # Process the run\n",
    "            run = project_client.agents.runs.create_and_process(\n",
    "                thread_id=thread.id,\n",
    "                agent_id=bing_search_agent.id\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 25\n",
      "\n",
      "Actually total search queries: 25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.final_output.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 5/5 [01:17<00:00, 15.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    all_agent_responses_for_subtopic, unique_citations_for_subtopic = collect_responses_and_citations(subtopic_result)\n",
    "\n",
    "    # --- Summarize the combined agent responses ONCE per subtopic ---\n",
    "    content_to_summarize = \"\\n\\n---\\n\\n\".join(all_agent_responses_for_subtopic)\n",
    "\n",
    "    subtopic_summary = \"No content found to summarize for this subtopic.\" # Default value\n",
    "    if content_to_summarize:\n",
    "        summary_prompt = f\"Summarize the following information related to the subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content_to_summarize}\"\n",
    "        try:\n",
    "            summary_response = await Runner().run(\n",
    "                starting_agent=summary_agent,\n",
    "                input=summary_prompt\n",
    "            )\n",
    "            subtopic_summary = summary_response.final_output # Adjust based on actual response structure\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}': {e}\")\n",
    "            subtopic_summary = f\"Error during summarization for subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}'. Details: {e}\"\n",
    "            # Depending on requirements, you might want to raise the exception, log it, or handle it differently\n",
    "\n",
    "    # --- Convert set of tuples back to list of dictionaries (or Citation objects) ---\n",
    "    citations_list = [\n",
    "        {\"title\": title, \"url\": url}\n",
    "        for title, url in unique_citations_for_subtopic\n",
    "    ]\n",
    "\n",
    "    # --- Append the consolidated result ---\n",
    "    mapped_chunks.append({\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"), # Use .get for safety\n",
    "        \"summary\": subtopic_summary,\n",
    "        \"citations\": citations_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "final_answer = await Runner().run(\n",
    "    starting_agent=research_agent,\n",
    "    input=(\n",
    "        \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "        \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "        \"a cohesive, academic-style paper:\\n\\n\"\n",
    "        f\"{research_input_prompt}\\n\\n\"\n",
    "        \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    "    ),\n",
    "    max_turns=21 # 5 turns are needed for a full collaboration between ResearchAgent and PeerReviewAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Final Research Report\n",
    "\n",
    "After the ResearchAgent and PeerReviewAgent complete their collaborative process, we extract the final research report from the agent outputs. The report includes:\n",
    "\n",
    "1. A clearly defined research objective\n",
    "2. Multiple sections covering all identified subtopics\n",
    "3. In-depth analysis with facts, statistics, and insights\n",
    "4. Proper citations using IEEE format\n",
    "5. A comprehensive references section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import HandoffCallItem\n",
    "import json\n",
    "\n",
    "def extract_research_report(final_answer):\n",
    "    # If final output is from ResearchAgent, get the report directly\n",
    "    if hasattr(final_answer.final_output, \"research_report\"):\n",
    "        return final_answer.final_output.research_report\n",
    "    \n",
    "    # If final output is from PeerReviewAgent, find the latest research report from ResearchAgent\n",
    "    for item in reversed(final_answer.new_items):  # Start from end to get the latest\n",
    "        if isinstance(item, HandoffCallItem) and item.agent.name == \"ResearchAgent\":\n",
    "            try:\n",
    "                args = json.loads(item.raw_item.arguments)\n",
    "                if \"research_report\" in args:\n",
    "                    return args[\"research_report\"]\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                continue\n",
    "    \n",
    "    # If we couldn't find a report\n",
    "    raise ValueError(\"No research report found in the conversation history\")\n",
    "\n",
    "research_report = extract_research_report(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Report Presentation\n",
    "\n",
    "The completed research report is displayed below in Markdown format. The report represents a comprehensive analysis of the original query, incorporating insights from multiple web sources and structured in an academic format with proper citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Comparative Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Principles, Methodologies, Applications, and Interrelationships\n",
       "\n",
       "## Introduction\n",
       "\n",
       "The field of artificial intelligence (AI) has undergone a remarkable transformation over the past several decades, evolving from rule-based systems and statistical models to sophisticated neural architectures capable of generating novel content. Central to this evolution are three core paradigms: classical machine learning, deep learning, and generative AI. Each approach is characterized by distinct foundational principles, technical methodologies, and application domains, yet they are deeply interconnected, often building upon and extending the capabilities of their predecessors. As AI technologies become increasingly pervasive across industries, a nuanced understanding of these paradigms—their definitions, architectures, strengths, limitations, and relationships—is essential for practitioners, researchers, and decision-makers seeking to harness their potential.\n",
       "\n",
       "This report provides an exceptionally comprehensive, integrated analysis of classical machine learning, deep learning, and generative AI. It systematically explores their definitions and foundations, technical architectures, real-world applications, comparative advantages and limitations, and the intricate relationships that bind them. Drawing on authoritative sources, the report aims to clarify the unique contributions and interdependencies of each approach, offering a robust framework for understanding the current landscape and future trajectory of AI.\n",
       "\n",
       "## 1. Definitions and Foundations of Each Approach\n",
       "\n",
       "The taxonomy of AI is structured around several core paradigms, each defined by unique methodologies, theoretical underpinnings, and operational mechanisms. Understanding the foundational principles of classical machine learning, deep learning, and generative AI is essential for appreciating their respective roles in contemporary AI applications.\n",
       "\n",
       "### 1.1 Classical Machine Learning\n",
       "\n",
       "Classical machine learning (ML) encompasses a suite of algorithms and statistical models developed prior to the deep learning revolution. These methods—including linear regression, logistic regression, decision trees, support vector machines (SVM), k-nearest neighbors (KNN), and clustering algorithms like k-means—are rooted in statistical theory and mathematical rigor. The hallmark of classical ML is its reliance on explicit feature engineering: practitioners manually select, transform, and craft input features based on domain knowledge to optimize model performance. This approach is particularly effective with structured, tabular data and is characterized by its interpretability, transparency, and statistical soundness. Classical ML algorithms are typically less computationally intensive than deep learning models, making them suitable for scenarios with limited data or where model explainability is paramount. The learning paradigms within classical ML include supervised learning (using labeled data), unsupervised learning (discovering patterns in unlabeled data), and reinforcement learning (learning from feedback or rewards). The overarching goal is generalization—ensuring models perform robustly on unseen data, not just the training set [1][4][5][10].\n",
       "\n",
       "### 1.2 Deep Learning\n",
       "\n",
       "Deep learning represents a subset of machine learning that leverages multilayered artificial neural networks—often referred to as deep neural networks—to automatically extract and learn hierarchical representations from raw data. Unlike classical ML, deep learning minimizes the need for manual feature engineering by enabling networks to discover relevant features autonomously through multiple layers of abstraction. Core architectures include convolutional neural networks (CNNs) for image data and recurrent neural networks (RNNs) for sequential data, among others. Training deep networks relies on algorithms such as backpropagation and gradient descent to iteratively minimize prediction errors. Deep learning models are highly scalable, often requiring vast datasets and significant computational resources (e.g., GPUs or TPUs) to achieve state-of-the-art performance. This approach excels in complex domains such as image and speech recognition, natural language processing (NLP), and autonomous systems, frequently surpassing human-level accuracy in specialized tasks. However, deep learning models are often considered \"black boxes\" due to their complexity and lack of interpretability compared to classical ML [2][6][8][11][12][13][15].\n",
       "\n",
       "### 1.3 Generative AI\n",
       "\n",
       "Generative AI (GenAI) is a rapidly advancing subfield of AI focused on creating new, original content—including text, images, audio, video, and even software code—that mimics the properties of its training data. Generative AI distinguishes itself from traditional discriminative models by learning the underlying probability distributions of data, enabling the synthesis of novel and realistic artifacts. Foundational models in this space include Generative Adversarial Networks (GANs), which employ an adversarial training process between a generator and a discriminator; Variational Autoencoders (VAEs), which use probabilistic encoding and decoding; and Large Language Models (LLMs) like GPT, which generate human-like text. Generative AI systems are capable of producing content on demand in response to user prompts, powering applications such as conversational agents (e.g., ChatGPT), image generation (e.g., DALL-E), and data augmentation for machine learning pipelines. The creative and synthetic capabilities of generative AI are transforming industries by enabling new forms of content creation, simulation, and automation [7][9][14][16].\n",
       "\n",
       "### 1.4 Comparative Foundations\n",
       "\n",
       "A comparative analysis reveals that while classical machine learning emphasizes interpretability, statistical rigor, and manual feature design, deep learning prioritizes automatic hierarchical feature extraction and excels with unstructured, high-dimensional data. Generative AI builds upon both, utilizing advanced deep learning architectures to model and sample from complex data distributions for content generation. Each paradigm is underpinned by distinct technical methodologies—ranging from explicit algorithmic learning and feature engineering in classical ML, to neural network-based representation learning and backpropagation in deep learning, and adversarial or probabilistic generative modeling in GenAI. Understanding these foundational distinctions is essential for selecting the appropriate AI methodology for a given problem and for advancing research and innovation in the field [1][2][7][9].\n",
       "\n",
       "## 2. Model Architectures and Methodologies\n",
       "\n",
       "The progression from classical machine learning to deep learning and generative AI is marked by increasingly sophisticated model architectures and training methodologies. Each paradigm is defined by characteristic model families, internal structures, and methodological approaches that determine their suitability for different data types and tasks.\n",
       "\n",
       "### 2.1 Classical Machine Learning Architectures\n",
       "\n",
       "Classical ML algorithms are foundational, interpretable, and effective for structured data, relying on well-understood mathematical frameworks and often requiring manual feature engineering. Key models include:\n",
       "\n",
       "- **Linear Regression**: A supervised regression model that fits a linear equation to the relationship between input features and a continuous output, minimizing the sum of squared errors. Its simplicity and interpretability make it a staple for predictive analytics.\n",
       "- **Logistic Regression**: Extends linear regression to classification by applying a logistic (sigmoid) function, outputting probabilities for binary outcomes. It is widely used for binary and, with extensions, multiclass classification.\n",
       "- **Decision Trees**: These models partition data recursively based on feature values, forming a tree structure where nodes represent features, branches represent decision rules, and leaves represent outcomes. Trees are interpretable and can handle both regression and classification.\n",
       "- **Support Vector Machines (SVMs)**: SVMs identify the optimal hyperplane that maximizes the margin between classes in high-dimensional space. The use of kernel tricks allows SVMs to handle non-linear boundaries efficiently.\n",
       "- **k-Nearest Neighbors (k-NN)**: An instance-based, non-parametric method that classifies or regresses based on the majority label or average value among the k closest data points, using distance metrics like Euclidean distance.\n",
       "- **Naive Bayes**: A probabilistic classifier based on Bayes’ theorem, assuming independence among features. It is fast, simple, and effective for text classification and other high-dimensional problems.\n",
       "- **Principal Component Analysis (PCA)**: An unsupervised dimensionality reduction technique that projects data onto orthogonal axes (principal components) capturing the greatest variance.\n",
       "- **Clustering Algorithms (e.g., k-Means)**: Unsupervised methods that partition data into clusters by minimizing within-cluster variance, iteratively updating centroids and assignments [1][2][3][4].\n",
       "\n",
       "These classical models are preferred for their interpretability, efficiency, and effectiveness on small to medium-sized datasets. However, they often require significant manual feature engineering and may struggle with unstructured data such as images or text.\n",
       "\n",
       "### 2.2 Deep Learning Architectures\n",
       "\n",
       "Deep learning leverages neural networks with multiple layers to automatically learn hierarchical representations from raw data. Key architectures include:\n",
       "\n",
       "- **Convolutional Neural Networks (CNNs)**: Designed for spatial data, CNNs use convolutional layers to extract local features, pooling layers for dimensionality reduction, and fully connected layers for final prediction. They dominate image classification, object detection, and medical imaging due to their ability to capture spatial hierarchies.\n",
       "- **Recurrent Neural Networks (RNNs)**: Suited for sequential data, RNNs maintain hidden states across time steps, enabling modeling of temporal dependencies. Variants like LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) address the vanishing gradient problem, allowing learning of long-range dependencies in tasks like language modeling and speech recognition.\n",
       "- **Transformers**: Transformers have revolutionized NLP and are increasingly used in vision and multi-modal tasks. Their self-attention mechanism allows modeling of relationships between all elements in a sequence, enabling parallelization and scalability. Key components include multi-head attention, positional encoding, and feed-forward layers. Transformers underpin large language models (LLMs) such as GPT and BERT [5][6][7][8].\n",
       "\n",
       "Deep learning models excel at learning from unstructured data and have driven breakthroughs in computer vision, NLP, and audio processing. However, they require large datasets and significant computational resources, and their interpretability can be limited compared to classical models.\n",
       "\n",
       "### 2.3 Generative AI Architectures\n",
       "\n",
       "Generative AI models are designed to synthesize new data samples that resemble the training data, with applications in image, text, audio, and video generation. The main generative architectures include:\n",
       "\n",
       "- **Generative Adversarial Networks (GANs)**: Comprise a generator and a discriminator in a zero-sum game. The generator creates synthetic data, while the discriminator distinguishes real from fake. Training is adversarial, with the generator improving to fool the discriminator. GANs are renowned for producing high-fidelity images but can be unstable to train and prone to mode collapse (limited output diversity).\n",
       "- **Variational Autoencoders (VAEs)**: Feature an encoder-decoder architecture, where the encoder maps inputs to a latent distribution and the decoder reconstructs data from this space. VAEs are trained using variational inference, maximizing a lower bound on data likelihood. They are stable and provide a principled approach to latent space modeling but may produce blurrier outputs than GANs.\n",
       "- **Diffusion Models**: These models iteratively transform random noise into data samples by learning to reverse a gradual noising process. They have recently set new benchmarks for image quality and diversity, often outperforming GANs in sample fidelity and robustness, though at the cost of higher computational demands and slower sample generation.\n",
       "- **Large Language Models (LLMs)**: Built on transformer architectures, LLMs like GPT and BERT can generate coherent, contextually relevant text and perform a wide array of language tasks. They exemplify the power of generative modeling in NLP [9][10][11][12].\n",
       "\n",
       "Generative models differ from traditional ML models in their objective: rather than mapping inputs to labels or values, they learn the underlying data distribution to generate new, realistic samples. This requires more complex architectures and large-scale training data.\n",
       "\n",
       "### 2.4 Comparative Methodological Distinctions\n",
       "\n",
       "Traditional ML models are best for structured data, require manual feature engineering, and are valued for interpretability and efficiency. Deep learning models automate feature extraction, handle unstructured data, and are scalable but demand more data and computational power. Generative AI models extend deep learning to content creation, using architectures tailored for synthesis, creativity, and modeling complex data distributions. The selection of model architecture and methodology is a function of data type, task requirements, and practical constraints. As architectures evolve, hybrid approaches and model interpretability remain active areas of research, with ongoing efforts to balance performance, transparency, and computational efficiency [1][2][10][12].\n",
       "\n",
       "#### Table 1: Comparative Overview of Model Architectures\n",
       "\n",
       "| Approach                | Core Models/Architectures        | Data Type         | Feature Engineering | Scalability | Interpretability | Typical Use Cases            |\n",
       "|-------------------------|----------------------------------|-------------------|--------------------|-------------|------------------|------------------------------|\n",
       "| Classical ML            | Linear/Logistic Regression, SVM, Decision Trees, k-NN, Naive Bayes, PCA, k-Means | Structured        | Manual             | Moderate     | High             | Tabular analytics, risk scoring |\n",
       "| Deep Learning           | CNNs, RNNs (LSTM, GRU), Transformers | Unstructured      | Automatic           | High        | Low-Moderate     | Image, speech, NLP           |\n",
       "| Generative AI           | GANs, VAEs, Diffusion, LLMs      | Unstructured      | Automatic           | High        | Low              | Content generation, data synthesis |\n",
       "\n",
       "## 3. Applications and Use Cases\n",
       "\n",
       "The practical impact of AI is best illustrated through its diverse applications across industries. Each paradigm—classical machine learning, deep learning, and generative AI—finds its niche in specific domains, shaped by their technical strengths and limitations.\n",
       "\n",
       "### 3.1 Classical Machine Learning Applications\n",
       "\n",
       "Classical ML remains foundational for tasks involving structured or tabular data, where interpretability, efficiency, and lower data requirements are paramount. In healthcare, algorithms such as logistic regression, support vector machines (SVM), and decision trees are routinely deployed for disease diagnosis, patient risk prediction, and medical image analysis—enabling clinicians to predict conditions like diabetes or heart disease from patient records. In finance, classical ML powers credit scoring, fraud detection, and algorithmic trading, with linear and logistic regression and tree-based methods assessing loan risk and identifying anomalous transactions. Marketing and customer analytics leverage clustering (e.g., k-means) and classification (e.g., Naïve Bayes) for customer segmentation, churn prediction, and targeted campaigns, helping businesses anticipate and influence customer behavior. Manufacturing benefits from predictive maintenance and quality control, where SVMs and decision trees analyze sensor data to forecast equipment failures or detect product defects. Even in fields like bioinformatics, classical ML supports gene expression analysis and protein classification. While deep learning has made inroads into image recognition, classical methods such as k-nearest neighbors (k-NN) and SVMs remain relevant for simpler image classification tasks, especially when data is limited [1][2][3][4].\n",
       "\n",
       "### 3.2 Deep Learning Applications\n",
       "\n",
       "Deep learning has revolutionized applications involving unstructured data—images, audio, video, and natural language—by leveraging neural network architectures that learn hierarchical representations directly from raw data. In healthcare, convolutional neural networks (CNNs) have set new benchmarks in medical image analysis, detecting tumors and other pathologies in MRI and X-ray scans with accuracy surpassing traditional ML. Deep learning also underpins drug discovery, modeling molecular interactions to identify promising compounds. Autonomous vehicles rely on deep learning for real-time object detection, lane-keeping, and pedestrian recognition, enabling safe navigation in complex environments. In natural language processing (NLP), models like GPT and BERT drive language translation, chatbots, sentiment analysis, and text summarization, handling the nuances of human language at scale. Financial institutions use deep learning for advanced fraud detection and algorithmic trading, analyzing vast transaction datasets for subtle patterns. Retail and e-commerce platforms employ deep learning for personalized recommendations, inventory management, and customer experience optimization. In manufacturing, deep learning automates quality control through visual inspection and powers predictive maintenance and robotics. Agriculture leverages deep learning for crop disease detection, yield prediction, and precision farming using drone imagery and sensor data. However, these advances come with requirements for large labeled datasets and significant computational resources [5][6][7][8].\n",
       "\n",
       "### 3.3 Generative AI Applications\n",
       "\n",
       "Generative AI represents the cutting edge of AI applications, enabling the creation of new content—text, images, code, and more—by learning data distributions and generating novel outputs. In healthcare, generative models accelerate drug discovery by proposing new chemical compounds and generate synthetic medical images to augment training datasets, improving diagnostic model robustness, especially for rare conditions. Personalized patient communication is enhanced through AI-powered chatbots and virtual assistants. In advertising and marketing, generative AI automates content creation (ad copy, blog posts, social media), personalizes marketing messages, and generates campaign visuals. Manufacturing benefits from AI-driven product design, scenario-based supply chain optimization, and predictive maintenance simulations. Software development is transformed by tools like GitHub Copilot, which generate code snippets, automate testing, and maintain documentation. Financial services use generative models to simulate fraudulent transactions, optimize trading strategies, and automate compliance reporting. In entertainment and media, generative AI creates game characters, stories, music, and visual effects, and automates content localization. Automotive applications include vehicle design optimization, synthetic data generation for autonomous driving, and customer service chatbots. These capabilities are built on deep learning architectures such as transformers (e.g., GPT, DALL-E) and generative adversarial networks (GANs), and require substantial data and computational resources [9][10][11][12].\n",
       "\n",
       "### 3.4 Comparative Analysis of Use Cases\n",
       "\n",
       "Comparative analyses reveal distinct strengths and trade-offs. Classical ML is optimal for structured data and interpretable, quick-to-deploy solutions, but struggles with unstructured data. Deep learning excels at extracting complex patterns from unstructured data but demands large datasets and computational power. Generative AI extends deep learning by enabling the creation of new data and automating creative tasks, but introduces complexity and interpretability challenges. For example, in healthcare, classical ML is used for disease risk prediction from tabular records, deep learning for image-based diagnosis, and generative AI for synthesizing rare medical images and automating report generation. The synergy between these approaches is increasingly important—generative AI can augment deep learning models with synthetic data, while classical ML remains indispensable for structured analytics and rapid prototyping [1][2][3][4].\n",
       "\n",
       "#### Table 2: Impact Assessment Matrix Across Industries\n",
       "\n",
       "| Industry        | Classical ML Applications        | Deep Learning Applications         | Generative AI Applications         |\n",
       "|-----------------|----------------------------------|------------------------------------|------------------------------------|\n",
       "| Healthcare      | Risk prediction, diagnosis       | Medical imaging, drug discovery    | Synthetic images, drug design      |\n",
       "| Finance         | Credit scoring, fraud detection  | Fraud detection, trading           | Simulated fraud, report automation |\n",
       "| Marketing       | Customer segmentation, churn     | Recommendation systems             | Content creation, personalization  |\n",
       "| Manufacturing   | Predictive maintenance, QC       | Visual inspection, robotics        | Product design, simulation         |\n",
       "| Software Dev    | Bug prediction                   | Code completion                    | Code generation, documentation     |\n",
       "| Entertainment   | Simple analytics                 | Audio/video analysis               | Story/music generation, VFX        |\n",
       "\n",
       "## 4. Advantages and Limitations\n",
       "\n",
       "Each AI paradigm offers distinct advantages and faces unique limitations, influencing their suitability for various applications and deployment scenarios. Understanding these trade-offs is critical for effective model selection and deployment.\n",
       "\n",
       "### 4.1 Classical Machine Learning\n",
       "\n",
       "Classical machine learning methods—such as decision trees, support vector machines, and logistic regression—are foundational to AI and remain highly valued, particularly for structured or tabular data. Their primary advantages include high interpretability, with models like linear regression and decision trees offering transparent, easily understood decision processes. This interpretability is crucial in regulated domains such as healthcare and finance, where model transparency underpins trust and compliance. Classical ML models are also computationally efficient, requiring less memory and processing power, and can be effectively trained on smaller datasets. Rapid training times facilitate fast prototyping and experimentation, and the field benefits from a robust theoretical foundation and well-established best practices [1][2][3][4].\n",
       "\n",
       "However, classical ML faces notable limitations. These models often lack the expressiveness needed to capture complex, nonlinear relationships, particularly in high-dimensional or unstructured data such as images and audio. They typically require extensive manual feature engineering—a process that is both time-consuming and reliant on domain expertise. Scalability can be an issue; while ensemble methods like random forests and gradient boosting machines handle larger datasets better, algorithms like k-nearest neighbors struggle with scale due to their reliance on storing and searching the entire dataset at prediction time. Furthermore, classical ML models are sensitive to data quality, often requiring careful preprocessing to mitigate the effects of noise and outliers. For many modern AI tasks, classical ML has reached a performance ceiling, with deep learning models now surpassing them in accuracy and versatility [1][2][3][4].\n",
       "\n",
       "### 4.2 Deep Learning\n",
       "\n",
       "Deep learning—characterized by multi-layered neural networks—has revolutionized AI by enabling breakthroughs in image recognition, speech processing, and natural language understanding. Its key strengths include the ability to automatically extract relevant features from raw data, eliminating the need for manual feature engineering. Deep learning models are highly scalable, capable of leveraging vast datasets and computational resources to improve performance continually. This scalability and adaptability make them suitable for big data applications and a wide array of domains, from autonomous vehicles to medical diagnostics. Deep learning's versatility is further demonstrated by its capacity to handle unstructured data and its continuous improvement as more data and computational power become available [5][6][7][8].\n",
       "\n",
       "The limitations of deep learning are significant. These models are data-hungry, often requiring millions of labeled examples to reach optimal performance—a barrier in domains where labeled data is scarce or expensive to obtain. Training and deploying deep learning models is computationally intensive, necessitating powerful GPUs and substantial memory, which can drive up costs and environmental impact. Deep neural networks are often criticized for their \"black box\" nature, as their complex architectures obscure the rationale behind predictions, complicating efforts to ensure fairness, accountability, and regulatory compliance. There is also a heightened risk of overfitting, especially with limited or non-diverse datasets, and developing, tuning, and deploying these models demands specialized expertise. Additionally, if training data contains biases, deep learning models can perpetuate or amplify these biases, raising ethical and societal concerns [5][6][7][8].\n",
       "\n",
       "### 4.3 Generative AI\n",
       "\n",
       "Generative AI—encompassing models like generative adversarial networks (GANs) and large language models (LLMs)—has enabled transformative applications in content creation, design, and scientific discovery. Generative AI can synthesize new text, images, and audio, augment datasets, and power advanced tools such as chatbots and design assistants. These capabilities are driving innovation in creative and scientific fields, offering new ways to approach problem-solving and data augmentation [9][10][11][12].\n",
       "\n",
       "Despite these advances, generative AI is constrained by several critical limitations. The quality and fairness of its outputs are directly tied to the data it is trained on; biases or inaccuracies in training data can lead to biased or misleading outputs. Generative AI models do not possess true understanding or reasoning, instead relying on statistical patterns, which can result in the generation of factually incorrect or fabricated information—a phenomenon known as \"hallucination.\" These models are also resource-intensive, requiring substantial computational power for both training and inference, which can be costly and environmentally taxing. The ease with which generative AI can create deepfakes, fake news, or plagiarized content raises profound ethical and legal questions, necessitating robust guidelines and safeguards. Furthermore, generative AI often struggles to generalize to domains significantly different from its training data and lacks the genuine creativity and contextual awareness of human creators [9][10][11][12].\n",
       "\n",
       "### 4.4 Scalability, Interpretability, and Deployment Challenges\n",
       "\n",
       "Scalability and interpretability present additional axes for comparison. Linear and logistic regression, as well as decision trees, offer high interpretability but may not scale effectively to complex, high-dimensional data. Ensemble methods like random forests and gradient boosting machines improve scalability but at the cost of transparency, while deep neural networks offer unmatched scalability and accuracy on large, unstructured datasets but are typically opaque. The trade-off between scalability and interpretability is a central consideration in model selection, particularly in applications where trust, explainability, and regulatory compliance are paramount.\n",
       "\n",
       "Deployment challenges are common across all AI paradigms. Models must be monitored for drift as data distributions evolve, integrated seamlessly into production environments, and continuously updated to maintain performance. Regulatory and ethical compliance is increasingly important, especially as AI systems are deployed in sensitive or high-stakes domains [13][14][15][16].\n",
       "\n",
       "#### Table 3: Comparative Advantages and Limitations\n",
       "\n",
       "| Approach        | Advantages                                   | Limitations                                  |\n",
       "|-----------------|----------------------------------------------|----------------------------------------------|\n",
       "| Classical ML    | Interpretability, efficiency, small data     | Limited expressiveness, manual features      |\n",
       "| Deep Learning   | Automatic features, unstructured data, scale | Data/computation intensive, black-box        |\n",
       "| Generative AI   | Content creation, data augmentation          | Bias, hallucination, resource/ethical issues |\n",
       "\n",
       "## 5. Relationships and Overlaps Between Approaches\n",
       "\n",
       "The relationship between classical machine learning, deep learning, and generative AI is best understood as a nested hierarchy within the broader field of artificial intelligence, with each approach building upon the foundations of its predecessor and extending the range of solvable problems and applications.\n",
       "\n",
       "### 5.1 Hierarchical Structure and Conceptual Overlap\n",
       "\n",
       "At the highest level, AI encompasses all techniques that enable computers to mimic human intelligence, including rule-based systems, expert systems, and learning algorithms. Classical machine learning refers to a set of algorithms—such as decision trees, support vector machines (SVMs), logistic regression, and k-nearest neighbors—that learn patterns from data to make predictions or classifications. A defining characteristic of classical ML is the reliance on manual feature engineering: domain experts must select and preprocess the most relevant data characteristics for the model to learn from. This approach is particularly effective for structured data (e.g., tabular datasets) and smaller sample sizes, where statistical methods can efficiently identify relationships. However, classical ML struggles with unstructured data types such as images, audio, and natural language, and with modeling highly complex, nonlinear relationships [1][2][3][4].\n",
       "\n",
       "Deep learning is a specialized subfield of machine learning that uses artificial neural networks with multiple layers—hence the term \"deep.\" These deep neural networks are capable of automatically learning hierarchical representations and complex features directly from raw data, significantly reducing the need for manual feature engineering. Deep learning excels at processing unstructured data, such as images, speech, and text, and has driven major advances in fields like computer vision and natural language processing. However, deep learning models require large volumes of data and substantial computational resources to achieve their superior performance. Despite these differences, both classical ML and deep learning share foundational principles, such as learning from data, optimizing parameters, and improving performance through experience [5][6][7][8].\n",
       "\n",
       "Generative AI represents a further specialization within deep learning. It encompasses models designed to generate new data instances that resemble the training data, such as realistic images, coherent text, or synthetic audio. Key technologies in this area include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and large language models (LLMs) like GPT. Generative AI models are built upon deep learning architectures and leverage advances like transformers and adversarial training to create highly realistic and creative outputs. While all generative AI models are deep learning models, not all deep learning models are generative; many are discriminative, focusing on classification or detection tasks [9][10][11][12].\n",
       "\n",
       "### 5.2 Practical Synergies and Hybridization\n",
       "\n",
       "The overlaps and relationships between these approaches are both conceptual and practical. Deep learning automates the feature extraction process that is manual in classical ML, enabling the modeling of more complex, high-dimensional data. Generative AI, in turn, extends deep learning from analysis and prediction to content creation. There is also a practical synergy: generative AI can create synthetic data to augment training datasets for classical ML or deep learning models, particularly when real data is scarce. Conversely, predictive models from classical ML or deep learning can be used to guide or evaluate generative processes.\n",
       "\n",
       "This progression—from classical ML to deep learning to generative AI—reflects a technological continuum. Classical ML established core concepts like supervised and unsupervised learning, which remain foundational in DL and GenAI. Deep learning emerged to address classical ML's limitations with unstructured data, and generative AI further extends these capabilities to the creation of new, original content. All three approaches use core machine learning principles such as optimization, loss functions, and data-driven learning, but differ in their technical implementations, data requirements, and end goals [13][14][15][16].\n",
       "\n",
       "#### Figure 1: Hierarchical Breakdown of AI Paradigms\n",
       "\n",
       "```\n",
       "Artificial Intelligence\n",
       "├── Machine Learning (ML)\n",
       "│   ├── Classical ML\n",
       "│   └── Deep Learning (DL)\n",
       "│       └── Generative AI (GenAI)\n",
       "```\n",
       "\n",
       "### 5.3 Integrated Application and Future Directions\n",
       "\n",
       "In summary, while classical machine learning, deep learning, and generative AI have distinct methodologies and strengths, they are deeply interconnected. Advances in one area often benefit the others, and in modern AI applications, these approaches are frequently combined to leverage their respective advantages. The taxonomy can be visualized as AI ⊇ ML ⊇ DL ⊇ GenAI, with each subset inheriting and extending the capabilities of its parent, and with significant overlap in techniques, principles, and practical use cases. This layered relationship enables AI systems to tackle an ever-broader array of complex, real-world problems, from structured data analysis to the generation of novel content [13][14][15][16].\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The comparative analysis of classical machine learning, deep learning, and generative AI reveals a rich tapestry of methodologies, technical architectures, and application domains. Classical ML remains indispensable for structured data and interpretable models, offering efficiency and transparency in regulated industries. Deep learning has unlocked new possibilities in perception and language, automating feature extraction and excelling with unstructured data at scale. Generative AI is pioneering the frontier of creative and synthetic intelligence, enabling the generation of new content and transforming workflows across industries. Each paradigm carries inherent advantages and limitations, shaped by data requirements, scalability, interpretability, and ethical considerations. Their relationships are best understood as a continuum, with each approach building upon and extending the capabilities of its predecessors. As AI continues to evolve, the integration and hybridization of these paradigms will drive further innovation, expanding the boundaries of what is possible in artificial intelligence.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] Artificial Intelligence (AI), Machine Learning (ML) & Deep Learning (DL ... https://ieeexplore.ieee.org/document/10625198\n",
       "[2] What is deep learning? | How deep learning works - Cloudflare https://www.cloudflare.com/learning/ai/what-is-deep-learning/\n",
       "[3] 13 foundational AI courses, resources from MIT | Open Learning https://openlearning.mit.edu/news/13-foundational-ai-courses-resources-mit\n",
       "[4] Learning Paradigms in AI | Accenture https://www.accenture.com/us-en/blogs/data-ai/learning-paradigms-ai\n",
       "[5] Classical Machine Learning: Seventy Years of Algorithmic Learning Evolution https://arxiv.org/abs/2408.01747\n",
       "[6] Deep Learning: A Comprehensive Overview on Techniques, Taxonomy ... https://link.springer.com/article/10.1007/s42979-021-00815-1\n",
       "[7] What is Generative AI? - IBM https://www.ibm.com/think/topics/generative-ai\n",
       "[8] Foundations of Deep Learning - SpringerLink https://link.springer.com/book/10.1007/978-981-16-8233-9\n",
       "[9] Generative AI: What Is It, Tools, Models, Applications and ... - Gartner https://www.gartner.com/en/topics/generative-ai\n",
       "[10] Understanding Machine Learning Principles: Learning, Inference ... - MDPI https://www.mdpi.com/2227-7390/13/3/451\n",
       "[11] Deep Learning Definition | DeepAI https://deepai.org/machine-learning-glossary-and-terms/deep-learning\n",
       "[12] Machine Learning and Deep Learning Paradigms: From Techniques to ... - MDPI https://www.mdpi.com/2073-431X/14/3/93\n",
       "[13] What Is Deep Learning? - IBM https://www.ibm.com/think/topics/deep-learning\n",
       "[14] Generative artificial intelligence - Wikipedia https://en.wikipedia.org/wiki/Generative_artificial_intelligence\n",
       "[15] [2106.10165] The Principles of Deep Learning Theory - arXiv.org https://arxiv.org/abs/2106.10165\n",
       "[16] What is the difference between traditional vs generative AI ... https://www.servicenow.com/ai/what-is-the-difference-between-traditional-vs-generative-ai.html\n",
       "[17] What is a Generative Model? - DataCamp https://www.datacamp.com/blog/what-is-a-generative-model\n",
       "[18] Traditional AI vs Generative AI vs Agentic AI - ML Journey https://mljourney.com/traditional-ai-vs-generative-ai-vs-agentic-ai/\n",
       "[19] Generative AI vs Traditional AI - GeeksforGeeks https://www.geeksforgeeks.org/difference-between-generative-ai-and-traditional-ai/\n",
       "[20] Generative AI vs. Traditional Machine Learning: What's the ... - LinkedIn https://www.linkedin.com/pulse/generative-ai-vs-traditional-machine-learning-whats-shrivastava\n",
       "[21] Generative Models Explained: VAEs, GANs, Diffusion, Transformers ... https://bestarion.com/generative-models-explained-vaes-gans-diffusion-transformers-autoregressive-models-nerfs/\n",
       "[22] Technology Foundations of Generative AI: Architectures ... - PwC https://www.pwc.de/en/digitale-transformation/generative-ai-artificial-intelligence/the-genai-building-blocks/technology-foundations-of-generative-ai-architectures-algorithms-and-innovations.html\n",
       "[23] Comparing Diffusion, GAN, and VAE Techniques - Generative AI Lab https://generativeailab.org/l/generative-ai/a-tale-of-three-generative-models-comparing-diffusion-gan-and-vae-techniques/569/\n",
       "[24] Generative Models in AI: A Comprehensive Comparison of GANs and VAEs ... https://www.geeksforgeeks.org/generative-models-in-ai-a-comprehensive-comparison-of-gans-and-vaes/\n",
       "[25] A Comprehensive Overview and Comparative Analysis on Deep https://arxiv.org/pdf/2305.17473\n",
       "[26] Modern AI: GenAI vs Machine Learning vs Deep Learning vs LLMs - Cloud4C https://www.cloud4c.com/blogs/genai-vs-machine-learning-vs-deep-learning-vs-llms\n",
       "[27] A Comprehensive Review of Deep Learning: Architectures, Recent ... - MDPI https://www.mdpi.com/2078-2489/15/12/755\n",
       "[28] Diffusion Models vs. GANs vs. VAEs: Comparison of Deep Generative ... https://towardsai.net/p/generative-ai/diffusion-models-vs-gans-vs-vaes-comparison-of-deep-generative-models\n",
       "[29] Application of classical and advanced machine learning models to ... https://www.sciencedirect.com/science/article/pii/S0957417422025179\n",
       "[30] Classic Machine Learning Methods - SpringerLink https://link.springer.com/protocol/10.1007/978-1-0716-3195-9_2\n",
       "[31] Introducing AI Max for Search campaigns - The Keyword https://blog.google/products/ads-commerce/google-ai-max-for-search-campaigns/\n",
       "[32] Semrush Report: AI Overviews’ Impact on Search in 2025 https://www.semrush.com/blog/semrush-ai-overviews-study/\n",
       "[33] 20 Examples of Generative AI Applications Across Industries https://www.coursera.org/articles/generative-ai-applications\n",
       "[34] Generative AI Use Cases Across Industries | Gartner https://www.gartner.com/en/articles/generative-ai-use-cases\n",
       "[35] 21 Generative AI Examples and its Applications Across Industries https://whatsthebigdata.com/generative-ai-examples/\n",
       "[36] Top 120 Generative AI Applications with Real-Life Examples - AIMultiple https://research.aimultiple.com/generative-ai-applications/\n",
       "[37] Top Generative AI Industry Applications & Use Cases - Turing https://www.turing.com/resources/generative-ai-applications\n",
       "[38] Challenges and Emerging Issues for Generative AI and Hyper Intelligence ... https://ieeexplore.ieee.org/document/10795737\n",
       "[39] AI Mode in Google Search: Updates from Google I/O 2025 - The Keyword https://blog.google/products/search/google-search-ai-mode-update/\n",
       "[40] On the Challenges and Opportunities in Generative AI - arXiv.org https://arxiv.org/html/2403.00025v1\n",
       "[41] ML and AI Model Explainability and Interpretability - Analytics Vidhya https://www.analyticsvidhya.com/blog/2025/01/explainability-and-interpretability/\n",
       "[42] Machine Learning Interpretability: A Survey on Methods and Metrics - MDPI https://www.mdpi.com/2079-9292/8/8/832\n",
       "[43] Semrush Report: AI Overviews’ Impact on Search in 2025 https://www.semrush.com/blog/semrush-ai-overviews-study/\n",
       "[44] Challenges with developing and deploying AI models and applications in ... https://link.springer.com/article/10.1007/s44163-024-00151-2\n",
       "[45] Decoding the AI Search Flow: From User Query to ... - ServiceNow https://www.servicenow.com/community/now-assist-articles/decoding-the-ai-search-flow-from-user-query-to-intelligent/ta-p/3259475\n",
       "[46] Pros and Cons of Various Machine Learning Models: A Comparison https://machinelearningmodels.org/pros-and-cons-of-various-machine-learning-models-a-comparison/\n",
       "[47] Overcoming Challenges in Deploying Large Language Models for Generative ... https://ijcttjournal.org/2024/Volume-72%20Issue-2/IJCTT-V72I2P114.pdf\n",
       "[48] What is generative AI? - IBM Research https://research.ibm.com/blog/what-is-generative-AI\n",
       "[49] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks - IBM https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
       "[50] Tracing the evolution of AI in the past decade and forecasting the ... https://www.sciencedirect.com/science/article/pii/S0957417422013732\n",
       "[51] Deep Learning vs Classical Machine Learning: The Key Differences https://techimpo.com/deep-learning-vs-classical-machine-learning/\n",
       "[52] Generative Artificial Intelligence: Fundamentals and Evolution - Springer https://link.springer.com/chapter/10.1007/978-981-97-8460-8_1\n",
       "[53] Gen AI vs Machine Learning vs Deep Learning - DataSpace Academy https://dataspaceacademy.com/blog/genai-vs-machine-learning-vs-deep-learning-a-comparative-study\n",
       "[54] The Evolution of AI Architecture: From Traditional Machine Learning to ... https://aimresearch.co/generative-ai/the-evolution-of-ai-architecture-from-traditional-machine-learning-to-generative-ai\n",
       "[55] AI, ML, DL, and Generative AI Face Off: A Comparative Analysis https://synoptek.com/insights/it-blogs/data-insights/ai-ml-dl-and-generative-ai-face-off-a-comparative-analysis/\n",
       "[56] When to Use GenAI Versus Predictive AI - MIT Sloan Management Review https://sloanreview.mit.edu/article/when-to-use-genai-versus-predictive-ai/\n",
       "[57] What is artificial intelligence, machine learning, and deep learning ... https://www.sciencedirect.com/science/article/pii/B9780443221323000022\n",
       "[58] Machine learning and generative AI: What are they good for in 2025? https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-and-generative-ai-what-are-they-good-for\n",
       "[59] Deep Learning vs. Machine Learning: A Beginner’s Guide https://www.coursera.org/articles/ai-vs-deep-learning-vs-machine-learning-beginners-guide\n",
       "[60] Unveiling the evolution of generative AI (GAI): a comprehensive and ... https://jesit.springeropen.com/articles/10.1186/s43067-024-00145-1\n",
       "[61] Understanding Artificial Intelligence Hierarchy: How AI, ML, Gen AI ... https://devblogit.com/understanding-artificial-intelligence-ai-hierarchy\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(research_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Workflow Visualization\n",
    "\n",
    "Below we can see the detailed steps in the research and review process, showing how the ResearchAgent and PeerReviewAgent collaborated to produce the final report. This visualization helps us understand how many iterations were required to meet quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 AGENT WORKFLOW: 'Create an exceptionally comprehensive, **paragraph-focused** and detailed research report using the following content. **Minimize bullet points** and ensure the final text resembles a cohesive, academic-style paper:\n",
      "\n",
      "{\n",
      "  \"objective\": \"To comprehensively compare and contrast classical machine learning, deep learning, and generative AI, examining their underlying principles, methodologies, applications, advantages, limitations, and interrelationships.\",\n",
      "  \"aggregated_summaries\": [\n",
      "    {\n",
      "      \"subtopic\": \"Definitions and Foundations of Each Approach\",\n",
      "      \"summary\": \"Acknowledge: The following synthesis integrates information from multiple search results to provide a unified, comprehensive summary of the definitions and foundational principles underlying classical machine learning, deep learning, and generative AI.\\n\\n---\\n\\n## Key Insights\\n- **Classical machine learning is grounded in statistical theory, relies on explicit feature engineering, and employs well-understood algorithms f'\n",
      "\n",
      "\n",
      "================================================================================\n",
      "👤 AGENT: ResearchAgent\n",
      "--------------------------------------------------------------------------------\n",
      "  💬 OUTPUT: {\"objective\":\"To comprehensively compare and contrast classical machine learning, deep learning, ...\n",
      "\n",
      "================================================================================\n",
      "🏁 FINAL OUTPUT:\n",
      "--------------------------------------------------------------------------------\n",
      "# Comparative Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Principles, Methodologies, Applications, and Interrelationships\n",
      "\n",
      "## Introduction\n",
      "\n",
      "The field of artificial intell...\n"
     ]
    }
   ],
   "source": [
    "from common.helper import pretty_print_agent_workflow\n",
    "pretty_print_agent_workflow(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson-deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
