{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search & Scraping**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow now includes a dedicated scraping phase for extracting and cleaning web content:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Web Content Scraping** - Extracting, cleaning, and filtering relevant content from web pages using a ScraperAgent\n",
    "4. **Content Analysis** - Summarizing scraped results and extracting key insights\n",
    "5. **Report Generation** - Creating detailed research reports with proper citations\n",
    "6. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- WebScraperAgent - Extracts, cleans, and filters relevant content from web pages\n",
    "- SummaryAgent - Extracts key insights from scraped content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Projects, and the OpenAI Agents SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Azure OpenAI to work with OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents import (\n",
    "    set_default_openai_client,\n",
    "    set_tracing_disabled,\n",
    "    OpenAIChatCompletionsModel\n",
    ")\n",
    "\n",
    "# setup settings\n",
    "from openai import AsyncAzureOpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Use the synchronous client instead of the async one\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AOAI_KEY\"),\n",
    "    api_version=os.environ.get(\"AOAI_API_VERSION\", \"2024-02-01\")\n",
    ")\n",
    "\n",
    "# Configure SDK\n",
    "set_default_openai_client(openai_client)\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "reasoningModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"reasoningModel\"), \n",
    "    openai_client=openai_client\n",
    ")\n",
    "\n",
    "chatModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    openai_client=openai_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models for Research Workflow\n",
    "\n",
    "The following Pydantic models define the structured data used throughout our research process:\n",
    "\n",
    "1. **ResearchTask** - Represents an individual research task with specific search queries\n",
    "2. **ResearchPlan** - Contains the overall plan with research objectives and tasks\n",
    "3. **Citation** - Stores source information for proper attribution\n",
    "4. **ComprehensiveResearchReport** - Defines the structure of the final research output\n",
    "5. **PeerReviewFeedback** - Contains structured feedback on report quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResearchTask(BaseModel):\n",
    "    id: Optional[str] = Field(None, description=\"Unique identifier for the task\")\n",
    "    subtopic: str = Field(..., description=\"Subtopic to research\")\n",
    "    search_queries: List[str] = Field(..., description=\"List of search queries to explore this subtopic\")\n",
    "    completed: bool = Field(..., description=\"Status of task completion\")\n",
    "\n",
    "class ResearchPlan(BaseModel):\n",
    "    query: str = Field(..., description=\"The original user query that prompted this research\")\n",
    "    objective: str = Field(..., description=\"The overall research objective, clearly defined\")\n",
    "    success_criteria: List[str] = Field(..., description=\"Criteria to determine when the research is sufficiently complete.\")\n",
    "    related_topics: List[str] = Field(..., description=\"List of related topics that may be useful for the research.\")\n",
    "    research_tasks: List[ResearchTask] = Field(..., description=\"List of specific research tasks to complete. Each task focuses on a subtopic.\")\n",
    "\n",
    "class ScrapedWebPage(BaseModel):\n",
    "    url: str = Field(..., description=\"The original URL that was scraped\")\n",
    "    title: Optional[str] = Field(None, description=\"The page title (if available, else None)\")\n",
    "    main_content: Optional[str] = Field(None, description=\"The main textual content of the page, cleaned and potentially truncated (if available, else None)\")\n",
    "    source: Optional[str] = Field(None, description=\"The name of the source (if available, else None)\")\n",
    "    published_date: Optional[str] = Field(None, description=\"YYYY-MM-DD (if available, else None)\")\n",
    "    scrape_error: Optional[str] = Field(None, description=\"Error message if scraping failed, else None\")\n",
    "    # Fields below might be added by the agent based on instructions, not the tool directly\n",
    "    extraction_method: Optional[str] = Field(None, description=\"How content was extracted (e.g., 'tool_extracted', 'agent_filtered')\") \n",
    "    relevance_score_agent: Optional[float] = Field(None, description=\"Agent's assessment of relevance (0-10)\")\n",
    "    matched_sections: Optional[List[str]] = Field(None, description=\"Sections identified by the agent as relevant\")\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "\n",
    "class ComprehensiveResearchReport(BaseModel):\n",
    "    objective: str = Field(..., description=\"The original research objective\")\n",
    "    research_report: str = Field(..., description=(\n",
    "        \"Comprehensive research report in markdown. \"\n",
    "        \"It should be structured with meaningful headings and subsections, but emphasize **fully-developed paragraphs**. \"\n",
    "        \"It should be long and detailed, and it should fully addresses the objectives, \"\n",
    "        \"and the various subtopics required to achieve the success criteria. \"\n",
    "        \"Use bullet points or lists **only** when they genuinely improve clarity (e.g., summarizing key data). \"\n",
    "        \"Tables and other data visualizations are encouraged. \"\n",
    "        \"The research report should always be long and detailed.\\n\\n\" \n",
    "        \"For citations, please use the IEEE (Institute of Electrical and Electronics Engineers). \"\n",
    "        \"How it works:\\n\\n\"\n",
    "        \"   1. In the text, use numbered citations in brackets [1].\\n\"\n",
    "        \"   2. At the end of the report, provide a list of citations in the format \"\n",
    "        \"(the list should ONLY contain the sources used in the free text of the research report. \"\n",
    "        \"Do NOT list sources which are not cited in the free text of the research report.):\\n\\n\"\n",
    "        \"       [1] Title of the source, URL.\"\n",
    "    ))\n",
    "    citations: List[Citation] = Field(..., description=(\n",
    "        \"List of citations (title and URL), corresponding to references actually used in research_report. \"\n",
    "        \"Do not add references that are not cited within the text.\"\n",
    "    ))\n",
    "    identified_gaps: Optional[List[str]] = Field(default=None, description=\"Identified information gaps.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Suggestions for additional research.\")\n",
    "\n",
    "class PeerReviewFeedback(BaseModel):\n",
    "    overall_feedback: str = Field(..., description=\"General feedback on the report.\")\n",
    "    strengths: List[str] = Field(..., description=\"Aspects of the report that are well done.\")\n",
    "    suggested_improvements: List[str] = Field(..., description=\"Specific suggestions to improve clarity, completeness, accuracy, or structure.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Additional research queries that could strengthen the report.\")\n",
    "    is_satisfactory: bool = Field(..., description=\"Indicates if the report meets all quality standards and no further revisions are needed.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "The research workflow is powered by two types of agents:\n",
    "\n",
    "1. **Azure AI Agents** - Created using Azure AI Projects for web search capabilities\n",
    "2. **OpenAI Agents** - For specialized research tasks\n",
    "\n",
    "Let's configure each type of agent with their specific instructions and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will ***create*** an **Azure AI Agent**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import BingGroundingTool\n",
    "\n",
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bing_connection = project_client.connections.get(\n",
    "    name=os.getenv(\"BING_CONNECTION_NAME\")\n",
    ")\n",
    "\n",
    "bing_tool = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "bing_search_agent = project_client.agents.create_agent(\n",
    "    name=\"bingSearchAgent\",\n",
    "    description=\"Agent to perform web searches using Bing.\",\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    temperature=0.5,\n",
    "    tools=bing_tool.definitions,\n",
    "    instructions=f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "    \"\"\".strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have an Azure AI Agent, run this cell to update it's instructions with today's date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful research assistant.\n",
      "\n",
      "Today's date is 2025-06-03.\n",
      "\n",
      "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
      "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
      "Provide a comprehensive answer based on the search results.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "bing_search_agent.instructions = f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(bing_search_agent.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenAI Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    Agent,\n",
    "    ModelSettings\n",
    ")\n",
    "\n",
    "from common.utils_scraping import scrape_web_page\n",
    "\n",
    "chatModelSettings=ModelSettings(\n",
    "        max_tokens=32768,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "\n",
    "    You are an expert research planner specializing in creating detailed research plans your task is to analyze a user's research query and create a structured research plan.\n",
    "    with the following components:\n",
    "    \n",
    "    1. DOMAIN CLASSIFICATION:\n",
    "       Classify the query into a fitting domain (e.g., technology, business, etc.).\n",
    "       The Domain is not included in the output, but it is important for the other components in the research plan.\n",
    "       The domain should be a single word (e.g., technology, business, etc.).\n",
    "       \n",
    "    2. RESEARCH OBJECTIVE:\n",
    "       Create a clear, comprehensive objective statement for the research\n",
    "       \n",
    "    3. SUBTOPICS:\n",
    "       Generate relevant subtopics that should be explored to thoroughly answer the query (Important. generate no less than 4 subtopics)\n",
    "       \n",
    "    4. SEARCH QUERIES:\n",
    "       For each subtopic, provide search queries that will yield valuable results (Important. It's better to generate more queries than less queries, but at least 2 queries per subtopic)\n",
    "       \n",
    "    5. SUCCESS CRITERIA:\n",
    "       List the criteria that will determine when the research is complete (Important. generate no less than 4 success criteria)\n",
    "       Take all of the above into account (e.g., the domain, objective, subtopics, and search queries) to create the success criteria.\n",
    "       \n",
    "    6. RELATED TOPICS:\n",
    "       suggest related topics that may be useful for the research (Important. generate no less than 3 related topics)\n",
    "    \n",
    "    Ensure each subtopic is thorough and directly relevant to the research query.\n",
    "    The search queries should be specific enough to return high-quality results.\n",
    "    \"\"\".strip(),\n",
    "    model=chatModel,\n",
    "    output_type=ResearchPlan,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "web_scraper_agent = Agent(\n",
    "    name=\"WebScraperAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "    \n",
    "    You are a robust, context-aware web scraping specialist. Your primary tool is 'scrape_web_page'.\n",
    "\n",
    "    Your input is a JSON string containing: 'url', 'subtopic', 'user_query', 'search_result_title', 'visited_urls', and 'max_content_length'. Parse this JSON to get the necessary information.\n",
    "\n",
    "    **Workflow:**\n",
    "    1.  **Parse Input:** Extract 'url', 'user_query', 'subtopic', 'search_result_summary', and 'max_content_length' from the input JSON string.\n",
    "    2.  **Call Scraping Tool:** Call the `scrape_web_page` tool with the 'url' and 'max_content_length'.\n",
    "    3.  **Analyze Tool Output:** Receive the dictionary from the tool containing `url`, `title`, `main_content`, `source`, `published_date`, `scrape_error`.\n",
    "    4.  **Contextual Filtering (If Content Exists and No Error):**\n",
    "        - If `scrape_error` is None and `main_content` exists:\n",
    "            - Review the `main_content`.\n",
    "            - Use the `user_query`, `subtopic`, and `search_result_summary` to identify ONLY the most relevant paragraphs or sections.\n",
    "            - If the entire `main_content` seems relevant or is short, keep it all.\n",
    "            - If filtering, replace `main_content` with ONLY the relevant extracted parts. Set `extraction_method` to 'agent_filtered'.\n",
    "            - Estimate a `relevance_score_agent` (0-10).\n",
    "            - Optionally list `matched_sections`.\n",
    "        - If `scrape_error` is present, ensure the `scrape_error` field in your output reflects the tool's error.\n",
    "    5.  **Format Output:** Return a SINGLE JSON object matching the `ScrapedWebPage` Pydantic model, including all fields based on the tool's output and your filtering. If the tool failed, `main_content` should be None/empty, and `scrape_error` should be set.\n",
    "    6.  **Return JSON object:** Return ONLY the final object formatted as a single, valid JSON. Do NOT add any explanatory text before or after the JSON.\n",
    "\n",
    "    **Constraints:**\n",
    "    - Your final output MUST be ONLY a valid JSON representing the scraped and processed data.\n",
    "    - Adhere strictly to the field names defined in the conceptual `ScrapedWebPage` structure when creating the JSON.\n",
    "    - Prioritize accuracy and relevance based on the provided context.\n",
    "    \"\"\",\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    tools=[scrape_web_page],\n",
    "    output_type=ScrapedWebPage\n",
    ")\n",
    "\n",
    "summary_agent = Agent(\n",
    "    name=\"SummaryAgent\",\n",
    "    instructions=(\n",
    "        \"You are a comprehensive research summarization specialist. Your task is to **synthesize information from combined search result content** related to a specific subtopic (which will be mentioned in the input prompt). \"\n",
    "        \"Create a **single, coherent, detailed, and information-rich summary** that:\\n\\n\"\n",
    "        \"1. Extracts ALL important facts, statistics, findings, and insights **relevant to the specified subtopic** from the combined text.\\n\"\n",
    "        \"2. Preserves specific numbers, percentages, dates, and technical details whenever present.\\n\"\n",
    "        \"3. Includes industry-specific terminology and concepts that add depth to the research.\\n\"\n",
    "        \"4. **Synthesizes** the key arguments and conclusions from the provided sources. If sources present different perspectives or data, try to capture that nuance.\\n\"\n",
    "        \"5. Provides thorough explanations rather than superficial overviews, integrating information smoothly.\\n\"\n",
    "        \"6. For technical content, preserves methodologies, technical specifications, and implementation details.\\n\"\n",
    "        \"7. For comparative content, maintains all sides of the comparison with their specific attributes.\\n\\n\"\n",
    "\n",
    "        \"**Acknowledge that the input combines information potentially from multiple search results.** Your goal is to create a unified summary focused on the overall subtopic, not just list summaries of individual parts.\\n\\n\"\n",
    "\n",
    "        \"Remember that your summary serves as the foundation for generating a comprehensive research report. The quality and depth of the final research report depends directly on how comprehensive and well-synthesized your summary is. Ensure it captures the essence of all provided content relevant to the subtopic.\\n\\n\"\n",
    "\n",
    "        \"FORMAT YOUR SUMMARY AS:\\n\"\n",
    "        \"## Key Insights\\n\"\n",
    "        \"- [Most critical takeaway #1]\\n\"\n",
    "        \"- [Most critical takeaway #2]\\n\"\n",
    "        \"- [Most critical takeaway #3]\\n\"\n",
    "        \"- [Optional: Most critical takeaway #4]\\n\\n\"\n",
    "        \"## Extensive Synthesis\\n\"\n",
    "        \"Write a thorough, multi-paragraph synthesis that:\\n\"\n",
    "        \"- Integrates all important facts, statistics, findings, and insights relevant to the subtopic.\\n\"\n",
    "        \"- Preserves specific numbers, percentages, dates, and technical details.\\n\"\n",
    "        \"- Explains methodologies, technical specifications, and implementation details where relevant.\\n\"\n",
    "        \"- Highlights agreements, disagreements, and nuances between sources.\\n\"\n",
    "        \"- Uses industry-specific terminology and concepts.\\n\"\n",
    "        \"- Provides context, background, and implications for the findings.\\n\"\n",
    "        \"- Maintains logical flow: start with an overview, then go into specifics, and conclude with implications or open questions.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    output_type=str,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    instructions=(\n",
    "        \"## General Instructions\\n\"\n",
    "        \"You are a meticulous research analyst specializing in creating **long, comprehensive, authoritative** reports. \"\n",
    "        \"Your goal is to produce **in-depth, highly detailed** content that thoroughly analyzes all aspects of the research topic. \"\n",
    "        \"Furthermore, you must also demonstrate subject matter expertise with nuanced insights, technical details, and sophisticated analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Style & Format:\\n\"\n",
    "        \"- **Default to paragraphs.** Present your findings in cohesive, well-structured paragraphs rather than excessive bullet points.\\n\"\n",
    "        \"- **Use bullet points sparingly.** Only use them when they add genuine clarity—e.g., summarizing key data.\\n\"\n",
    "        \"- **Structure** the report with a clear hierarchy, but avoid excessive nesting. Aim for a balanced structure:\\n\"\n",
    "        \"   - Use main sections and occasional subsections where needed.\\n\"\n",
    "        \"   - Avoid over-fragmentation by limiting sub-subsections unless absolutely necessary.\\n\"\n",
    "        \"   - Favor broader thematic groupings to maintain narrative flow and reduce section clutter.\\n\"\n",
    "        \"   - With that said, if a subtopic would benefit from a sub-subsection, feel free to add it.\\n\"\n",
    "        \"- **Data visualizations** (e.g., tables, charts, diagrams) in Markdown are encouraged wherever they enhance understanding.\\n\"\n",
    "        \"- Maintain a logical, flowing structure so each subsection builds upon the prior sections.\\n\"\n",
    "        \"- **Citations:** Use IEEE style: [1], [2], etc. Provide a 'References' section at the end of your report with only the sources cited in the text.\\n\\n\"\n",
    "        \n",
    "        \"### Long & Comprehensive Requirement:\\n\"\n",
    "        \"- The final report must be the equivalent of **10 to 12 pages** of substantive text, approximately **7000-9000 words**.\\n\"\n",
    "        \"- Each major section should have **extensive exploration** (ideally 800-1000 words per section).\\n\"\n",
    "        \"- Ensure thorough coverage of the topic with **well-developed paragraphs**, plenty of detail, and rigorous analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Depth Requirements:\\n\"\n",
    "        \"- Include **quantitative data**, statistics, and specific examples to support your arguments.\\n\"\n",
    "        \"- Compare and contrast **multiple perspectives** on complex topics.\\n\"\n",
    "        \"- Integrate ideas across sections for a cohesive, synthesized analysis rather than isolated observations.\\n\\n\"\n",
    "        \n",
    "        \"### Workflow\\n\"\n",
    "        \"- When given the research objective and content, develop a **long-form narrative** with detailed explanations.\\n\"\n",
    "        \"- If PeerReviewAgent provides feedback, revise thoroughly, addressing all points.\\n\"\n",
    "        \"- Once feedback is marked satisfactory, present the final report.\\n\\n\"\n",
    "        \n",
    "        \"### Important Guidelines\\n\"\n",
    "        \"- Retain high-quality content in any revision.\\n\"\n",
    "        \"- If feedback highlights missing info, propose specific research queries.\\n\"\n",
    "        \"- Avoid unnecessary repetition.\\n\\n\"\n",
    "\n",
    "        \"**REMINDER**:\"\n",
    "        \"Your output should be a single, cohesive Markdown document that reads like a well-developed academic or professional paper, with minimal use of bullet points. \"\n",
    "        \"Prefer broader thematic sections over excessive fragmentation. \"\n",
    "        \"Sub-subsections may be used where helpful, but structure should remain balanced and readable. \"\n",
    "        \"Lastly, do not forget to include the references section at the end of the report.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=ComprehensiveResearchReport,\n",
    ")\n",
    "\n",
    "\n",
    "peer_review_agent = Agent(\n",
    "    name=\"PeerReviewAgent\",\n",
    "    instructions=(\n",
    "        \"You are a critical yet constructive peer reviewer evaluating research reports. \"\n",
    "        \"Your goal is to provide detailed, actionable feedback using a structured evaluation framework.\\n\\n\"\n",
    "        \n",
    "        \"## Evaluation Framework:\\n\"\n",
    "        \"1. COMPLETENESS (0-10): Does the report thoroughly cover all aspects of the research topic?\\n\"\n",
    "        \"   - Are all required subtopics adequately addressed?\\n\"\n",
    "        \"   - Is there sufficient depth in each section (500+ words per major section)?\\n\"\n",
    "        \"   - Are there any obvious gaps or missing perspectives?\\n\\n\"\n",
    "        \n",
    "        \"2. CLARITY & STRUCTURE (0-10): Is the report well-organized and clearly written?\\n\"\n",
    "        \"   - Does it have a logical flow with clear sections and subsections?\\n\"\n",
    "        \"   - Are complex concepts explained in accessible language?\\n\"\n",
    "        \"   - Does it use formatting effectively (headings, lists, tables)?\\n\\n\"\n",
    "        \n",
    "        \"3. EVIDENCE & SUPPORT (0-10): Is information well-supported?\\n\"\n",
    "        \"   - Are claims backed by data, statistics, or authoritative sources?\\n\"\n",
    "        \"   - Are citations used appropriately and consistently?\\n\"\n",
    "        \"   - Does it include multiple perspectives when appropriate?\\n\\n\"\n",
    "        \n",
    "        \"4. ANALYSIS & INSIGHT (0-10): Does the report provide valuable analysis?\\n\"\n",
    "        \"   - Does it go beyond summarizing to provide meaningful insights?\\n\"\n",
    "        \"   - Does it connect ideas across different sections?\\n\"\n",
    "        \"   - Does it identify implications and future directions?\\n\\n\"\n",
    "        \n",
    "        \"## Response Guidelines:\\n\"\n",
    "        \"- For each criterion, provide a score (0-10) and specific feedback citing examples from the report\\n\"\n",
    "        \"- In your overall assessment, calculate a total score (0-40)\\n\"\n",
    "        \"- Reports scoring 32+ (80%) can be marked as satisfactory\\n\"\n",
    "        \"- For reports below 32, provide clear, prioritized improvement suggestions\\n\"\n",
    "        \"- Be constructive and specific - point to exact sections that need improvement\\n\"\n",
    "        \n",
    "        \"\\n\\n## Important Rules:\"\n",
    "        \"\\n- If the report meets all quality standards (score ≥32), simply confirm this by changing the is_satisfactory field to true and hand it back to ResearchAgent.\"\n",
    "        \"\\n- Always perform a handoff to ResearchAgent for final report generation.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=PeerReviewFeedback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hand-offs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent.handoffs = [peer_review_agent]\n",
    "peer_review_agent.handoffs = [research_agent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Web Content Scraping** → WebScraperAgent extracts, cleans, and filters relevant content from web pages\n",
    "5. **Analysis** → SummaryAgent processes scraped results, extracting key insights while preserving technical details\n",
    "6. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "7. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "8. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "9. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"162pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 161.88\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.700798 0.700798) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 2256.28,-227 2256.28,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1347.54,-8C1347.54,-8 2003.79,-8 2003.79,-8 2009.79,-8 2015.79,-14 2015.79,-20 2015.79,-20 2015.79,-203 2015.79,-203 2015.79,-209 2009.79,-215 2003.79,-215 2003.79,-215 1347.54,-215 1347.54,-215 1341.54,-215 1335.54,-209 1335.54,-203 1335.54,-203 1335.54,-20 1335.54,-20 1335.54,-14 1341.54,-8 1347.54,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"1675.67\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.85,-72.79C133.42,-72.47 159.62,-72.62 216.49,-73.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.33,-76.71 226.36,-73.32 216.4,-69.71 216.33,-76.71\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.43,-72.26C370.75,-71.89 396.11,-72.04 445.47,-72.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.17,-76.21 455.22,-72.84 445.27,-69.21 445.17,-76.21\"/>\n",
       "<text text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- scraper -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>scraper</title>\n",
       "<path fill=\"#fff5cc\" stroke=\"#4472c4\" d=\"M822.54,-92.25C822.54,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 822.54,-55.75 822.54,-55.75 828.54,-55.75 834.54,-61.75 834.54,-67.75 834.54,-67.75 834.54,-80.25 834.54,-80.25 834.54,-86.25 828.54,-92.25 822.54,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"785.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ScraperAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"785.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Data Extraction</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;scraper -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;scraper</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.3,-71.02C636.13,-70.81 667.42,-71.34 725.15,-72.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"725.06,-76.12 735.14,-72.85 725.22,-69.13 725.06,-76.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M1183.29,-92.25C1183.29,-92.25 1006.04,-92.25 1006.04,-92.25 1000.04,-92.25 994.04,-86.25 994.04,-80.25 994.04,-80.25 994.04,-67.75 994.04,-67.75 994.04,-61.75 1000.04,-55.75 1006.04,-55.75 1006.04,-55.75 1183.29,-55.75 1183.29,-55.75 1189.29,-55.75 1195.29,-61.75 1195.29,-67.75 1195.29,-67.75 1195.29,-80.25 1195.29,-80.25 1195.29,-86.25 1189.29,-92.25 1183.29,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1094.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1094.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- scraper&#45;&gt;summary -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>scraper&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M834.66,-67.98C874.05,-63.85 903.47,-63.79 982.25,-67.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"982.02,-71.29 992.19,-68.31 982.38,-64.29 982.02,-71.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"914.29\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Cleaned Data</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1445.79,-92.25C1445.79,-92.25 1355.54,-92.25 1355.54,-92.25 1349.54,-92.25 1343.54,-86.25 1343.54,-80.25 1343.54,-80.25 1343.54,-67.75 1343.54,-67.75 1343.54,-61.75 1349.54,-55.75 1355.54,-55.75 1355.54,-55.75 1445.79,-55.75 1445.79,-55.75 1451.79,-55.75 1457.79,-61.75 1457.79,-67.75 1457.79,-67.75 1457.79,-80.25 1457.79,-80.25 1457.79,-86.25 1451.79,-92.25 1445.79,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1400.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1400.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1195.42,-65.59C1266.57,-60 1299.1,-58.99 1331.97,-62.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1331.33,-65.98 1341.68,-63.73 1332.18,-59.03 1331.33,-65.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"1269.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1673.79,-52.25C1673.79,-52.25 1584.29,-52.25 1584.29,-52.25 1578.29,-52.25 1572.29,-46.25 1572.29,-40.25 1572.29,-40.25 1572.29,-27.75 1572.29,-27.75 1572.29,-21.75 1578.29,-15.75 1584.29,-15.75 1584.29,-15.75 1673.79,-15.75 1673.79,-15.75 1679.79,-15.75 1685.79,-21.75 1685.79,-27.75 1685.79,-27.75 1685.79,-40.25 1685.79,-40.25 1685.79,-46.25 1679.79,-52.25 1673.79,-52.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1629.04\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1629.04\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1458.28,-64.35C1510.39,-55.62 1538.37,-50.88 1560.78,-46.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1561.38,-50.32 1570.6,-45.1 1560.14,-43.43 1561.38,-50.32\"/>\n",
       "<text text-anchor=\"middle\" x=\"1515.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1907.94,-105.94C1907.94,-105.94 1841.39,-78.56 1841.39,-78.56 1835.84,-76.28 1835.84,-71.72 1841.39,-69.44 1841.39,-69.44 1907.94,-42.06 1907.94,-42.06 1913.49,-39.78 1924.59,-39.78 1930.14,-42.06 1930.14,-42.06 1996.69,-69.44 1996.69,-69.44 2002.24,-71.72 2002.24,-76.28 1996.69,-78.56 1996.69,-78.56 1930.14,-105.94 1930.14,-105.94 1924.59,-108.22 1913.49,-108.22 1907.94,-105.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"1919.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text text-anchor=\"middle\" x=\"1919.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1469.35,-72.63C1698.71,-68.06 1755.47,-67.33 1837.88,-70.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1469.38,-69.13 1459.45,-72.82 1469.52,-76.12 1469.38,-69.13\"/>\n",
       "<text text-anchor=\"middle\" x=\"1629.04\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1685.97,-38.17C1781.93,-45.29 1818.8,-48.76 1854.31,-56.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1853.35,-59.92 1863.88,-58.77 1854.94,-53.1 1853.35,-59.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"1758.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"2183.16\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"2183.16\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text text-anchor=\"middle\" x=\"2183.16\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2006.35,-73.01C2052.44,-72.52 2079.95,-72.32 2102.43,-72.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2102.27,-75.92 2112.29,-72.49 2102.31,-68.92 2102.27,-75.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"2060.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x238acabfeb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram_scraper\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram_scraper()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affect on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "plan = await Runner().run(\n",
    "    starting_agent=planner_agent,\n",
    "    input=user_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is classical machine learning?',\n",
       " 'What is deep learning?',\n",
       " 'What is generative AI?',\n",
       " 'Core principles of classical machine learning vs deep learning vs generative AI']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.final_output.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. Multiple search queries are sent to gather diverse perspectives.\n",
    "2. The agent returns structured search results with titles, summaries, relevance scores, and URLs.\n",
    "3. Results are organized by subtopic for further processing.\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to identify promising sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics: 100%|██████████| 4/4 [03:04<00:00, 46.02s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.final_output.research_tasks, desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            message = project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=formatted_query,\n",
    "            )\n",
    "\n",
    "            # Process the run\n",
    "            run = project_client.agents.runs.create_and_process(\n",
    "                thread_id=thread.id,\n",
    "                agent_id=bing_search_agent.id\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 17\n",
      "\n",
      "Actually total search queries: 17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.final_output.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Web Content Scraping\n",
    "\n",
    "The WebScraperAgent processes the URLs and metadata returned by the BingSearchAgent. For each subtopic:\n",
    "\n",
    "1. Only URLs with a high enough relevance score are selected for scraping.\n",
    "2. The WebScraperAgent visits each selected URL and extracts the most relevant content, guided by the user query, subtopic, and search result summary.\n",
    "3. Extracted content is cleaned, deduplicated, and enriched with metadata such as title, source, published date, and extraction method.\n",
    "4. The resulting structured data is organized by subtopic for downstream analysis and summarization.\n",
    "\n",
    "This step ensures that only the most promising and contextually relevant web content is collected, providing a high-quality foundation for subsequent summarization and synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "class ScraperAgentInput(BaseModel):\n",
    "    url: str\n",
    "    subtopic: str\n",
    "    user_query: str\n",
    "    search_result_title: str\n",
    "    visited_urls: Set[str] = Field(default_factory=set)\n",
    "    max_content_length: int = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing scrape tasks...\n",
      "Found 24 unique URLs above threshold to scrape.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement a threshold for relevance score \n",
    "\n",
    "# --- Scraping Phase ---\n",
    "urls_to_process_map = {}\n",
    "\n",
    "print(\"Preparing scrape tasks...\")\n",
    "for subtopic_result in search_results:\n",
    "    subtopic = subtopic_result[\"subtopic\"]\n",
    "    for query_result in subtopic_result[\"queries\"]:\n",
    "        query = query_result[\"query\"]\n",
    "        for result in query_result[\"results\"]:\n",
    "            if result[\"url\"] not in urls_to_process_map:\n",
    "            # if result.relevance_score >= MIN_RELEVANCE_SCORE and result.url not in urls_to_process_map:\n",
    "                urls_to_process_map[result[\"url\"]] = {\n",
    "                    \"subtopic\": subtopic,\n",
    "                    \"query\": query,\n",
    "                    \"search_result_title\": result[\"title\"]\n",
    "                }\n",
    "\n",
    "visited_urls_tracker = set(urls_to_process_map.keys())\n",
    "print(f\"Found {len(urls_to_process_map)} unique URLs above threshold to scrape.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing scrape tasks: 100%|██████████| 24/24 [02:31<00:00,  6.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "MAX_SCRAPE_CONTENT_LENGTH = 4000 # Max characters for scrape tool\n",
    "\n",
    "scrape_tasks = []\n",
    "num_urls_to_scrape = len(urls_to_process_map)\n",
    "\n",
    "for url, context in tqdm(islice(urls_to_process_map.items(), num_urls_to_scrape),\n",
    "                         desc=\"Preparing scrape tasks\",\n",
    "                         total=num_urls_to_scrape):\n",
    "    agent_input_model = ScraperAgentInput(\n",
    "        url=url,\n",
    "        subtopic=context[\"subtopic\"],\n",
    "        user_query=context[\"query\"],\n",
    "        search_result_title=context[\"search_result_title\"],\n",
    "        visited_urls=visited_urls_tracker,\n",
    "        max_content_length=MAX_SCRAPE_CONTENT_LENGTH\n",
    "    )\n",
    "\n",
    "    scrape_response = await Runner().run(\n",
    "        starting_agent=web_scraper_agent,\n",
    "        input=f\"Scrape data from the provided URL: {agent_input_model.model_dump_json()}\"\n",
    "    )\n",
    "    scrape_tasks.append(scrape_response.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Content Analysis and Summarization\n",
    "\n",
    "For each scraped result, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the cleaned web content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms high-quality scraped data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 4/4 [00:48<00:00, 12.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_contents_and_citations, summarize_content\n",
    "summarize_per_webpage = False  # True will summarize per web page, False will summarize per subtopic\n",
    "\n",
    "# Build a lookup for scraped content (using attribute access)\n",
    "scraped_content_by_url = {\n",
    "    item.url: item.main_content\n",
    "    for item in scrape_tasks\n",
    "    if getattr(item, \"main_content\", None)\n",
    "}\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    contents, citations = collect_contents_and_citations(subtopic_result, scraped_content_by_url)\n",
    "    summaries = await summarize_content(contents, summary_agent, Runner, summarize_per_webpage)\n",
    "    if summarize_per_webpage:\n",
    "        mapped_chunks.append({\n",
    "            \"subtopic\": subtopic_result[\"subtopic\"],\n",
    "            \"summaries\": summaries,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "    else:\n",
    "        mapped_chunks.append({\n",
    "            \"subtopic\": subtopic_result[\"subtopic\"],\n",
    "            \"summaries\": summaries,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "\n",
    "# Filter out empty summaries\n",
    "mapped_chunks = [c for c in mapped_chunks if c['summaries']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "final_answer = await Runner().run(\n",
    "    starting_agent=research_agent,\n",
    "    input=(\n",
    "        \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "        \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "        \"a cohesive, academic-style paper:\\n\\n\"\n",
    "        f\"{research_input_prompt}\\n\\n\"\n",
    "        \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    "    ),\n",
    "    max_turns=21 # 5 turns are needed for a full collaboration between ResearchAgent and PeerReviewAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Final Research Report\n",
    "\n",
    "After the ResearchAgent and PeerReviewAgent complete their collaborative process, we extract the final research report from the agent outputs. The report includes:\n",
    "\n",
    "1. A clearly defined research objective\n",
    "2. Multiple sections covering all identified subtopics\n",
    "3. In-depth analysis with facts, statistics, and insights\n",
    "4. Proper citations using IEEE format\n",
    "5. A comprehensive references section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import HandoffCallItem\n",
    "\n",
    "def extract_research_report(final_answer):\n",
    "    # If final output is from ResearchAgent, get the report directly\n",
    "    if hasattr(final_answer.final_output, \"research_report\"):\n",
    "        return final_answer.final_output.research_report\n",
    "    \n",
    "    # If final output is from PeerReviewAgent, find the latest research report from ResearchAgent\n",
    "    for item in reversed(final_answer.new_items):  # Start from end to get the latest\n",
    "        if isinstance(item, HandoffCallItem) and item.agent.name == \"ResearchAgent\":\n",
    "            try:\n",
    "                args = json.loads(item.raw_item.arguments)\n",
    "                if \"research_report\" in args:\n",
    "                    return args[\"research_report\"]\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                continue\n",
    "    \n",
    "    # If we couldn't find a report\n",
    "    raise ValueError(\"No research report found in the conversation history\")\n",
    "\n",
    "research_report = extract_research_report(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Report Presentation\n",
    "\n",
    "The completed research report is displayed below in Markdown format. The report represents a comprehensive analysis of the original query, incorporating insights from multiple web sources and structured in an academic format with proper citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Comparative Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Definitions, Methodologies, Applications, Strengths, and Limitations\n",
       "\n",
       "## Introduction\n",
       "\n",
       "The field of artificial intelligence (AI) has undergone a remarkable evolution, progressing from rule-based expert systems to sophisticated neural networks capable of generating original content. This transformation is characterized by the emergence and interplay of three key paradigms: classical machine learning (ML), deep learning (DL), and generative AI (GenAI). Each paradigm represents a distinct approach to enabling machines to learn from data, solve complex problems, and, increasingly, create new content. As AI technologies become ever more integral to industry, research, and daily life, a nuanced understanding of their definitions, methodologies, applications, strengths, and limitations is essential. This report offers a comprehensive, in-depth comparison of classical machine learning, deep learning, and generative AI, synthesizing technical, practical, and ethical perspectives to illuminate their unique contributions and evolving relationships.\n",
       "\n",
       "## 1. Definitions and Core Principles\n",
       "\n",
       "### 1.1 Classical Machine Learning\n",
       "\n",
       "Classical machine learning is a subset of artificial intelligence that focuses on algorithms enabling computers to learn from data and make predictions or decisions without being explicitly programmed for each task. At its core, classical ML relies on statistical methods to identify patterns in structured datasets, with the goal of generalizing from historical data to new, unseen examples. The learning process typically involves training a model on labeled data (supervised learning), unlabeled data (unsupervised learning), or a combination (semi-supervised learning), and then evaluating its performance on separate test data. Classical ML encompasses a range of algorithms, including linear regression, logistic regression, decision trees, support vector machines (SVMs), k-nearest neighbors, and clustering techniques such as k-means. These models are generally characterized by their reliance on explicit feature engineering, where domain experts manually select and transform input variables to optimize model performance. The success of classical ML is often contingent upon the quality of the features and the availability of labeled data, making it highly effective for structured data analysis but less suited to unstructured or high-dimensional data such as images or raw text [1][2].\n",
       "\n",
       "### 1.2 Deep Learning\n",
       "\n",
       "Deep learning represents a specialized branch of machine learning distinguished by its use of artificial neural networks with multiple layers—hence the term \"deep.\" Inspired by the structure and function of the human brain, deep learning models automatically learn hierarchical representations of data, enabling them to extract complex features and model non-linear relationships. Unlike classical ML, deep learning minimizes the need for manual feature engineering by learning directly from raw data. The architecture of deep learning networks can vary, with common types including feedforward neural networks, convolutional neural networks (CNNs) for image processing, recurrent neural networks (RNNs) and long short-term memory networks (LSTMs) for sequential data, and transformer models for natural language processing. Deep learning excels at tasks involving unstructured or high-dimensional data, such as image and speech recognition, language translation, and autonomous driving. The depth and complexity of these models, however, necessitate large volumes of training data and significant computational resources, often leveraging specialized hardware such as graphics processing units (GPUs) [3][4].\n",
       "\n",
       "### 1.3 Generative AI\n",
       "\n",
       "Generative AI (GenAI) is a transformative subset of artificial intelligence focused on the autonomous creation of new, original content—text, images, audio, video, code, and more—by learning patterns from massive datasets. Unlike traditional AI, which primarily analyzes data to make predictions or decisions, generative AI models are designed to produce outputs that mimic or even surpass human creativity. At the heart of generative AI are advanced deep learning architectures, particularly large language models (LLMs), generative adversarial networks (GANs), and transformers, which are trained on vast, often unlabeled datasets. The generative AI development process typically unfolds in three phases: training a foundation model on massive datasets, fine-tuning for specific applications, and iterative generation and evaluation to refine output quality. Generative AI's flexibility, scalability, and ability to respond to natural language prompts have accelerated its adoption across industries, with applications ranging from content creation and research to design and automation [5][6][7].\n",
       "\n",
       "### 1.4 Hierarchical Relationship\n",
       "\n",
       "The relationship among these paradigms can be visualized as a nested hierarchy: AI encompasses all systems that mimic human intelligence, including machine learning (which enables systems to learn from data), deep learning (which uses multi-layer neural networks for complex pattern recognition), and generative AI (which leverages these advances to create new content). This hierarchy clarifies the progression from broad, rule-based systems to increasingly specialized and autonomous models.\n",
       "\n",
       "#### Figure 1: Hierarchical Breakdown of AI Paradigms\n",
       "\n",
       "| Level           | Description                                        | Examples                       |\n",
       "|-----------------|----------------------------------------------------|--------------------------------|\n",
       "| Artificial Intelligence (AI) | Systems mimicking human intelligence         | Expert systems, search engines |\n",
       "| Machine Learning (ML)        | Algorithms learning from data                | SVM, decision trees            |\n",
       "| Deep Learning (DL)           | Multi-layered neural networks                | CNNs, RNNs, LSTMs              |\n",
       "| Generative AI (GenAI)        | Content-creating models using DL architectures | GPT, DALL-E, GANs              |\n",
       "\n",
       "## 2. Methodologies and Architectures\n",
       "\n",
       "### 2.1 Classical Machine Learning Methodologies\n",
       "\n",
       "Classical machine learning methodologies are grounded in statistical learning theory and rely heavily on structured data and explicit feature engineering. The primary learning paradigms include supervised learning, where models are trained on labeled data to perform classification or regression; unsupervised learning, which seeks to uncover hidden structures in unlabeled data through clustering or dimensionality reduction; semi-supervised learning, which combines labeled and unlabeled data to improve performance in scenarios with limited annotations; and reinforcement learning, where agents learn optimal actions through trial and error in dynamic environments. Classical ML workflows typically involve data collection, preprocessing, feature selection and extraction, model selection, training, evaluation, and deployment. Overfitting—where a model performs well on training data but poorly on new data—is a persistent challenge, addressed through techniques such as regularization, cross-validation, and pruning in tree-based models. The effectiveness of classical ML is often constrained by the need for high-quality labeled data and the expertise required for feature engineering [1][2][8].\n",
       "\n",
       "### 2.2 Deep Learning Architectures\n",
       "\n",
       "Deep learning methodologies depart from the explicit feature engineering of classical ML by leveraging artificial neural networks with multiple layers. The fundamental unit of a neural network is the neuron, which processes input data through weighted connections and non-linear activation functions. Deep learning models are characterized by their depth—the number of hidden layers—which enables them to learn increasingly abstract representations of data. Key architectures include:\n",
       "\n",
       "- **Feedforward Neural Networks:** The simplest form, where data flows in one direction from input to output.\n",
       "- **Convolutional Neural Networks (CNNs):** Specialized for image and spatial data, CNNs use convolutional layers to automatically extract spatial hierarchies of features.\n",
       "- **Recurrent Neural Networks (RNNs) and LSTMs:** Designed for sequential data, RNNs maintain internal memory to capture temporal dependencies, while LSTMs address the vanishing gradient problem in long sequences.\n",
       "- **Transformers:** Introduced for natural language processing, transformers use attention mechanisms to model relationships within sequential data, enabling parallel processing and improved performance on tasks such as language translation and text generation.\n",
       "\n",
       "Deep learning models are typically trained using large-scale datasets and require significant computational resources. The automatic feature extraction capabilities of DL have made it the architecture of choice for tasks involving unstructured data, such as image classification, speech recognition, and natural language understanding [3][4][9].\n",
       "\n",
       "### 2.3 Generative AI Methodologies\n",
       "\n",
       "Generative AI builds upon deep learning architectures to enable the creation of new content. The most prominent methodologies include:\n",
       "\n",
       "- **Large Language Models (LLMs):** Transformer-based models like GPT-3 and GPT-4 are trained on massive corpora of text, learning to generate coherent and contextually relevant language. These models use attention mechanisms to capture relationships within and across sentences, enabling nuanced language generation.\n",
       "- **Generative Adversarial Networks (GANs):** Consist of two neural networks—a generator and a discriminator—that compete in a zero-sum game. The generator creates synthetic data, while the discriminator evaluates its authenticity, driving the generator to produce increasingly realistic outputs. GANs are particularly effective for image, audio, and video synthesis.\n",
       "- **Variational Autoencoders (VAEs):** Probabilistic models that learn to encode data into a latent space and generate new samples by decoding from this space, useful for data synthesis and anomaly detection.\n",
       "- **Multimodal Large Language Models (MLLMs):** Extend the capabilities of LLMs to process and generate content across multiple modalities, such as text, images, audio, and video.\n",
       "\n",
       "The generative AI development process involves training foundation models on vast, often unlabeled datasets, fine-tuning for specific applications, and iterative evaluation and improvement. Recent advances such as Multimodal Retrieval-Augmented Generation (MM-RAG) further enhance generative AI by integrating multiple data modalities, improving contextual understanding and response accuracy [5][6][10].\n",
       "\n",
       "#### Figure 2: Comparison Table of Methodologies and Architectures\n",
       "\n",
       "| Paradigm        | Key Methodologies           | Typical Architectures                | Data Requirements      |\n",
       "|-----------------|----------------------------|--------------------------------------|-----------------------|\n",
       "| Classical ML    | Supervised, unsupervised, reinforcement | Decision trees, SVMs, k-means        | Labeled, structured   |\n",
       "| Deep Learning   | Supervised, unsupervised   | CNNs, RNNs, LSTMs, transformers      | Large, unstructured   |\n",
       "| Generative AI   | Unsupervised, semi-supervised, adversarial | LLMs, GANs, VAEs, MLLMs              | Massive, unlabeled    |\n",
       "\n",
       "## 3. Applications and Use Cases\n",
       "\n",
       "### 3.1 Classical Machine Learning Applications\n",
       "\n",
       "Classical machine learning has been foundational in a wide array of applications, particularly where structured data and explicit feature engineering are feasible. Notable use cases include:\n",
       "\n",
       "- **Fraud Detection:** ML algorithms analyze transaction patterns to identify anomalous behavior indicative of fraud in banking and finance.\n",
       "- **Medical Diagnosis:** Decision trees and support vector machines assist in diagnosing diseases based on patient data, improving accuracy and efficiency.\n",
       "- **Sentiment Analysis:** Text classification models assess customer feedback or social media posts to gauge public sentiment.\n",
       "- **Image and Video Recognition:** Early computer vision applications used classical ML for object detection and facial recognition, though these have largely been superseded by deep learning.\n",
       "- **Data Mining:** Unsupervised learning techniques uncover hidden patterns and associations in large datasets, supporting business intelligence and market analysis.\n",
       "\n",
       "Despite their impact, classical ML models often struggle with high-dimensional or unstructured data, limiting their applicability in domains such as raw image or audio processing [1][2][11].\n",
       "\n",
       "### 3.2 Deep Learning Applications\n",
       "\n",
       "Deep learning has revolutionized fields that require the analysis of unstructured or high-dimensional data. Its automatic feature extraction and hierarchical representation learning have enabled breakthroughs in:\n",
       "\n",
       "- **Image Recognition:** CNNs power state-of-the-art systems for object detection, facial recognition, and medical imaging analysis.\n",
       "- **Speech Recognition:** RNNs and LSTMs facilitate accurate transcription and voice-controlled interfaces.\n",
       "- **Natural Language Processing (NLP):** Transformers and LSTMs underpin applications such as language translation, sentiment analysis, and question answering.\n",
       "- **Autonomous Vehicles:** Deep learning models process sensor data to enable real-time perception, decision-making, and control in self-driving cars.\n",
       "- **Recommendation Systems:** DL architectures analyze user behavior and preferences to deliver personalized content in e-commerce and streaming platforms.\n",
       "\n",
       "The success of deep learning in these domains is attributable to its capacity to learn directly from raw data, reducing the need for manual intervention and enabling scalability to complex, real-world problems [3][4][12].\n",
       "\n",
       "### 3.3 Generative AI Applications\n",
       "\n",
       "Generative AI extends the capabilities of deep learning by enabling the creation of new, original content across modalities. Its applications are rapidly expanding and include:\n",
       "\n",
       "- **Text Generation:** LLMs such as GPT-3 and GPT-4 generate essays, articles, code, and conversational responses, powering chatbots, virtual assistants, and content creation tools.\n",
       "- **Image Generation:** Models like DALL-E and Stable Diffusion create realistic images from textual descriptions, supporting design, advertising, and entertainment.\n",
       "- **Audio and Music Synthesis:** Generative models produce human-like voices, sound effects, and original music compositions.\n",
       "- **Video Generation and Editing:** AI-driven tools generate or manipulate video content, enabling new forms of storytelling and creative expression.\n",
       "- **Data Synthesis:** Synthetic datasets generated by GANs and VAEs support training of other ML models, particularly in data-scarce or privacy-sensitive domains.\n",
       "- **3D Model Generation:** Used in gaming, architecture, and simulation to create realistic virtual environments.\n",
       "- **Language Translation and Summarization:** LLMs provide real-time, context-aware translation and summarization services.\n",
       "- **Conversational Agents:** Advanced chatbots and virtual assistants leverage generative AI for more natural and engaging interactions.\n",
       "\n",
       "The adoption of generative AI is accelerating across industries, with approximately 35% of businesses globally already using AI and another 42% exploring its potential. Generative AI's flexibility and scalability, enabled by foundation models trained on large datasets, allow rapid adaptation to new use cases and deliver time-to-value up to 70% faster than traditional AI approaches in some early tests [5][6][13].\n",
       "\n",
       "#### Figure 3: Impact Assessment Matrix Across Industries\n",
       "\n",
       "| Industry        | Classical ML Applications   | Deep Learning Applications           | Generative AI Applications      |\n",
       "|-----------------|----------------------------|--------------------------------------|--------------------------------|\n",
       "| Healthcare      | Disease diagnosis, risk prediction | Medical imaging, genomics            | Synthetic data, drug discovery |\n",
       "| Finance         | Fraud detection, credit scoring | Algorithmic trading, risk modeling   | Report generation, scenario simulation |\n",
       "| Retail          | Customer segmentation, demand forecasting | Recommendation systems, inventory optimization | Personalized marketing, virtual try-ons |\n",
       "| Media & Entertainment | Content recommendation, audience analysis | Automated editing, content tagging | Script writing, image/video generation |\n",
       "| Manufacturing   | Predictive maintenance, quality control | Defect detection, process optimization | Design automation, digital twins |\n",
       "\n",
       "## 4. Strengths, Limitations, and Evolution\n",
       "\n",
       "### 4.1 Strengths and Limitations of Classical Machine Learning\n",
       "\n",
       "Classical machine learning's principal strength lies in its interpretability and efficiency when applied to structured data with well-defined features. Models such as decision trees and logistic regression offer transparency, enabling practitioners to understand and explain model decisions—a critical requirement in regulated industries such as finance and healthcare. Classical ML algorithms are computationally efficient, making them suitable for deployment in resource-constrained environments. However, their reliance on explicit feature engineering and labeled data limits their scalability and adaptability. Classical ML struggles with high-dimensional, unstructured, or noisy data, and its performance often plateaus as data complexity increases. The need for domain expertise in feature selection further constrains its applicability in rapidly evolving or data-rich domains [1][2][14].\n",
       "\n",
       "### 4.2 Strengths and Limitations of Deep Learning\n",
       "\n",
       "Deep learning's transformative power stems from its ability to automatically learn hierarchical representations from raw data, enabling it to model complex, non-linear relationships and excel in tasks involving unstructured data. DL models have achieved state-of-the-art performance in image and speech recognition, natural language processing, and autonomous systems. Their scalability and adaptability make them suitable for large-scale, real-world applications. However, deep learning models are often criticized for their \"black box\" nature, making interpretability and explainability challenging. The training of deep networks requires vast amounts of labeled data and significant computational resources, raising barriers to entry for smaller organizations. Overfitting, vanishing gradients, and the need for hyperparameter tuning are persistent technical challenges. Despite these limitations, ongoing research in explainable AI and efficient training methods continues to address these concerns [3][4][15].\n",
       "\n",
       "### 4.3 Strengths and Limitations of Generative AI\n",
       "\n",
       "Generative AI represents a paradigm shift, moving beyond analysis and prediction to autonomous content creation. Its strengths include the ability to generate high-quality, contextually relevant content across modalities, democratizing creativity and enabling hyperautomation. Generative AI models can synthesize novel responses, personalize user experiences, and accelerate research and development. However, these capabilities introduce significant ethical, technical, and societal challenges. The risk of misinformation, plagiarism, and the displacement of human creativity is heightened by the plausibility and scale of AI-generated content. The training of generative models often relies on vast, unlabeled datasets scraped from the internet, raising concerns about data provenance, bias, and intellectual property. The human cost of data labeling, particularly in content moderation, has come under scrutiny, with reports of low-wage workers exposed to traumatic material to build safety mechanisms. Privacy and data governance issues arise from the collection and use of user interaction data for model refinement. Technically, generative AI models are resource-intensive, requiring advanced hardware and sophisticated architectures such as transformers, GANs, and multimodal retrieval-augmented generation (MM-RAG) systems [5][6][16][17].\n",
       "\n",
       "### 4.4 Ethical and Societal Considerations\n",
       "\n",
       "The ethical landscape of generative AI is complex and evolving. The potential for AI-generated misinformation to erode trust in information ecosystems is a pressing concern, as is the risk of plagiarism and the undermining of academic and creative originality. The labor conditions of data labelers, particularly in developing countries, highlight the human cost embedded in AI safety mechanisms. Privacy and data governance challenges are exacerbated by the scale and scope of data collection required for training and refining generative models. Addressing these issues requires a multidisciplinary approach, integrating technical safeguards, regulatory frameworks, and ethical guidelines to ensure the responsible development and deployment of AI technologies [16][17].\n",
       "\n",
       "### 4.5 Evolution and Future Trajectories\n",
       "\n",
       "The evolution from classical machine learning to deep learning and generative AI reflects a progression toward greater autonomy, adaptability, and creative capability in artificial systems. Each paradigm builds upon the strengths and addresses the limitations of its predecessors, driving innovation across industries. The convergence of multimodal capabilities, as exemplified by MM-RAG architectures, is unlocking new frontiers in contextual understanding and content generation. As AI systems become more integrated into daily life, the demand for transparency, accountability, and ethical stewardship will intensify. The trajectory of AI suggests continued growth in generative applications, with deep learning and generative models at the forefront of technological and societal transformation [5][6][16][17].\n",
       "\n",
       "#### Figure 4: Timeline of Major Developments in AI\n",
       "\n",
       "| Year | Development                      | Paradigm            |\n",
       "|------|----------------------------------|---------------------|\n",
       "| 1950s| Rule-based expert systems         | Classical AI        |\n",
       "| 1980s| Emergence of machine learning     | Classical ML        |\n",
       "| 1990s| Support vector machines, decision trees | Classical ML  |\n",
       "| 2006 | Deep learning resurgence (Hinton et al.) | Deep Learning  |\n",
       "| 2012 | AlexNet wins ImageNet competition | Deep Learning      |\n",
       "| 2014 | Introduction of GANs              | Generative AI       |\n",
       "| 2017 | Transformer architecture (Vaswani et al.) | Deep Learning/GenAI |\n",
       "| 2020s| Large language models (GPT-3, GPT-4), multimodal AI | Generative AI |\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The comparative analysis of classical machine learning, deep learning, and generative AI reveals a dynamic landscape characterized by rapid innovation, expanding capabilities, and complex ethical considerations. Classical ML provides interpretability and efficiency for structured data but is limited by its reliance on explicit feature engineering. Deep learning overcomes these limitations through hierarchical representation learning, enabling breakthroughs in unstructured data analysis but introducing challenges of interpretability and resource intensity. Generative AI, building on deep learning, ushers in a new era of autonomous content creation, democratizing creativity and accelerating innovation while raising profound ethical and societal questions. The hierarchical relationship among these paradigms underscores the importance of understanding their unique strengths, limitations, and synergies. As AI technologies continue to evolve, the integration of technical, ethical, and societal perspectives will be essential to harnessing their transformative potential for the benefit of individuals, organizations, and society at large.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] [2310.11470] Classic machine learning methods - arXiv.org, https://arxiv.org/abs/2310.11470\n",
       "[2] A Tour of Machine Learning Algorithms, https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/\n",
       "[3] Difference Between Machine Learning and Deep Learning, https://www.geeksforgeeks.org/difference-between-machine-learning-and-deep-learning/\n",
       "[4] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks - IBM, https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
       "[5] What is Generative AI? - IBM, https://www.ibm.com/think/topics/generative-ai\n",
       "[6] What Is Generative AI? Definition, Applications, and Impact, https://www.coursera.org/articles/what-is-generative-ai\n",
       "[7] Modern AI: GenAI vs Machine Learning vs Deep Learning vs LLMs - Cloud4C, https://www.cloud4c.com/blogs/genai-vs-machine-learning-vs-deep-learning-vs-llms\n",
       "[8] Gen AI vs Machine Learning vs Deep Learning - DataSpace Academy, https://dataspaceacademy.com/blog/genai-vs-machine-learning-vs-deep-learning-a-comparative-study\n",
       "[9] Technology Foundations of Generative AI: Architectures ... - PwC, https://www.pwc.de/en/digitale-transformation/generative-ai-artificial-intelligence/the-genai-building-blocks/technology-foundations-of-generative-ai-architectures-algorithms-and-innovations.html\n",
       "[10] AI, ML, DL, and Generative AI Face Off: A Comparative Analysis, https://synoptek.com/insights/it-blogs/data-insights/ai-ml-dl-and-generative-ai-face-off-a-comparative-analysis/\n",
       "[11] From Classical Machine Learning to Deep Neural Networks: A ... - MDPI, https://www.mdpi.com/2076-3417/11/12/5541\n",
       "[12] Classic and Adaptive machines - GeeksforGeeks, https://www.geeksforgeeks.org/classic-and-adaptive-machines/\n",
       "[13] Introducing AI Max for Search campaigns - The Keyword, https://blog.google/products/ads-commerce/google-ai-max-for-search-campaigns/\n",
       "[14] Semrush Report: AI Overviews’ Impact on Search in 2025, https://www.semrush.com/blog/semrush-ai-overviews-study/\n",
       "[15] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks - IBM, https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
       "[16] ChatGPT - Wikipedia, https://en.wikipedia.org/wiki/ChatGPT\n",
       "[17] Multimodal Retrieval Augmented Generation (Multimodal RAG), https://www.geeksforgeeks.org/multimodal-retrieval-augmented-generation-multimodal-rag/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(research_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Workflow Visualization\n",
    "\n",
    "Below we can see the detailed steps in the research and review process, showing how the ResearchAgent and PeerReviewAgent collaborated to produce the final report. This visualization helps us understand how many iterations were required to meet quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 AGENT WORKFLOW: 'Create an exceptionally comprehensive, **paragraph-focused** and detailed research report using the following content. **Minimize bullet points** and ensure the final text resembles a cohesive, academic-style paper:\n",
      "\n",
      "{\n",
      "  \"objective\": \"To comprehensively compare and contrast classical machine learning, deep learning, and generative AI, highlighting their definitions, methodologies, applications, strengths, and limitations.\",\n",
      "  \"aggregated_summaries\": [\n",
      "    {\n",
      "      \"subtopic\": \"Definitions and Core Principles\",\n",
      "      \"summaries\": \"Acknowledging that the input combines information from multiple search results, here is a unified, comprehensive summary focused on the subtopic: **What is Generative AI and how does it work?**\\n\\n---\\n\\n## Key Insights\\n- **Generative AI (GenAI) is a subset of artificial intelligence that creates new, original content\\u2014such as text, images, audio, video, and code\\u2014by learning patterns from massive datasets, distinguishing it from traditional, predictiv'\n",
      "\n",
      "\n",
      "================================================================================\n",
      "👤 AGENT: ResearchAgent\n",
      "--------------------------------------------------------------------------------\n",
      "  💬 OUTPUT: {\"objective\":\"To comprehensively compare and contrast classical machine learning, deep learning, ...\n",
      "\n",
      "================================================================================\n",
      "🏁 FINAL OUTPUT:\n",
      "--------------------------------------------------------------------------------\n",
      "# Comparative Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Definitions, Methodologies, Applications, Strengths, and Limitations\n",
      "\n",
      "## Introduction\n",
      "\n",
      "The field of artificial i...\n"
     ]
    }
   ],
   "source": [
    "from common.helper import pretty_print_agent_workflow\n",
    "pretty_print_agent_workflow(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson-deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
