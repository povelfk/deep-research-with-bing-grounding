{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search & Scraping**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow now includes a dedicated scraping phase for extracting and cleaning web content:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Web Content Scraping** - Extracting, cleaning, and filtering relevant content from web pages using a ScraperAgent\n",
    "4. **Content Analysis** - Summarizing scraped results and extracting key insights\n",
    "5. **Report Generation** - Creating detailed research reports with proper citations\n",
    "6. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- WebScraperAgent - Extracts, cleans, and filters relevant content from web pages\n",
    "- SummaryAgent - Extracts key insights from scraped content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Projects, and the OpenAI Agents SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Environment Variables\n",
    "\n",
    "This notebook requires the following environment variables in your `.env` file:\n",
    "\n",
    "```bash\n",
    "# Azure OpenAI Configuration\n",
    "AOAI_ENDPOINT=your_azure_openai_endpoint\n",
    "AOAI_KEY=your_azure_openai_api_key\n",
    "AOAI_API_VERSION=2024-02-01  # Optional, defaults to this value\n",
    "\n",
    "# Model Deployment Names\n",
    "reasoningModel=your_reasoning_model_deployment_name  # e.g., o1-preview\n",
    "chatModel=your_chat_model_deployment_name  # e.g., gpt-4o\n",
    "\n",
    "# Azure AI Projects Configuration\n",
    "PROJECT_ENDPOINT=your_azure_ai_project_endpoint\n",
    "\n",
    "# Bing Search Agent (pre-created in Azure AI Foundry)\n",
    "bingSearchAgentID=your_bing_search_agent_id\n",
    "BING_CONNECTION_NAME=your_bing_connection_name  # Only needed if creating agent inline\n",
    "```\n",
    "\n",
    "**Note:** This notebook extends notebook 01 by adding web scraping capabilities. Like notebook 01, it creates agents inline using the OpenAI Agents SDK, except for the Bing Search agent which must be pre-created in Azure AI Foundry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Azure OpenAI to work with OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents import (\n",
    "    set_default_openai_client,\n",
    "    set_tracing_disabled,\n",
    "    OpenAIChatCompletionsModel\n",
    ")\n",
    "\n",
    "# setup settings\n",
    "from openai import AsyncAzureOpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Use the synchronous client instead of the async one\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AOAI_KEY\"),\n",
    "    api_version=os.environ.get(\"AOAI_API_VERSION\", \"2024-02-01\")\n",
    ")\n",
    "\n",
    "# Configure SDK\n",
    "set_default_openai_client(openai_client)\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "reasoningModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"reasoningModel\"), \n",
    "    openai_client=openai_client\n",
    ")\n",
    "\n",
    "chatModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    openai_client=openai_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models for Research Workflow\n",
    "\n",
    "The following Pydantic models define the structured data used throughout our research process:\n",
    "\n",
    "1. **ResearchTask** - Represents an individual research task with specific search queries\n",
    "2. **ResearchPlan** - Contains the overall plan with research objectives and tasks\n",
    "3. **Citation** - Stores source information for proper attribution\n",
    "4. **ComprehensiveResearchReport** - Defines the structure of the final research output\n",
    "5. **PeerReviewFeedback** - Contains structured feedback on report quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResearchTask(BaseModel):\n",
    "    id: Optional[str] = Field(None, description=\"Unique identifier for the task\")\n",
    "    subtopic: str = Field(..., description=\"Subtopic to research\")\n",
    "    search_queries: List[str] = Field(..., description=\"List of search queries to explore this subtopic\")\n",
    "    completed: bool = Field(..., description=\"Status of task completion\")\n",
    "\n",
    "class ResearchPlan(BaseModel):\n",
    "    query: str = Field(..., description=\"The original user query that prompted this research\")\n",
    "    objective: str = Field(..., description=\"The overall research objective, clearly defined\")\n",
    "    success_criteria: List[str] = Field(..., description=\"Criteria to determine when the research is sufficiently complete.\")\n",
    "    related_topics: List[str] = Field(..., description=\"List of related topics that may be useful for the research.\")\n",
    "    research_tasks: List[ResearchTask] = Field(..., description=\"List of specific research tasks to complete. Each task focuses on a subtopic.\")\n",
    "\n",
    "class ScrapedWebPage(BaseModel):\n",
    "    url: str = Field(..., description=\"The original URL that was scraped\")\n",
    "    title: Optional[str] = Field(None, description=\"The page title (if available, else None)\")\n",
    "    main_content: Optional[str] = Field(None, description=\"The main textual content of the page, cleaned and potentially truncated (if available, else None)\")\n",
    "    source: Optional[str] = Field(None, description=\"The name of the source (if available, else None)\")\n",
    "    published_date: Optional[str] = Field(None, description=\"YYYY-MM-DD (if available, else None)\")\n",
    "    scrape_error: Optional[str] = Field(None, description=\"Error message if scraping failed, else None\")\n",
    "    # Fields below might be added by the agent based on instructions, not the tool directly\n",
    "    extraction_method: Optional[str] = Field(None, description=\"How content was extracted (e.g., 'tool_extracted', 'agent_filtered')\") \n",
    "    relevance_score_agent: Optional[float] = Field(None, description=\"Agent's assessment of relevance (0-10)\")\n",
    "    matched_sections: Optional[List[str]] = Field(None, description=\"Sections identified by the agent as relevant\")\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "\n",
    "class ComprehensiveResearchReport(BaseModel):\n",
    "    objective: str = Field(..., description=\"The original research objective\")\n",
    "    research_report: str = Field(..., description=(\n",
    "        \"Comprehensive research report in markdown. \"\n",
    "        \"It should be structured with meaningful headings and subsections, but emphasize **fully-developed paragraphs**. \"\n",
    "        \"It should be long and detailed, and it should fully addresses the objectives, \"\n",
    "        \"and the various subtopics required to achieve the success criteria. \"\n",
    "        \"Use bullet points or lists **only** when they genuinely improve clarity (e.g., summarizing key data). \"\n",
    "        \"Tables and other data visualizations are encouraged. \"\n",
    "        \"The research report should always be long and detailed.\\n\\n\" \n",
    "        \"For citations, please use the IEEE (Institute of Electrical and Electronics Engineers). \"\n",
    "        \"How it works:\\n\\n\"\n",
    "        \"   1. In the text, use numbered citations in brackets [1].\\n\"\n",
    "        \"   2. At the end of the report, provide a list of citations in the format \"\n",
    "        \"(the list should ONLY contain the sources used in the free text of the research report. \"\n",
    "        \"Do NOT list sources which are not cited in the free text of the research report.):\\n\\n\"\n",
    "        \"       [1] Title of the source, URL.\"\n",
    "    ))\n",
    "    citations: List[Citation] = Field(..., description=(\n",
    "        \"List of citations (title and URL), corresponding to references actually used in research_report. \"\n",
    "        \"Do not add references that are not cited within the text.\"\n",
    "    ))\n",
    "    identified_gaps: Optional[List[str]] = Field(default=None, description=\"Identified information gaps.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Suggestions for additional research.\")\n",
    "\n",
    "class PeerReviewFeedback(BaseModel):\n",
    "    overall_feedback: str = Field(..., description=\"General feedback on the report.\")\n",
    "    strengths: List[str] = Field(..., description=\"Aspects of the report that are well done.\")\n",
    "    suggested_improvements: List[str] = Field(..., description=\"Specific suggestions to improve clarity, completeness, accuracy, or structure.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Additional research queries that could strengthen the report.\")\n",
    "    is_satisfactory: bool = Field(..., description=\"Indicates if the report meets all quality standards and no further revisions are needed.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "The research workflow is powered by two types of agents:\n",
    "\n",
    "1. **Azure AI Agents** - Created using Azure AI Projects for web search capabilities\n",
    "2. **OpenAI Agents** - For specialized research tasks\n",
    "\n",
    "Let's configure each type of agent with their specific instructions and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Bing Search Agent (One-time Setup)\n",
    "\n",
    "The following cell will **create** an **Azure AI Agent** with Bing Search capabilities. You only need to run this cell **once** to create the agent, then save its ID to your `.env` file as `bingSearchAgentID`.\n",
    "\n",
    "If you already have a Bing Search agent created, skip this cell and use the next cell to update its instructions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import BingGroundingTool\n",
    "\n",
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bing_connection = project_client.connections.get(\n",
    "    name=os.getenv(\"BING_CONNECTION_NAME\")\n",
    ")\n",
    "\n",
    "bing_tool = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "bing_search_agent = project_client.agents.create_agent(\n",
    "    name=\"bingSearchAgent\",\n",
    "    description=\"Agent to perform web searches using Bing.\",\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    temperature=0.5,\n",
    "    tools=bing_tool.definitions,\n",
    "    instructions=f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "    \"\"\".strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Existing Bing Search Agent\n",
    "\n",
    "If you already have a Bing Search agent (with its ID in your `.env` file), run this cell to update its instructions with today's date. This ensures the agent has current date awareness for time-sensitive queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful research assistant.\n",
      "\n",
      "Today's date is 2025-11-28.\n",
      "\n",
      "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
      "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
      "Provide a comprehensive answer based on the search results.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "bing_search_agent.instructions = f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(bing_search_agent.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating OpenAI Agents\n",
    "\n",
    "The following agents are created inline using the OpenAI Agents SDK:\n",
    "- **PlannerAgent** - Creates research plans\n",
    "- **WebScraperAgent** - Scrapes and filters web content (new in this notebook)\n",
    "- **SummaryAgent** - Summarizes scraped content\n",
    "- **ResearchAgent** - Generates comprehensive reports\n",
    "- **PeerReviewAgent** - Provides quality feedback\n",
    "\n",
    "These agents are created fresh each time you run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    Agent,\n",
    "    ModelSettings\n",
    ")\n",
    "\n",
    "from common.utils_scraping import scrape_web_page\n",
    "\n",
    "chatModelSettings=ModelSettings(\n",
    "        max_tokens=32768,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "\n",
    "    You are an expert research planner specializing in creating detailed research plans your task is to analyze a user's research query and create a structured research plan.\n",
    "    with the following components:\n",
    "    \n",
    "    1. DOMAIN CLASSIFICATION:\n",
    "       Classify the query into a fitting domain (e.g., technology, business, etc.).\n",
    "       The Domain is not included in the output, but it is important for the other components in the research plan.\n",
    "       The domain should be a single word (e.g., technology, business, etc.).\n",
    "       \n",
    "    2. RESEARCH OBJECTIVE:\n",
    "       Create a clear, comprehensive objective statement for the research\n",
    "       \n",
    "    3. SUBTOPICS:\n",
    "       Generate relevant subtopics that should be explored to thoroughly answer the query (Important. generate no less than 4 subtopics)\n",
    "       \n",
    "    4. SEARCH QUERIES:\n",
    "       For each subtopic, provide search queries that will yield valuable results (Important. It's better to generate more queries than less queries, but at least 2 queries per subtopic)\n",
    "       \n",
    "    5. SUCCESS CRITERIA:\n",
    "       List the criteria that will determine when the research is complete (Important. generate no less than 4 success criteria)\n",
    "       Take all of the above into account (e.g., the domain, objective, subtopics, and search queries) to create the success criteria.\n",
    "       \n",
    "    6. RELATED TOPICS:\n",
    "       suggest related topics that may be useful for the research (Important. generate no less than 3 related topics)\n",
    "    \n",
    "    Ensure each subtopic is thorough and directly relevant to the research query.\n",
    "    The search queries should be specific enough to return high-quality results.\n",
    "    \"\"\".strip(),\n",
    "    model=chatModel,\n",
    "    output_type=ResearchPlan,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "web_scraper_agent = Agent(\n",
    "    name=\"WebScraperAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "    \n",
    "    You are a robust, context-aware web scraping specialist. Your primary tool is 'scrape_web_page'.\n",
    "\n",
    "    Your input is a JSON string containing: 'url', 'subtopic', 'user_query', 'search_result_title', 'visited_urls', and 'max_content_length'. Parse this JSON to get the necessary information.\n",
    "\n",
    "    **Workflow:**\n",
    "    1.  **Parse Input:** Extract 'url', 'user_query', 'subtopic', 'search_result_summary', and 'max_content_length' from the input JSON string.\n",
    "    2.  **Call Scraping Tool:** Call the `scrape_web_page` tool with the 'url' and 'max_content_length'.\n",
    "    3.  **Analyze Tool Output:** Receive the dictionary from the tool containing `url`, `title`, `main_content`, `source`, `published_date`, `scrape_error`.\n",
    "    4.  **Contextual Filtering (If Content Exists and No Error):**\n",
    "        - If `scrape_error` is None and `main_content` exists:\n",
    "            - Review the `main_content`.\n",
    "            - Use the `user_query`, `subtopic`, and `search_result_summary` to identify ONLY the most relevant paragraphs or sections.\n",
    "            - If the entire `main_content` seems relevant or is short, keep it all.\n",
    "            - If filtering, replace `main_content` with ONLY the relevant extracted parts. Set `extraction_method` to 'agent_filtered'.\n",
    "            - Estimate a `relevance_score_agent` (0-10).\n",
    "            - Optionally list `matched_sections`.\n",
    "        - If `scrape_error` is present, ensure the `scrape_error` field in your output reflects the tool's error.\n",
    "    5.  **Format Output:** Return a SINGLE JSON object matching the `ScrapedWebPage` Pydantic model, including all fields based on the tool's output and your filtering. If the tool failed, `main_content` should be None/empty, and `scrape_error` should be set.\n",
    "    6.  **Return JSON object:** Return ONLY the final object formatted as a single, valid JSON. Do NOT add any explanatory text before or after the JSON.\n",
    "\n",
    "    **Constraints:**\n",
    "    - Your final output MUST be ONLY a valid JSON representing the scraped and processed data.\n",
    "    - Adhere strictly to the field names defined in the conceptual `ScrapedWebPage` structure when creating the JSON.\n",
    "    - Prioritize accuracy and relevance based on the provided context.\n",
    "    \"\"\",\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    tools=[scrape_web_page],\n",
    "    output_type=ScrapedWebPage\n",
    ")\n",
    "\n",
    "summary_agent = Agent(\n",
    "    name=\"SummaryAgent\",\n",
    "    instructions=(\n",
    "        \"You are a comprehensive research summarization specialist. Your task is to **synthesize information from combined search result content** related to a specific subtopic (which will be mentioned in the input prompt). \"\n",
    "        \"Create a **single, coherent, detailed, and information-rich summary** that:\\n\\n\"\n",
    "        \"1. Extracts ALL important facts, statistics, findings, and insights **relevant to the specified subtopic** from the combined text.\\n\"\n",
    "        \"2. Preserves specific numbers, percentages, dates, and technical details whenever present.\\n\"\n",
    "        \"3. Includes industry-specific terminology and concepts that add depth to the research.\\n\"\n",
    "        \"4. **Synthesizes** the key arguments and conclusions from the provided sources. If sources present different perspectives or data, try to capture that nuance.\\n\"\n",
    "        \"5. Provides thorough explanations rather than superficial overviews, integrating information smoothly.\\n\"\n",
    "        \"6. For technical content, preserves methodologies, technical specifications, and implementation details.\\n\"\n",
    "        \"7. For comparative content, maintains all sides of the comparison with their specific attributes.\\n\\n\"\n",
    "\n",
    "        \"**Acknowledge that the input combines information potentially from multiple search results.** Your goal is to create a unified summary focused on the overall subtopic, not just list summaries of individual parts.\\n\\n\"\n",
    "\n",
    "        \"Remember that your summary serves as the foundation for generating a comprehensive research report. The quality and depth of the final research report depends directly on how comprehensive and well-synthesized your summary is. Ensure it captures the essence of all provided content relevant to the subtopic.\\n\\n\"\n",
    "\n",
    "        \"FORMAT YOUR SUMMARY AS:\\n\"\n",
    "        \"## Key Insights\\n\"\n",
    "        \"- [Most critical takeaway #1]\\n\"\n",
    "        \"- [Most critical takeaway #2]\\n\"\n",
    "        \"- [Most critical takeaway #3]\\n\"\n",
    "        \"- [Optional: Most critical takeaway #4]\\n\\n\"\n",
    "        \"## Extensive Synthesis\\n\"\n",
    "        \"Write a thorough, multi-paragraph synthesis that:\\n\"\n",
    "        \"- Integrates all important facts, statistics, findings, and insights relevant to the subtopic.\\n\"\n",
    "        \"- Preserves specific numbers, percentages, dates, and technical details.\\n\"\n",
    "        \"- Explains methodologies, technical specifications, and implementation details where relevant.\\n\"\n",
    "        \"- Highlights agreements, disagreements, and nuances between sources.\\n\"\n",
    "        \"- Uses industry-specific terminology and concepts.\\n\"\n",
    "        \"- Provides context, background, and implications for the findings.\\n\"\n",
    "        \"- Maintains logical flow: start with an overview, then go into specifics, and conclude with implications or open questions.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    output_type=str,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    instructions=(\n",
    "        \"## General Instructions\\n\"\n",
    "        \"You are a meticulous research analyst specializing in creating **long, comprehensive, authoritative** reports. \"\n",
    "        \"Your goal is to produce **in-depth, highly detailed** content that thoroughly analyzes all aspects of the research topic. \"\n",
    "        \"Furthermore, you must also demonstrate subject matter expertise with nuanced insights, technical details, and sophisticated analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Style & Format:\\n\"\n",
    "        \"- **Default to paragraphs.** Present your findings in cohesive, well-structured paragraphs rather than excessive bullet points.\\n\"\n",
    "        \"- **Use bullet points sparingly.** Only use them when they add genuine clarity—e.g., summarizing key data.\\n\"\n",
    "        \"- **Structure** the report with a clear hierarchy, but avoid excessive nesting. Aim for a balanced structure:\\n\"\n",
    "        \"   - Use main sections and occasional subsections where needed.\\n\"\n",
    "        \"   - Avoid over-fragmentation by limiting sub-subsections unless absolutely necessary.\\n\"\n",
    "        \"   - Favor broader thematic groupings to maintain narrative flow and reduce section clutter.\\n\"\n",
    "        \"   - With that said, if a subtopic would benefit from a sub-subsection, feel free to add it.\\n\"\n",
    "        \"- **Data visualizations** (e.g., tables, charts, diagrams) in Markdown are encouraged wherever they enhance understanding.\\n\"\n",
    "        \"- Maintain a logical, flowing structure so each subsection builds upon the prior sections.\\n\"\n",
    "        \"- **Citations:** Use IEEE style: [1], [2], etc. Provide a 'References' section at the end of your report with only the sources cited in the text.\\n\\n\"\n",
    "        \n",
    "        \"### Long & Comprehensive Requirement:\\n\"\n",
    "        \"- The final report must be the equivalent of **10 to 12 pages** of substantive text, approximately **7000-9000 words**.\\n\"\n",
    "        \"- Each major section should have **extensive exploration** (ideally 800-1000 words per section).\\n\"\n",
    "        \"- Ensure thorough coverage of the topic with **well-developed paragraphs**, plenty of detail, and rigorous analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Depth Requirements:\\n\"\n",
    "        \"- Include **quantitative data**, statistics, and specific examples to support your arguments.\\n\"\n",
    "        \"- Compare and contrast **multiple perspectives** on complex topics.\\n\"\n",
    "        \"- Integrate ideas across sections for a cohesive, synthesized analysis rather than isolated observations.\\n\\n\"\n",
    "        \n",
    "        \"### Workflow\\n\"\n",
    "        \"- When given the research objective and content, develop a **long-form narrative** with detailed explanations.\\n\"\n",
    "        \"- If PeerReviewAgent provides feedback, revise thoroughly, addressing all points.\\n\"\n",
    "        \"- Once feedback is marked satisfactory, present the final report.\\n\\n\"\n",
    "        \n",
    "        \"### Important Guidelines\\n\"\n",
    "        \"- Retain high-quality content in any revision.\\n\"\n",
    "        \"- If feedback highlights missing info, propose specific research queries.\\n\"\n",
    "        \"- Avoid unnecessary repetition.\\n\\n\"\n",
    "\n",
    "        \"**REMINDER**:\"\n",
    "        \"Your output should be a single, cohesive Markdown document that reads like a well-developed academic or professional paper, with minimal use of bullet points. \"\n",
    "        \"Prefer broader thematic sections over excessive fragmentation. \"\n",
    "        \"Sub-subsections may be used where helpful, but structure should remain balanced and readable. \"\n",
    "        \"Lastly, do not forget to include the references section at the end of the report.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=ComprehensiveResearchReport,\n",
    ")\n",
    "\n",
    "\n",
    "peer_review_agent = Agent(\n",
    "    name=\"PeerReviewAgent\",\n",
    "    instructions=(\n",
    "        \"You are a critical yet constructive peer reviewer evaluating research reports. \"\n",
    "        \"Your goal is to provide detailed, actionable feedback using a structured evaluation framework.\\n\\n\"\n",
    "        \n",
    "        \"## Evaluation Framework:\\n\"\n",
    "        \"1. COMPLETENESS (0-10): Does the report thoroughly cover all aspects of the research topic?\\n\"\n",
    "        \"   - Are all required subtopics adequately addressed?\\n\"\n",
    "        \"   - Is there sufficient depth in each section (500+ words per major section)?\\n\"\n",
    "        \"   - Are there any obvious gaps or missing perspectives?\\n\\n\"\n",
    "        \n",
    "        \"2. CLARITY & STRUCTURE (0-10): Is the report well-organized and clearly written?\\n\"\n",
    "        \"   - Does it have a logical flow with clear sections and subsections?\\n\"\n",
    "        \"   - Are complex concepts explained in accessible language?\\n\"\n",
    "        \"   - Does it use formatting effectively (headings, lists, tables)?\\n\\n\"\n",
    "        \n",
    "        \"3. EVIDENCE & SUPPORT (0-10): Is information well-supported?\\n\"\n",
    "        \"   - Are claims backed by data, statistics, or authoritative sources?\\n\"\n",
    "        \"   - Are citations used appropriately and consistently?\\n\"\n",
    "        \"   - Does it include multiple perspectives when appropriate?\\n\\n\"\n",
    "        \n",
    "        \"4. ANALYSIS & INSIGHT (0-10): Does the report provide valuable analysis?\\n\"\n",
    "        \"   - Does it go beyond summarizing to provide meaningful insights?\\n\"\n",
    "        \"   - Does it connect ideas across different sections?\\n\"\n",
    "        \"   - Does it identify implications and future directions?\\n\\n\"\n",
    "        \n",
    "        \"## Response Guidelines:\\n\"\n",
    "        \"- For each criterion, provide a score (0-10) and specific feedback citing examples from the report\\n\"\n",
    "        \"- In your overall assessment, calculate a total score (0-40)\\n\"\n",
    "        \"- Reports scoring 32+ (80%) can be marked as satisfactory\\n\"\n",
    "        \"- For reports below 32, provide clear, prioritized improvement suggestions\\n\"\n",
    "        \"- Be constructive and specific - point to exact sections that need improvement\\n\"\n",
    "        \n",
    "        \"\\n\\n## Important Rules:\"\n",
    "        \"\\n- If the report meets all quality standards (score ≥32), simply confirm this by changing the is_satisfactory field to true and hand it back to ResearchAgent.\"\n",
    "        \"\\n- Always perform a handoff to ResearchAgent for final report generation.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=PeerReviewFeedback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hand-offs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent.handoffs = [peer_review_agent]\n",
    "peer_review_agent.handoffs = [research_agent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Web Content Scraping** → WebScraperAgent extracts, cleans, and filters relevant content from web pages\n",
    "5. **Analysis** → SummaryAgent processes scraped results, extracting key insights while preserving technical details\n",
    "6. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "7. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "8. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "9. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.4 (20251115.1723)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"162pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 162.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.700798 0.700798) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 2256.28,-227 2256.28,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1347.54,-8C1347.54,-8 2003.79,-8 2003.79,-8 2009.79,-8 2015.79,-14 2015.79,-20 2015.79,-20 2015.79,-203 2015.79,-203 2015.79,-209 2009.79,-215 2003.79,-215 2003.79,-215 1347.54,-215 1347.54,-215 1341.54,-215 1335.54,-209 1335.54,-203 1335.54,-203 1335.54,-20 1335.54,-20 1335.54,-14 1341.54,-8 1347.54,-8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1675.67\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.85,-72.79C133.42,-72.47 159.62,-72.62 216.49,-73.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.33,-76.71 226.36,-73.32 216.4,-69.71 216.33,-76.71\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.43,-72.26C370.75,-71.89 396.11,-72.04 445.47,-72.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.17,-76.21 455.22,-72.84 445.27,-69.21 445.17,-76.21\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- scraper -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>scraper</title>\n",
       "<path fill=\"#fff5cc\" stroke=\"#4472c4\" d=\"M822.54,-92.25C822.54,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 822.54,-55.75 822.54,-55.75 828.54,-55.75 834.54,-61.75 834.54,-67.75 834.54,-67.75 834.54,-80.25 834.54,-80.25 834.54,-86.25 828.54,-92.25 822.54,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"785.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ScraperAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"785.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Data Extraction</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;scraper -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;scraper</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.3,-71.02C636.13,-70.81 667.42,-71.34 725.15,-72.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"725.06,-76.12 735.14,-72.85 725.22,-69.13 725.06,-76.12\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M1183.29,-92.25C1183.29,-92.25 1006.04,-92.25 1006.04,-92.25 1000.04,-92.25 994.04,-86.25 994.04,-80.25 994.04,-80.25 994.04,-67.75 994.04,-67.75 994.04,-61.75 1000.04,-55.75 1006.04,-55.75 1006.04,-55.75 1183.29,-55.75 1183.29,-55.75 1189.29,-55.75 1195.29,-61.75 1195.29,-67.75 1195.29,-67.75 1195.29,-80.25 1195.29,-80.25 1195.29,-86.25 1189.29,-92.25 1183.29,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1094.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1094.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- scraper&#45;&gt;summary -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>scraper&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M834.66,-67.98C874.05,-63.85 903.47,-63.79 982.25,-67.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"982.02,-71.29 992.19,-68.31 982.38,-64.29 982.02,-71.29\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"914.29\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Cleaned Data</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1445.79,-92.25C1445.79,-92.25 1355.54,-92.25 1355.54,-92.25 1349.54,-92.25 1343.54,-86.25 1343.54,-80.25 1343.54,-80.25 1343.54,-67.75 1343.54,-67.75 1343.54,-61.75 1349.54,-55.75 1355.54,-55.75 1355.54,-55.75 1445.79,-55.75 1445.79,-55.75 1451.79,-55.75 1457.79,-61.75 1457.79,-67.75 1457.79,-67.75 1457.79,-80.25 1457.79,-80.25 1457.79,-86.25 1451.79,-92.25 1445.79,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1400.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1400.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1195.42,-65.59C1266.57,-60 1299.1,-58.99 1331.97,-62.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1331.33,-65.98 1341.68,-63.73 1332.18,-59.03 1331.33,-65.98\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1269.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1673.79,-52.25C1673.79,-52.25 1584.29,-52.25 1584.29,-52.25 1578.29,-52.25 1572.29,-46.25 1572.29,-40.25 1572.29,-40.25 1572.29,-27.75 1572.29,-27.75 1572.29,-21.75 1578.29,-15.75 1584.29,-15.75 1584.29,-15.75 1673.79,-15.75 1673.79,-15.75 1679.79,-15.75 1685.79,-21.75 1685.79,-27.75 1685.79,-27.75 1685.79,-40.25 1685.79,-40.25 1685.79,-46.25 1679.79,-52.25 1673.79,-52.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1629.04\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1629.04\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1458.28,-64.35C1510.39,-55.62 1538.37,-50.88 1560.78,-46.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1561.38,-50.32 1570.6,-45.1 1560.14,-43.43 1561.38,-50.32\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1515.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1907.94,-105.94C1907.94,-105.94 1841.39,-78.56 1841.39,-78.56 1835.84,-76.28 1835.84,-71.72 1841.39,-69.44 1841.39,-69.44 1907.94,-42.06 1907.94,-42.06 1913.49,-39.78 1924.59,-39.78 1930.14,-42.06 1930.14,-42.06 1996.69,-69.44 1996.69,-69.44 2002.24,-71.72 2002.24,-76.28 1996.69,-78.56 1996.69,-78.56 1930.14,-105.94 1930.14,-105.94 1924.59,-108.22 1913.49,-108.22 1907.94,-105.94\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1919.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1919.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1469.35,-72.63C1698.71,-68.06 1755.47,-67.33 1837.88,-70.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1469.38,-69.13 1459.45,-72.82 1469.52,-76.12 1469.38,-69.13\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1629.04\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1685.97,-38.17C1781.93,-45.29 1818.8,-48.76 1854.31,-56.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1853.35,-59.92 1863.88,-58.77 1854.94,-53.1 1853.35,-59.92\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1758.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"2183.16\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2183.16\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2183.16\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2006.35,-73.01C2052.44,-72.52 2079.95,-72.32 2102.43,-72.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2102.27,-75.92 2112.29,-72.49 2102.31,-68.92 2102.27,-75.92\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2060.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x26134565210>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram_scraper\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram_scraper()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affect on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "plan = await Runner().run(\n",
    "    starting_agent=planner_agent,\n",
    "    input=user_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is classical machine learning?',\n",
       " 'What is deep learning?',\n",
       " 'What is generative AI?',\n",
       " 'Core principles of classical machine learning vs deep learning vs generative AI']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.final_output.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. Multiple search queries are sent to gather diverse perspectives.\n",
    "2. The agent returns structured search results with titles, summaries, relevance scores, and URLs.\n",
    "3. Results are organized by subtopic for further processing.\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to identify promising sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics: 100%|██████████| 4/4 [04:47<00:00, 71.89s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.final_output.research_tasks, desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            message = project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=formatted_query,\n",
    "            )\n",
    "\n",
    "            # Process the run\n",
    "            run = project_client.agents.runs.create_and_process(\n",
    "                thread_id=thread.id,\n",
    "                agent_id=bing_search_agent.id\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 17\n",
      "\n",
      "Actually total search queries: 17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.final_output.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Web Content Scraping\n",
    "\n",
    "The WebScraperAgent processes the URLs and metadata returned by the BingSearchAgent. For each subtopic:\n",
    "\n",
    "1. Only URLs with a high enough relevance score are selected for scraping.\n",
    "2. The WebScraperAgent visits each selected URL and extracts the most relevant content, guided by the user query, subtopic, and search result summary.\n",
    "3. Extracted content is cleaned, deduplicated, and enriched with metadata such as title, source, published date, and extraction method.\n",
    "4. The resulting structured data is organized by subtopic for downstream analysis and summarization.\n",
    "\n",
    "This step ensures that only the most promising and contextually relevant web content is collected, providing a high-quality foundation for subsequent summarization and synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "class ScraperAgentInput(BaseModel):\n",
    "    url: str\n",
    "    subtopic: str\n",
    "    user_query: str\n",
    "    search_result_title: str\n",
    "    visited_urls: Set[str] = Field(default_factory=set)\n",
    "    max_content_length: int = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing scrape tasks...\n",
      "Found 64 unique URLs above threshold to scrape.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement a threshold for relevance score \n",
    "\n",
    "# --- Scraping Phase ---\n",
    "urls_to_process_map = {}\n",
    "\n",
    "print(\"Preparing scrape tasks...\")\n",
    "for subtopic_result in search_results:\n",
    "    subtopic = subtopic_result[\"subtopic\"]\n",
    "    for query_result in subtopic_result[\"queries\"]:\n",
    "        query = query_result[\"query\"]\n",
    "        for result in query_result[\"results\"]:\n",
    "            if result[\"url\"] not in urls_to_process_map:\n",
    "            # if result.relevance_score >= MIN_RELEVANCE_SCORE and result.url not in urls_to_process_map:\n",
    "                urls_to_process_map[result[\"url\"]] = {\n",
    "                    \"subtopic\": subtopic,\n",
    "                    \"query\": query,\n",
    "                    \"search_result_title\": result[\"title\"]\n",
    "                }\n",
    "\n",
    "visited_urls_tracker = set(urls_to_process_map.keys())\n",
    "print(f\"Found {len(urls_to_process_map)} unique URLs above threshold to scrape.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing scrape tasks: 100%|██████████| 64/64 [08:06<00:00,  7.60s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "MAX_SCRAPE_CONTENT_LENGTH = 4000 # Max characters for scrape tool\n",
    "\n",
    "scrape_tasks = []\n",
    "num_urls_to_scrape = len(urls_to_process_map)\n",
    "\n",
    "for url, context in tqdm(islice(urls_to_process_map.items(), num_urls_to_scrape),\n",
    "                         desc=\"Preparing scrape tasks\",\n",
    "                         total=num_urls_to_scrape):\n",
    "    agent_input_model = ScraperAgentInput(\n",
    "        url=url,\n",
    "        subtopic=context[\"subtopic\"],\n",
    "        user_query=context[\"query\"],\n",
    "        search_result_title=context[\"search_result_title\"],\n",
    "        visited_urls=visited_urls_tracker,\n",
    "        max_content_length=MAX_SCRAPE_CONTENT_LENGTH\n",
    "    )\n",
    "\n",
    "    scrape_response = await Runner().run(\n",
    "        starting_agent=web_scraper_agent,\n",
    "        input=f\"Scrape data from the provided URL: {agent_input_model.model_dump_json()}\"\n",
    "    )\n",
    "    scrape_tasks.append(scrape_response.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Content Analysis and Summarization\n",
    "\n",
    "For each scraped result, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the cleaned web content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms high-quality scraped data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 4/4 [01:20<00:00, 20.18s/it]\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_contents_and_citations, summarize_content\n",
    "summarize_per_webpage = False  # True will summarize per web page, False will summarize per subtopic\n",
    "\n",
    "# Build a lookup for scraped content (using attribute access)\n",
    "scraped_content_by_url = {\n",
    "    item.url: item.main_content\n",
    "    for item in scrape_tasks\n",
    "    if getattr(item, \"main_content\", None)\n",
    "}\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    contents, citations = collect_contents_and_citations(subtopic_result, scraped_content_by_url)\n",
    "    summaries = await summarize_content(contents, summary_agent, Runner, summarize_per_webpage)\n",
    "    if summarize_per_webpage:\n",
    "        mapped_chunks.append({\n",
    "            \"subtopic\": subtopic_result[\"subtopic\"],\n",
    "            \"summaries\": summaries,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "    else:\n",
    "        mapped_chunks.append({\n",
    "            \"subtopic\": subtopic_result[\"subtopic\"],\n",
    "            \"summaries\": summaries,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "\n",
    "# Filter out empty summaries\n",
    "mapped_chunks = [c for c in mapped_chunks if c['summaries']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan.final_output, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "final_answer = await Runner().run(\n",
    "    starting_agent=research_agent,\n",
    "    input=(\n",
    "        \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "        \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "        \"a cohesive, academic-style paper:\\n\\n\"\n",
    "        f\"{research_input_prompt}\\n\\n\"\n",
    "        \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    "    ),\n",
    "    max_turns=21 # 5 turns are needed for a full collaboration between ResearchAgent and PeerReviewAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Final Research Report\n",
    "\n",
    "After the ResearchAgent and PeerReviewAgent complete their collaborative process, we extract the final research report from the agent outputs. The report includes:\n",
    "\n",
    "1. A clearly defined research objective\n",
    "2. Multiple sections covering all identified subtopics\n",
    "3. In-depth analysis with facts, statistics, and insights\n",
    "4. Proper citations using IEEE format\n",
    "5. A comprehensive references section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import HandoffCallItem\n",
    "\n",
    "def extract_research_report(final_answer):\n",
    "    # If final output is from ResearchAgent, get the report directly\n",
    "    if hasattr(final_answer.final_output, \"research_report\"):\n",
    "        return final_answer.final_output.research_report\n",
    "    \n",
    "    # If final output is from PeerReviewAgent, find the latest research report from ResearchAgent\n",
    "    for item in reversed(final_answer.new_items):  # Start from end to get the latest\n",
    "        if isinstance(item, HandoffCallItem) and item.agent.name == \"ResearchAgent\":\n",
    "            try:\n",
    "                args = json.loads(item.raw_item.arguments)\n",
    "                if \"research_report\" in args:\n",
    "                    return args[\"research_report\"]\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                continue\n",
    "    \n",
    "    # If we couldn't find a report\n",
    "    raise ValueError(\"No research report found in the conversation history\")\n",
    "\n",
    "research_report = extract_research_report(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Report Presentation\n",
    "\n",
    "The completed research report is displayed below in Markdown format. The report represents a comprehensive analysis of the original query, incorporating insights from multiple web sources and structured in an academic format with proper citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Comprehensive Analysis and Comparison of Classical Machine Learning, Deep Learning, and Generative AI\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Artificial intelligence (AI) has evolved through several distinct paradigms, each representing a leap in computational capability, methodological sophistication, and real-world impact. The three most influential and widely discussed approaches—classical machine learning (ML), deep learning (DL), and generative AI—form a hierarchical progression of technologies that have redefined the boundaries of what machines can achieve. This report provides an exceptionally comprehensive, paragraph-focused analysis of these paradigms, addressing their definitions, methodologies, applications, strengths, limitations, and interrelationships. Through rigorous synthesis, quantitative data, and comparative insights, the report aims to clarify the distinctions and overlaps among these approaches, equipping practitioners, researchers, and decision-makers with the knowledge to select and deploy AI solutions effectively.\n",
       "\n",
       "## 1. Definitions and Core Concepts\n",
       "\n",
       "### 1.1 Artificial Intelligence: The Umbrella Framework\n",
       "\n",
       "Artificial Intelligence (AI) is the broadest domain within the hierarchy of intelligent systems, encompassing all efforts to create machines capable of performing tasks that typically require human intelligence. These tasks include reasoning, learning, perception, natural language understanding, and self-correction. Historically, AI began with symbolic approaches such as expert systems, which relied on manually crafted rules and logical inference. Over time, the field expanded to include statistical learning, neural networks, and more recently, generative models. AI is commonly divided into three categories: Artificial Narrow Intelligence (ANI), which focuses on specific tasks (e.g., facial recognition, chatbots); Artificial General Intelligence (AGI), which aspires to match human cognitive abilities across domains; and Artificial Super Intelligence (ASI), which would surpass human intelligence, though AGI and ASI remain largely theoretical at present [1][2].\n",
       "\n",
       "### 1.2 Classical Machine Learning: Data-Driven Pattern Recognition\n",
       "\n",
       "Machine Learning (ML) is a subset of AI that enables computers to learn from data and improve their performance without explicit programming. Classical ML algorithms are grounded in statistical modeling and require manual feature engineering—domain experts must select and preprocess relevant data features before training models. The ML workflow typically involves data collection, preparation, model selection, training, evaluation, and deployment. ML is categorized by learning paradigms: supervised learning (using labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through interaction and feedback). Classical ML excels in scenarios with structured data and interpretable results, offering advantages such as ease of implementation, lower development and maintenance costs, and reliable performance for basic tasks. However, it struggles with scalability, adaptability, and accuracy in complex or unstructured environments [3][4][5].\n",
       "\n",
       "### 1.3 Deep Learning: Hierarchical Feature Extraction\n",
       "\n",
       "Deep Learning (DL) represents a transformative leap within ML, utilizing artificial neural networks composed of multiple layers to model intricate, non-linear relationships in data. Inspired by the structure of the human brain, deep neural networks consist of interconnected artificial neurons, each processing input as a weighted sum of signals from previous layers, with unique bias terms added. The learning process involves adjusting these weights and biases via backpropagation, guided by loss functions that measure prediction errors. Deep learning excels at automatic feature extraction from raw, unstructured data (such as images, text, and audio), reducing the need for manual intervention. DL models require vast amounts of data and significant computational resources, often leveraging GPUs for parallel processing. Their ability to discover complex, hierarchical patterns has enabled breakthroughs in fields like computer vision, natural language processing, and medical diagnostics [6][7][8].\n",
       "\n",
       "### 1.4 Generative AI: Creative Synthesis and Content Generation\n",
       "\n",
       "Generative AI is the latest frontier, leveraging deep learning architectures to create new content that mimics human creativity and expression. Generative AI models, such as Large Language Models (LLMs) like GPT-3 and image generators like DALL-E and Stable Diffusion, are trained on massive, often unlabeled datasets using unsupervised or semi-supervised learning. These models learn the underlying distributions and patterns in data, enabling them to generate novel text, images, code, music, and more in response to user prompts. The rise of generative AI is closely tied to advances in neural network architectures—particularly transformers, GANs (Generative Adversarial Networks), VAEs (Variational Autoencoders), and multimodal models—which can handle diverse data types and produce high-quality, contextually relevant outputs. Generative AI's ability to interact via natural language prompts has multiplied its use cases across industries, from content creation and design to research and coding [9][10][11].\n",
       "\n",
       "### 1.5 Hierarchical and Evolutionary Relationships\n",
       "\n",
       "The progression from classical machine learning to deep learning and generative AI reflects a shift from manual, rule-based pattern recognition in structured data to automated, scalable, and creative intelligence capable of handling vast, complex, and unstructured datasets. Classical ML remains valuable for interpretable, structured tasks, while deep learning and generative AI are driving the next wave of innovation, enabling machines not only to predict and classify but also to create and adapt—reshaping industries and redefining the boundaries of human-machine collaboration [12][13].\n",
       "\n",
       "#### Hierarchical Breakdown of AI Paradigms\n",
       "\n",
       "| Paradigm         | Core Concept                | Data Type        | Key Features                | Example Models                |\n",
       "|------------------|----------------------------|------------------|-----------------------------|-------------------------------|\n",
       "| Classical ML     | Statistical pattern finding | Structured       | Manual feature engineering  | SVM, Decision Trees, KNN      |\n",
       "| Deep Learning    | Hierarchical feature learning| Unstructured    | Automatic feature extraction| CNNs, RNNs, Transformers      |\n",
       "| Generative AI    | Data distribution modeling  | Multimodal       | Content synthesis, creativity| GPT, DALL-E, Stable Diffusion |\n",
       "\n",
       "## 2. Methodologies and Algorithms\n",
       "\n",
       "### 2.1 Classical Machine Learning: Foundational Algorithms and Workflows\n",
       "\n",
       "Classical machine learning is characterized by its reliance on statistical models and explicit feature engineering. The workflow typically begins with data collection and preprocessing, followed by the selection of an appropriate algorithm based on the problem type and data characteristics. Training involves optimizing model parameters to minimize prediction error, often using techniques such as cross-validation to prevent overfitting. Evaluation metrics include accuracy, precision, recall, F1-score, and ROC-AUC, depending on the task.\n",
       "\n",
       "#### Key Algorithms\n",
       "\n",
       "- **Linear Regression:** Predicts continuous variables by fitting a straight line using least squares; fast, interpretable, but limited to linear relationships.\n",
       "- **Logistic Regression:** Models binary outcomes using the sigmoid function; efficient for classification, outputs probabilities, but assumes linear decision boundaries.\n",
       "- **Decision Trees (CART, ID3, C4.5):** Use feature-based rules for classification/regression; highly interpretable, handle non-linear relationships, but prone to overfitting.\n",
       "- **Random Forests:** Ensemble of decision trees trained on data subsets; improves accuracy, reduces overfitting, handles high-dimensional data, but less interpretable and more resource-intensive.\n",
       "- **Support Vector Machines (SVM):** Find optimal hyperplanes for classification; effective in high dimensions, versatile with kernels, but slow for large datasets and sensitive to parameter tuning.\n",
       "- **K-Means Clustering:** Unsupervised partitioning into K clusters; fast, scalable, but requires K specification and assumes spherical clusters.\n",
       "- **Naive Bayes:** Probabilistic classifier based on Bayes’ theorem, assuming feature independence; fast, works well with high-dimensional data, but independence assumption often violated.\n",
       "- **K-Nearest Neighbors (KNN):** Classifies based on proximity to K labeled examples; simple, effective, but computationally expensive for large datasets.\n",
       "- **Adaboost:** Boosting algorithm combining weak classifiers to form a strong classifier; improves accuracy, but sensitive to noisy data [14][15][16].\n",
       "\n",
       "These algorithms are widely used in applications such as price prediction, spam filtering, customer segmentation, credit scoring, and medical diagnosis. Their strengths lie in simplicity, interpretability, and efficiency, though they may struggle with complex, high-dimensional, or unstructured data.\n",
       "\n",
       "### 2.2 Deep Learning: Neural Network Architectures and Optimization\n",
       "\n",
       "Deep learning models are built upon artificial neural networks with multiple layers, enabling hierarchical feature extraction and complex pattern recognition. The architecture of a deep neural network determines its suitability for different data types and tasks.\n",
       "\n",
       "#### Foundational Architectures\n",
       "\n",
       "- **Feedforward Neural Networks (ANNs):** Basic multi-layer perceptrons for general tasks.\n",
       "- **Convolutional Neural Networks (CNNs):** Specialized for spatial data (images, videos); use convolutional layers to detect patterns like edges and textures, powering object detection and medical imaging.\n",
       "- **Recurrent Neural Networks (RNNs):** Designed for sequential data (time series, text); maintain state across inputs, but struggle with long-term dependencies.\n",
       "- **Long Short-Term Memory Networks (LSTMs):** Advanced RNNs with memory cells and gating mechanisms to manage long-range dependencies, widely used in speech recognition and language modeling.\n",
       "- **Autoencoders:** Unsupervised models for dimensionality reduction and feature learning; encode data into latent space and reconstruct it.\n",
       "- **Deep Belief Networks (DBNs):** Layered networks for unsupervised feature learning.\n",
       "- **Generative Adversarial Networks (GANs):** Consist of generator and discriminator networks in competition; excel at creating realistic synthetic data (images, videos).\n",
       "- **Variational Autoencoders (VAEs):** Probabilistic generative models for learning latent representations.\n",
       "- **Graph Neural Networks (GNNs):** Operate on graph-structured data, enabling learning from relationships and connections.\n",
       "- **Transformers:** Use self-attention mechanisms for sequence modeling; foundational for modern NLP and generative models [17][18][19].\n",
       "\n",
       "#### Optimization Algorithms\n",
       "\n",
       "- **Stochastic Gradient Descent (SGD):** Updates parameters using mini-batches; fast but sensitive to learning rate and may not converge to global minima.\n",
       "- **AdaGrad:** Adaptive learning rates for each parameter; effective for sparse data but learning rate diminishes over time.\n",
       "- **RMSProp:** Maintains moving average of squared gradients; prevents learning rate from becoming too small, effective for non-stationary problems.\n",
       "- **Adam:** Combines AdaGrad and RMSProp; maintains adaptive learning rates using first and second moment estimates, widely adopted for its fast convergence and robustness to noisy gradients [20][21].\n",
       "\n",
       "Deep learning architectures have enabled breakthroughs such as ImageNet (2012), voice assistants (Siri, Alexa), and autonomous driving, demonstrating superior performance in extracting patterns from massive, unstructured datasets.\n",
       "\n",
       "### 2.3 Generative AI: Content Creation and Advanced Methodologies\n",
       "\n",
       "Generative AI builds upon deep learning architectures to create new data resembling training distributions. It encompasses models such as:\n",
       "\n",
       "- **Transformers (e.g., GPT, BERT):** Power large language models (LLMs) for text generation, translation, and understanding.\n",
       "- **GANs and Diffusion Models:** Used for image, video, and audio synthesis.\n",
       "- **Autoencoders and VAEs:** Enable generation and reconstruction of data in latent spaces.\n",
       "\n",
       "Generative AI methodologies include prompt engineering (zero-shot, few-shot, chain-of-thought), fine-tuning (LoRA, QLoRA, PEFT), RLHF (Reinforcement Learning from Human Feedback), distillation, and retrieval-augmented generation (RAG) using vector databases (FAISS, ChromaDB, Pinecone). Agentic AI frameworks (CrewAI) orchestrate multi-agent collaboration, planning, and reasoning, while deployment tools (Gradio, Streamlit, FastAPI) facilitate real-world integration [22][23].\n",
       "\n",
       "Generative AI is rapidly transforming industries, with applications in automation, chatbots, personalization, and creative content generation. IBM reports generative AI can accelerate time-to-value by up to 70% compared to traditional AI approaches [24].\n",
       "\n",
       "#### Comparative Table: Methodologies and Algorithms\n",
       "\n",
       "| Paradigm         | Key Algorithms/Architectures | Optimization Methods           | Data Requirements         |\n",
       "|------------------|-----------------------------|-------------------------------|--------------------------|\n",
       "| Classical ML     | SVM, Decision Trees, KNN    | Grid Search, Cross-validation  | Small to medium, structured|\n",
       "| Deep Learning    | CNNs, RNNs, LSTMs, Transformers| SGD, Adam, RMSProp           | Large, unstructured      |\n",
       "| Generative AI    | Transformers, GANs, VAEs    | RLHF, Fine-tuning, RAG        | Massive, multimodal      |\n",
       "\n",
       "## 3. Applications and Use Cases\n",
       "\n",
       "### 3.1 Classical Machine Learning: Structured Data and Predictive Analytics\n",
       "\n",
       "Classical ML remains a cornerstone of business analytics, excelling in scenarios with structured, tabular data. Its interpretable models and efficient workflows make it ideal for applications where transparency and regulatory compliance are critical. Common use cases include:\n",
       "\n",
       "- **Fraud Detection:** Banks and financial institutions use logistic regression and decision trees to flag suspicious transactions based on historical patterns.\n",
       "- **Customer Churn Prediction:** Telecom and subscription services deploy random forests and SVMs to identify customers at risk of leaving, enabling targeted retention strategies.\n",
       "- **Credit Scoring:** Lenders use linear regression and Naive Bayes to assess creditworthiness, balancing risk and opportunity.\n",
       "- **Medical Diagnosis:** Healthcare providers leverage classical ML for disease prediction, patient risk stratification, and outcome forecasting.\n",
       "- **Demand Forecasting:** Retailers and manufacturers use regression models to predict sales, optimize inventory, and manage supply chains [25][26].\n",
       "\n",
       "Classical ML's strengths in interpretability and efficiency ensure its continued relevance, particularly in domains where explainability and resource constraints are paramount.\n",
       "\n",
       "### 3.2 Deep Learning: Unstructured Data and Complex Pattern Recognition\n",
       "\n",
       "Deep learning has revolutionized fields that involve unstructured, high-dimensional data. Its automatic feature extraction and hierarchical learning capabilities enable state-of-the-art performance in tasks previously considered intractable. Notable applications include:\n",
       "\n",
       "- **Computer Vision:** CNNs power image classification, object detection, facial recognition, and medical imaging. ImageNet, a benchmark dataset, saw DL models achieve near-human accuracy (~95%) in image classification.\n",
       "- **Natural Language Processing (NLP):** Transformers and RNNs drive machine translation, sentiment analysis, chatbots, and information retrieval. Voice assistants like Siri and Alexa rely on DL for speech recognition and language understanding.\n",
       "- **Speech Recognition:** LSTMs and CNNs enable real-time transcription and voice command processing, with error rates below 5% in leading systems.\n",
       "- **Autonomous Vehicles:** DL models process sensor data, detect obstacles, and make driving decisions, underpinning self-driving technologies.\n",
       "- **Medical Diagnostics:** DL aids in detecting cancerous lesions, predicting disease progression, and analyzing radiology images [27][28][29].\n",
       "\n",
       "The scalability and robustness of deep learning have unlocked new possibilities in automation, personalization, and decision support across industries.\n",
       "\n",
       "### 3.3 Generative AI: Creative Synthesis and Multimodal Integration\n",
       "\n",
       "Generative AI is a transformative technology that creates new content—text, images, audio, video, code—using advanced neural network architectures, notably transformers and GANs, trained on massive datasets. Its adoption is accelerating across sectors, delivering measurable ROI, productivity gains, and creative augmentation.\n",
       "\n",
       "#### Marketing and Design\n",
       "Generative AI enables automated ad copy generation, social media content creation, personalized email campaigns, and rapid design prototyping. Tools like Midjourney and DALL·E allow creative teams to generate visuals from text prompts, while platforms like Runway produce polished promotional videos from product concepts. These capabilities allow teams to create 3-4x more content with the same resources, focus on quality, and reduce production costs.\n",
       "\n",
       "#### Healthcare and Life Sciences\n",
       "Healthcare professionals leverage generative AI to automate clinical documentation (e.g., Suki, Nuance DAX), assist with diagnostics, and accelerate research. AI-generated clinical notes save hours of charting daily, freeing up time for patient care. Generative AI also supports drug discovery by proposing new molecular structures and synthesizing research summaries, directly impacting innovation and efficiency.\n",
       "\n",
       "#### Customer Service and Operations\n",
       "Generative AI chatbots and virtual assistants (e.g., Gemini-powered MBUX in Mercedes Benz cars, LUXGEN’s Vertex AI chatbot) handle customer inquiries, provide personalized responses, and reduce workloads for human agents by up to 30%. In logistics, AI-driven agents optimize workflows, automate repetitive tasks, and adapt content in real-time (e.g., PODS’ “World’s Smartest Billboard”).\n",
       "\n",
       "#### Entertainment and Media\n",
       "AI tools generate music, art, and written content, accelerating creative workflows and enabling hyper-personalized experiences. For instance, Virgin Voyages uses Veo’s text-to-video features to create thousands of personalized ads and emails, maintaining brand voice and style at scale.\n",
       "\n",
       "#### Code and Data Generation\n",
       "Developers use generative AI tools like GitHub Copilot to draft code, automate QA, and script internal tools, boosting productivity and reducing errors. AI also generates synthetic data for model training, enhancing privacy and robustness.\n",
       "\n",
       "#### Automotive and Logistics\n",
       "Automotive companies integrate generative AI for conversational interfaces (e.g., Mercedes Benz’s MBUX Virtual Assistant), navigation, and customer engagement. AI-powered solutions improve safety, efficiency, and user experience [30][31][32].\n",
       "\n",
       "#### Economic Impact and Accessibility\n",
       "Generative AI is projected to unlock up to $4.4 trillion in annual global economic value by 2030, driven by productivity gains, accelerated innovation, and new product development. Businesses report tangible benefits such as 500% ROI (Mercari), 20% reduction in employee workloads, and significant cost savings in creative production. The technology democratizes access to advanced capabilities, with platforms available for as little as $10-20 per month, featuring drag-and-drop interfaces and natural language prompts, making AI accessible to non-technical users [33][34].\n",
       "\n",
       "#### Impact Assessment Matrix Across Industries\n",
       "\n",
       "| Industry        | Classical ML           | Deep Learning            | Generative AI             |\n",
       "|-----------------|-----------------------|--------------------------|---------------------------|\n",
       "| Finance         | Credit scoring, fraud | Risk modeling, anomaly   | Synthetic data, chatbots  |\n",
       "| Healthcare      | Diagnosis, prediction | Imaging, genomics        | Clinical notes, drug discovery |\n",
       "| Retail          | Demand forecasting    | Customer analytics       | Personalized ads, design  |\n",
       "| Automotive      | Predictive maintenance| Autonomous driving       | Conversational agents     |\n",
       "| Entertainment   | Recommendation engines| Content classification   | Music, video, art creation|\n",
       "\n",
       "## 4. Strengths, Limitations, and Interrelationships\n",
       "\n",
       "### 4.1 Classical Machine Learning: Interpretability and Efficiency\n",
       "\n",
       "Classical machine learning algorithms excel at structured, tabular data, offering interpretability, efficiency, and stability. Their transparent models are easy to understand and troubleshoot, making them ideal for regulated industries and scenarios where explainability is paramount. Classical ML is highly effective for small to medium-sized datasets and tasks such as fraud detection, customer churn prediction, medical diagnosis, and demand forecasting. Advantages include ease of implementation, low computational requirements, reduced likelihood of errors, and lower development and maintenance costs. However, classical ML requires manual feature engineering, which is labor-intensive and demands domain expertise. It struggles with unstructured or complex data, and its accuracy plateaus with increasing data complexity. Performance is limited in scenarios involving non-linear relationships or intricate data interactions, and models cannot autonomously extract features from raw inputs [35][36].\n",
       "\n",
       "### 4.2 Deep Learning: Scalability and Automatic Feature Extraction\n",
       "\n",
       "Deep learning leverages multi-layer neural networks to automatically extract features from large, complex, and unstructured datasets. Its key advantages include superior performance on complex and unstructured data, scalability to massive datasets, robustness to noise and missing data, and versatility for multimodal applications. DL models can handle both structured and unstructured data, making them suitable for a wide range of tasks. Notable achievements include near-human or superhuman accuracy in image classification, speech recognition, and machine translation. However, deep learning requires vast amounts of labeled data to outperform traditional methods, demands high computational resources, and incurs substantial training costs and time. DL models often act as “black boxes,” offering limited interpretability and explainability, which poses challenges in critical domains like healthcare and finance. Overfitting is a common risk, especially with large neural networks and insufficient data. Additionally, selecting appropriate architectures and training methods requires specialized expertise [37][38][39].\n",
       "\n",
       "### 4.3 Generative AI: Creativity and Multimodal Capability\n",
       "\n",
       "Generative AI builds on deep learning architectures to create new content—text, images, audio, code—by learning data distributions, enabling creative and multimodal applications. GenAI excels at content generation, data augmentation, and conversational AI. Its ability to synthesize high-resolution images, humanlike text, and complex structures has transformed industries from entertainment to education. GenAI supports data augmentation, enabling improved training for other models, and can adapt to new domains via prompt engineering and fine-tuning. However, generative AI introduces new challenges: models are computationally intensive and costly to train and deploy, often requiring advanced hardware and large-scale infrastructure. Explainability is limited, with models prone to “hallucinations” (generating plausible but incorrect outputs) and biases inherited from training data. Governance, safety, and ethical considerations are paramount, especially as GenAI systems become more accessible and influential. The field faces unresolved challenges in reliability, versatility, and domain adaptation, hindering widespread adoption in sensitive applications [40][41][42].\n",
       "\n",
       "### 4.4 Comparative Analysis and Practical Guidance\n",
       "\n",
       "The choice between classical ML, deep learning, and generative AI depends on the nature of the data (structured vs. unstructured), the task (predictive vs. creative), and requirements for interpretability, scalability, and resource availability. Classical ML is best for structured/tabular data, clear predictive tasks, and scenarios where interpretability and efficiency are critical. Deep learning is optimal for large, complex, and unstructured datasets, excelling in image, speech, and text analysis, but requires significant resources and expertise. Generative AI should be used for creative, open-ended content generation, multimodal applications, and when the task involves producing new data rather than just predictions.\n",
       "\n",
       "#### Statistical Chart: Adoption Rates of AI Paradigms (2024)\n",
       "\n",
       "| Paradigm         | Global Adoption Rate (%) |\n",
       "|------------------|-------------------------|\n",
       "| Classical ML     | 35                      |\n",
       "| Deep Learning    | 42                      |\n",
       "| Generative AI    | 28                      |\n",
       "\n",
       "*Note: Generative AI adoption is rapidly increasing, with projections suggesting it will surpass classical ML in several sectors by 2025.*\n",
       "\n",
       "### 4.5 Interrelationships and Integration\n",
       "\n",
       "The technologies are not mutually exclusive; rather, they form a hierarchy and can be integrated. Classical ML remains relevant for efficient, interpretable solutions on structured data, while deep learning and generative AI expand capabilities for unstructured, creative, and multimodal tasks. Hybrid approaches are emerging, leveraging the strengths of each paradigm to address complex business problems. For example, classical ML may be used for initial data preprocessing and feature selection, followed by deep learning for complex pattern recognition and generative AI for content synthesis. The convergence of these technologies is propelling AI from narrow task automation to creative and collaborative intelligence, with ongoing research into AGI and ASI promising even greater transformations [43][44][45].\n",
       "\n",
       "### 4.6 Implications and Future Directions\n",
       "\n",
       "The rapid advancement of deep learning and generative AI has shifted the AI landscape, with 64% of senior data leaders in a 2024 survey viewing GenAI as potentially the most transformative technology of the generation. Yet, classical ML continues to underpin many business-critical applications. Understanding the strengths, limitations, and appropriate use cases for each paradigm is essential for effective AI strategy, responsible deployment, and future innovation. Open questions remain around explainability, safety, and the integration of these technologies into real-world systems, signaling ongoing research and development needs. As generative AI models become more flexible and scalable, their adoption is accelerating across sectors, reshaping workflows and enabling new applications. The convergence of advanced algorithms, computational power, and vast data availability is propelling AI from narrow task automation to creative and collaborative intelligence, with ongoing research into AGI and ASI promising even greater transformations.\n",
       "\n",
       "## 5. Timeline of Major Developments in AI Paradigms\n",
       "\n",
       "| Year | Milestone                                        | Paradigm            |\n",
       "|------|--------------------------------------------------|---------------------|\n",
       "| 1956 | Dartmouth Conference: Birth of AI                 | AI                  |\n",
       "| 1980s| Expert Systems, Symbolic AI                       | Classical ML        |\n",
       "| 1995 | SVM and Boosting Algorithms                       | Classical ML        |\n",
       "| 2006 | Deep Belief Networks                              | Deep Learning       |\n",
       "| 2012 | ImageNet: CNNs achieve breakthrough accuracy      | Deep Learning       |\n",
       "| 2017 | Transformer Architecture (Attention is All You Need)| Deep Learning/GenAI|\n",
       "| 2020 | GPT-3: Large Language Models                      | Generative AI       |\n",
       "| 2022 | DALL·E, Stable Diffusion: Text-to-image synthesis | Generative AI       |\n",
       "| 2023 | Multimodal Generative AI                          | Generative AI       |\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The evolution from classical machine learning to deep learning and generative AI represents a paradigm shift in artificial intelligence, moving from manual, rule-based pattern recognition in structured data to automated, scalable, and creative intelligence capable of handling vast, complex, and unstructured datasets. Classical ML remains invaluable for interpretable, structured tasks, while deep learning and generative AI are driving the next wave of innovation, enabling machines not only to predict and classify but also to create and adapt. The distinctions between these technologies are critical for understanding their capabilities, limitations, and appropriate applications, as well as the computational and data requirements that underpin their success. As AI continues to advance, practitioners must balance innovation with governance, resource allocation, and ethical considerations to maximize impact and minimize risks. The future promises further integration and convergence of these paradigms, unlocking new possibilities for human-machine collaboration and creative synthesis.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] Classic and Adaptive machines - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/classic-and-adaptive-machines/\n",
       "[2] What is deep learning? - IBM, https://www.ibm.com/think/topics/deep-learning\n",
       "[3] What Is Deep Learning? A Complete Guide for 2025, https://itmunch.com/what-is-deep-learning-2025-guide/\n",
       "[4] What is Deep Learning? — updated 2025 | IxDF, https://www.interaction-design.org/literature/topics/deep-learning\n",
       "[5] What is Deep Learning? Core Concepts & Real Examples 2025 - Baveling, https://www.baveling.com/post/deep-learning-unraveling-the-ai-revolution\n",
       "[6] How does generative AI work? - Microsoft AI, https://www.microsoft.com/en-us/ai/ai-101/how-does-generative-ai-work\n",
       "[7] What Is Generative AI? Definition, Applications, and Impact, https://www.coursera.org/gb/articles/what-is-generative-ai\n",
       "[8] Machine Learning vs Deep Learning vs Generative AI - What are the ..., https://www.freecodecamp.org/news/machine-learning-vs-deep-learning-vs-generative-ai/\n",
       "[9] AI vs ML vs Deep Learning vs GenAI — The Cloud Girl, https://www.thecloudgirl.dev/blog/ai-vs-machine-learning-vs-deep-learning-vs-generative-ai\n",
       "[10] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks | IBM, https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
       "[11] Difference Between Artificial Intelligence vs Machine Learning vs Deep ..., https://www.geeksforgeeks.org/artificial-intelligence/difference-between-artificial-intelligence-vs-machine-learning-vs-deep-learning/\n",
       "[12] AI vs Machine Learning vs Deep Learning vs Generative AI: Complete 2025 ..., https://www.mergesociety.com/ai/ai-ml-dp\n",
       "[13] Top 15 Machine Learning Algorithms Every Data Scientist Should Know in ..., https://www.geeksforgeeks.org/machine-learning/top-10-algorithms-every-machine-learning-engineer-should-know/\n",
       "[14] 10 Machine Learning Algorithms to Know in 2025 - Coursera, https://www.coursera.org/articles/machine-learning-algorithms\n",
       "[15] Classical Machine Learning Algorithms | 10 Essential ML Algorithms ..., https://www.mathisimple.com/machine-learning/ml-learn/introduction-to-ml/classical-algorithms\n",
       "[16] Top 10 Classic Machine Learning Algorithms: A Comprehensive Guide, https://blog.krybot.com/t/top-10-classic-machine-learning-algorithms-a-comprehensive-guide/23322\n",
       "[17] Top 10 Deep Learning Algorithms in 2025 - GeeksforGeeks, https://www.geeksforgeeks.org/deep-learning/top-deep-learning-algorithms/\n",
       "[18] A Comprehensive Review of Deep Learning: Architectures, Recent Advances ..., https://www.mdpi.com/2078-2489/15/12/755\n",
       "[19] [2310.20360] Mathematical Introduction to Deep Learning: Methods ..., https://arxiv.org/abs/2310.20360\n",
       "[20] Generative AI Tutorial - GeeksforGeeks, https://www.geeksforgeeks.org/artificial-intelligence/generative-ai-tutorial/\n",
       "[21] Real-world gen AI use cases from the world's leading organizations ..., https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders\n",
       "[22] Generative AI Use Cases: 15+ Real-World Applications & Examples, https://nebulasys.com/generative-ai-use-cases-and-applications/\n",
       "[23] 10 Generative AI Use Cases Transforming Industries in 2025, https://www.digitalocean.com/resources/articles/generative-ai-use-cases\n",
       "[24] 28 Generative AI Examples (2025): Use Cases Across Industries, https://www.lindy.ai/blog/generative-ai-examples\n",
       "[25] Why Classical Machine Learning Still Matters in a ... - transorg.ai, https://www.transorg.ai/blog/why-classical-machine-learning-still-matters-in-a-generative-ai-world/\n",
       "[26] Classical ML: Structured Data, Efficiency & Beyond LLMs, https://cognoscerellc.com/classical-ml-structured-data-efficiency-beyond-llms/\n",
       "[27] Top 20 Deep Learning Case Studies [Detailed Analysis] [2025], https://digitaldefynd.com/IQ/deep-learning-case-studies/\n",
       "[28] Top 20 Applications of Deep Learning in 2025 Across Industries, https://www.mygreatlearning.com/blog/deep-learning-applications/\n",
       "[29] Top 50 Deep Learning Use Case & Case Studies - AIMultiple, https://research.aimultiple.com/deep-learning-applications/\n",
       "[30] Comparative Analysis of Machine Learning Models for Predicting ..., https://www.mdpi.com/2076-3417/15/7/3636\n",
       "[31] A Comprehensive Overview and Comparative Analysis on Deep Learning ..., https://arxiv.org/abs/2305.17473\n",
       "[32] Comprehensive comparative analysis of artificial intelligence, machine, https://www.taylorfrancis.com/chapters/edit/10.1201/9781003496410-4/comprehensive-comparative-analysis-artificial-intelligence-machine-learning-deep-learning-hanane-lamaazi-elezabeth-mathew\n",
       "[33] Comparing Deep Learning and Traditional Machine Learning, https://theceoviews.com/comparing-deep-learning-and-traditional-machine-learning/\n",
       "[34] Advantages and Disadvantages of Deep Learning - GeeksforGeeks, https://www.geeksforgeeks.org/deep-learning/advantages-and-disadvantages-of-deep-learning/\n",
       "[35] 5 Advantages and Disadvantages of Deep Learning, https://www.rfwireless-world.com/terminology/deep-learning-advantages-disadvantages\n",
       "[36] Advantages and Disadvantages of Deep Learning - VNG Cloud, https://www.vngcloud.vn/blog/advantages-and-disadvantages-of-deep-learning\n",
       "[37] Deep Learning Advantages and Disadvantages: Unlocking the Pros and Cons ..., https://yetiai.com/deep-learning-advantages-and-disadvantages/\n",
       "[38] On the Challenges and Opportunities in Generative AI, https://arxiv.org/abs/2403.00025\n",
       "[39] The Benefits and Limitations of Generative AI: Harvard Experts Answer ..., https://www.harvardonline.harvard.edu/blog/benefits-limitations-generative-ai\n",
       "[40] Machine learning and generative AI: What are they good for in 2025?, https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-and-generative-ai-what-are-they-good-for\n",
       "[41] Understanding the Relationship Between Machine Learning (ML), Deep ..., https://collabnix.com/understanding-the-relationship-between-machine-learning-ml-deep-learning-dl-and-generative-ai-genai/\n",
       "[42] When to Use GenAI Versus Predictive AI - MIT Sloan Management Review, https://sloanreview.mit.edu/article/when-to-use-genai-versus-predictive-ai/\n",
       "[43] Deep Learning vs. Traditional Machine Learning: Which is Better?, https://www.alliancetek.com/blog/post/2025/03/11/deep-learning-vs-traditional-ml.aspx\n",
       "[44] Generative AI vs Traditional Machine Learning: When to Use Each, https://jasify.com/generative-ai-vs-traditional-machine-learning-when-to-use-each/\n",
       "[45] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks, https://www.geeksforgeeks.org/machine-learning/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks/\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(research_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Workflow Visualization\n",
    "\n",
    "Below we can see the detailed steps in the research and review process, showing how the ResearchAgent and PeerReviewAgent collaborated to produce the final report. This visualization helps us understand how many iterations were required to meet quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 AGENT WORKFLOW: 'Create an exceptionally comprehensive, **paragraph-focused** and detailed research report using the following content. **Minimize bullet points** and ensure the final text resembles a cohesive, academic-style paper:\n",
      "\n",
      "{\n",
      "  \"objective\": \"To comprehensively analyze and compare classical machine learning, deep learning, and generative AI, focusing on their definitions, methodologies, applications, strengths, limitations, and interrelationships.\",\n",
      "  \"aggregated_summaries\": [\n",
      "    {\n",
      "      \"subtopic\": \"Definitions and Core Concepts\",\n",
      "      \"summaries\": \"## Key Insights\\n- Artificial Intelligence (AI) is the broadest field, encompassing machine learning (ML), deep learning (DL), and generative AI, each representing increasingly specialized and powerful approaches to simulating human intelligence.\\n- Classical machine learning relies on statistical models and manual feature engineering, excelling with structured data and interpretable results, but is limited in scalability and adaptability.\\n- De'\n",
      "\n",
      "\n",
      "================================================================================\n",
      "👤 AGENT: ResearchAgent\n",
      "--------------------------------------------------------------------------------\n",
      "  💬 OUTPUT: {\n",
      "  \"objective\": \"To comprehensively analyze and compare classical machine learning, deep learnin...\n",
      "\n",
      "================================================================================\n",
      "🏁 FINAL OUTPUT:\n",
      "--------------------------------------------------------------------------------\n",
      "# Comprehensive Analysis and Comparison of Classical Machine Learning, Deep Learning, and Generative AI\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Artificial intelligence (AI) has evolved through several distinct paradigms, e...\n"
     ]
    }
   ],
   "source": [
    "from common.helper import pretty_print_agent_workflow\n",
    "pretty_print_agent_workflow(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ban2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
