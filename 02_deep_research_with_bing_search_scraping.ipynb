{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search & Scraping**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow now includes a dedicated scraping phase for extracting and cleaning web content:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Web Content Scraping** - Extracting, cleaning, and filtering relevant content from web pages using a ScraperAgent\n",
    "4. **Content Analysis** - Summarizing scraped results and extracting key insights\n",
    "5. **Report Generation** - Creating detailed research reports with proper citations\n",
    "6. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- WebScraperAgent - Extracts, cleans, and filters relevant content from web pages\n",
    "- SummaryAgent - Extracts key insights from scraped content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Projects, and the OpenAI Agents SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Environment Variables\n",
    "\n",
    "This notebook requires the following environment variables in your `.env` file:\n",
    "\n",
    "```bash\n",
    "# Azure OpenAI Configuration\n",
    "AOAI_ENDPOINT=your_azure_openai_endpoint\n",
    "AOAI_KEY=your_azure_openai_api_key\n",
    "AOAI_API_VERSION=2024-02-01  # Optional, defaults to this value\n",
    "\n",
    "# Model Deployment Names\n",
    "reasoningModel=your_reasoning_model_deployment_name  # e.g., o1-preview\n",
    "chatModel=your_chat_model_deployment_name  # e.g., gpt-4o\n",
    "\n",
    "# Azure AI Projects Configuration\n",
    "PROJECT_ENDPOINT=your_azure_ai_project_endpoint\n",
    "\n",
    "# Bing Search Agent (pre-created in Azure AI Foundry)\n",
    "bingSearchAgentID=your_bing_search_agent_id\n",
    "BING_CONNECTION_NAME=your_bing_connection_name  # Only needed if creating agent inline\n",
    "```\n",
    "\n",
    "**Note:** This notebook extends notebook 01 by adding web scraping capabilities. Like notebook 01, it creates agents inline using the OpenAI Agents SDK, except for the Bing Search agent which must be pre-created in Azure AI Foundry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Azure OpenAI to work with OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from agents import (\n",
    "    set_default_openai_client,\n",
    "    set_tracing_disabled,\n",
    "    OpenAIChatCompletionsModel\n",
    ")\n",
    "\n",
    "# setup settings\n",
    "from openai import AsyncAzureOpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Use the synchronous client instead of the async one\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AOAI_KEY\"),\n",
    "    api_version=os.environ.get(\"AOAI_API_VERSION\", \"2024-02-01\")\n",
    ")\n",
    "\n",
    "# Configure SDK\n",
    "set_default_openai_client(openai_client)\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "reasoningModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"reasoningModel\"), \n",
    "    openai_client=openai_client\n",
    ")\n",
    "\n",
    "chatModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    openai_client=openai_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models for Research Workflow\n",
    "\n",
    "The following Pydantic models define the structured data used throughout our research process:\n",
    "\n",
    "1. **ResearchTask** - Represents an individual research task with specific search queries\n",
    "2. **ResearchPlan** - Contains the overall plan with research objectives and tasks\n",
    "3. **Citation** - Stores source information for proper attribution\n",
    "4. **ComprehensiveResearchReport** - Defines the structure of the final research output\n",
    "5. **PeerReviewFeedback** - Contains structured feedback on report quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResearchTask(BaseModel):\n",
    "    id: Optional[str] = Field(None, description=\"Unique identifier for the task\")\n",
    "    subtopic: str = Field(..., description=\"Subtopic to research\")\n",
    "    search_queries: List[str] = Field(..., description=\"List of search queries to explore this subtopic\")\n",
    "    completed: bool = Field(..., description=\"Status of task completion\")\n",
    "\n",
    "class ResearchPlan(BaseModel):\n",
    "    query: str = Field(..., description=\"The original user query that prompted this research\")\n",
    "    objective: str = Field(..., description=\"The overall research objective, clearly defined\")\n",
    "    success_criteria: List[str] = Field(..., description=\"Criteria to determine when the research is sufficiently complete.\")\n",
    "    related_topics: List[str] = Field(..., description=\"List of related topics that may be useful for the research.\")\n",
    "    research_tasks: List[ResearchTask] = Field(..., description=\"List of specific research tasks to complete. Each task focuses on a subtopic.\")\n",
    "\n",
    "class ScrapedWebPage(BaseModel):\n",
    "    url: str = Field(..., description=\"The original URL that was scraped\")\n",
    "    title: Optional[str] = Field(None, description=\"The page title (if available, else None)\")\n",
    "    main_content: Optional[str] = Field(None, description=\"The main textual content of the page, cleaned and potentially truncated (if available, else None)\")\n",
    "    source: Optional[str] = Field(None, description=\"The name of the source (if available, else None)\")\n",
    "    published_date: Optional[str] = Field(None, description=\"YYYY-MM-DD (if available, else None)\")\n",
    "    scrape_error: Optional[str] = Field(None, description=\"Error message if scraping failed, else None\")\n",
    "    # Fields below might be added by the agent based on instructions, not the tool directly\n",
    "    extraction_method: Optional[str] = Field(None, description=\"How content was extracted (e.g., 'tool_extracted', 'agent_filtered')\") \n",
    "    relevance_score_agent: Optional[float] = Field(None, description=\"Agent's assessment of relevance (0-10)\")\n",
    "    matched_sections: Optional[List[str]] = Field(None, description=\"Sections identified by the agent as relevant\")\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "\n",
    "class ComprehensiveResearchReport(BaseModel):\n",
    "    objective: str = Field(..., description=\"The original research objective\")\n",
    "    research_report: str = Field(..., description=(\n",
    "        \"Comprehensive research report in markdown. \"\n",
    "        \"It should be structured with meaningful headings and subsections, but emphasize **fully-developed paragraphs**. \"\n",
    "        \"It should be long and detailed, and it should fully addresses the objectives, \"\n",
    "        \"and the various subtopics required to achieve the success criteria. \"\n",
    "        \"Use bullet points or lists **only** when they genuinely improve clarity (e.g., summarizing key data). \"\n",
    "        \"Tables and other data visualizations are encouraged. \"\n",
    "        \"The research report should always be long and detailed.\\n\\n\" \n",
    "        \"For citations, please use the IEEE (Institute of Electrical and Electronics Engineers). \"\n",
    "        \"How it works:\\n\\n\"\n",
    "        \"   1. In the text, use numbered citations in brackets [1].\\n\"\n",
    "        \"   2. At the end of the report, provide a list of citations in the format \"\n",
    "        \"(the list should ONLY contain the sources used in the free text of the research report. \"\n",
    "        \"Do NOT list sources which are not cited in the free text of the research report.):\\n\\n\"\n",
    "        \"       [1] Title of the source, URL.\"\n",
    "    ))\n",
    "    citations: List[Citation] = Field(..., description=(\n",
    "        \"List of citations (title and URL), corresponding to references actually used in research_report. \"\n",
    "        \"Do not add references that are not cited within the text.\"\n",
    "    ))\n",
    "    identified_gaps: Optional[List[str]] = Field(default=None, description=\"Identified information gaps.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Suggestions for additional research.\")\n",
    "\n",
    "class PeerReviewFeedback(BaseModel):\n",
    "    overall_feedback: str = Field(..., description=\"General feedback on the report.\")\n",
    "    strengths: List[str] = Field(..., description=\"Aspects of the report that are well done.\")\n",
    "    suggested_improvements: List[str] = Field(..., description=\"Specific suggestions to improve clarity, completeness, accuracy, or structure.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Additional research queries that could strengthen the report.\")\n",
    "    is_satisfactory: bool = Field(..., description=\"Indicates if the report meets all quality standards and no further revisions are needed.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "The research workflow is powered by two types of agents:\n",
    "\n",
    "1. **Azure AI Agents** - Created using Azure AI Projects for web search capabilities\n",
    "2. **OpenAI Agents** - For specialized research tasks\n",
    "\n",
    "Let's configure each type of agent with their specific instructions and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Bing Search Agent (One-time Setup)\n",
    "\n",
    "The following cell will **create** an **Azure AI Agent** with Bing Search capabilities. You only need to run this cell **once** to create the agent, then save its ID to your `.env` file as `bingSearchAgentID`.\n",
    "\n",
    "If you already have a Bing Search agent created, skip this cell and use the next cell to update its instructions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import BingGroundingTool\n",
    "\n",
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bing_connection = project_client.connections.get(\n",
    "    name=os.getenv(\"BING_CONNECTION_NAME\")\n",
    ")\n",
    "\n",
    "bing_tool = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "bing_search_agent = project_client.agents.create_agent(\n",
    "    name=\"bingSearchAgent\",\n",
    "    description=\"Agent to perform web searches using Bing.\",\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    temperature=0.5,\n",
    "    tools=bing_tool.definitions,\n",
    "    instructions=f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "    \"\"\".strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Existing Bing Search Agent\n",
    "\n",
    "If you already have a Bing Search agent (with its ID in your `.env` file), run this cell to update its instructions with today's date. This ensures the agent has current date awareness for time-sensitive queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful research assistant.\n",
      "\n",
      "Today's date is 2025-11-10.\n",
      "\n",
      "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
      "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
      "Provide a comprehensive answer based on the search results.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "bing_search_agent.instructions = f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(bing_search_agent.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating OpenAI Agents\n",
    "\n",
    "The following agents are created inline using the OpenAI Agents SDK:\n",
    "- **PlannerAgent** - Creates research plans\n",
    "- **WebScraperAgent** - Scrapes and filters web content (new in this notebook)\n",
    "- **SummaryAgent** - Summarizes scraped content\n",
    "- **ResearchAgent** - Generates comprehensive reports\n",
    "- **PeerReviewAgent** - Provides quality feedback\n",
    "\n",
    "These agents are created fresh each time you run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    Agent,\n",
    "    ModelSettings\n",
    ")\n",
    "\n",
    "from common.utils_scraping import scrape_web_page\n",
    "\n",
    "chatModelSettings=ModelSettings(\n",
    "        max_tokens=32768,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "\n",
    "    You are an expert research planner specializing in creating detailed research plans your task is to analyze a user's research query and create a structured research plan.\n",
    "    with the following components:\n",
    "    \n",
    "    1. DOMAIN CLASSIFICATION:\n",
    "       Classify the query into a fitting domain (e.g., technology, business, etc.).\n",
    "       The Domain is not included in the output, but it is important for the other components in the research plan.\n",
    "       The domain should be a single word (e.g., technology, business, etc.).\n",
    "       \n",
    "    2. RESEARCH OBJECTIVE:\n",
    "       Create a clear, comprehensive objective statement for the research\n",
    "       \n",
    "    3. SUBTOPICS:\n",
    "       Generate relevant subtopics that should be explored to thoroughly answer the query (Important. generate no less than 4 subtopics)\n",
    "       \n",
    "    4. SEARCH QUERIES:\n",
    "       For each subtopic, provide search queries that will yield valuable results (Important. It's better to generate more queries than less queries, but at least 2 queries per subtopic)\n",
    "       \n",
    "    5. SUCCESS CRITERIA:\n",
    "       List the criteria that will determine when the research is complete (Important. generate no less than 4 success criteria)\n",
    "       Take all of the above into account (e.g., the domain, objective, subtopics, and search queries) to create the success criteria.\n",
    "       \n",
    "    6. RELATED TOPICS:\n",
    "       suggest related topics that may be useful for the research (Important. generate no less than 3 related topics)\n",
    "    \n",
    "    Ensure each subtopic is thorough and directly relevant to the research query.\n",
    "    The search queries should be specific enough to return high-quality results.\n",
    "    \"\"\".strip(),\n",
    "    model=chatModel,\n",
    "    output_type=ResearchPlan,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "web_scraper_agent = Agent(\n",
    "    name=\"WebScraperAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "    \n",
    "    You are a robust, context-aware web scraping specialist. Your primary tool is 'scrape_web_page'.\n",
    "\n",
    "    Your input is a JSON string containing: 'url', 'subtopic', 'user_query', 'search_result_title', 'visited_urls', and 'max_content_length'. Parse this JSON to get the necessary information.\n",
    "\n",
    "    **Workflow:**\n",
    "    1.  **Parse Input:** Extract 'url', 'user_query', 'subtopic', 'search_result_summary', and 'max_content_length' from the input JSON string.\n",
    "    2.  **Call Scraping Tool:** Call the `scrape_web_page` tool with the 'url' and 'max_content_length'.\n",
    "    3.  **Analyze Tool Output:** Receive the dictionary from the tool containing `url`, `title`, `main_content`, `source`, `published_date`, `scrape_error`.\n",
    "    4.  **Contextual Filtering (If Content Exists and No Error):**\n",
    "        - If `scrape_error` is None and `main_content` exists:\n",
    "            - Review the `main_content`.\n",
    "            - Use the `user_query`, `subtopic`, and `search_result_summary` to identify ONLY the most relevant paragraphs or sections.\n",
    "            - If the entire `main_content` seems relevant or is short, keep it all.\n",
    "            - If filtering, replace `main_content` with ONLY the relevant extracted parts. Set `extraction_method` to 'agent_filtered'.\n",
    "            - Estimate a `relevance_score_agent` (0-10).\n",
    "            - Optionally list `matched_sections`.\n",
    "        - If `scrape_error` is present, ensure the `scrape_error` field in your output reflects the tool's error.\n",
    "    5.  **Format Output:** Return a SINGLE JSON object matching the `ScrapedWebPage` Pydantic model, including all fields based on the tool's output and your filtering. If the tool failed, `main_content` should be None/empty, and `scrape_error` should be set.\n",
    "    6.  **Return JSON object:** Return ONLY the final object formatted as a single, valid JSON. Do NOT add any explanatory text before or after the JSON.\n",
    "\n",
    "    **Constraints:**\n",
    "    - Your final output MUST be ONLY a valid JSON representing the scraped and processed data.\n",
    "    - Adhere strictly to the field names defined in the conceptual `ScrapedWebPage` structure when creating the JSON.\n",
    "    - Prioritize accuracy and relevance based on the provided context.\n",
    "    \"\"\",\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    tools=[scrape_web_page],\n",
    "    output_type=ScrapedWebPage\n",
    ")\n",
    "\n",
    "summary_agent = Agent(\n",
    "    name=\"SummaryAgent\",\n",
    "    instructions=(\n",
    "        \"You are a comprehensive research summarization specialist. Your task is to **synthesize information from combined search result content** related to a specific subtopic (which will be mentioned in the input prompt). \"\n",
    "        \"Create a **single, coherent, detailed, and information-rich summary** that:\\n\\n\"\n",
    "        \"1. Extracts ALL important facts, statistics, findings, and insights **relevant to the specified subtopic** from the combined text.\\n\"\n",
    "        \"2. Preserves specific numbers, percentages, dates, and technical details whenever present.\\n\"\n",
    "        \"3. Includes industry-specific terminology and concepts that add depth to the research.\\n\"\n",
    "        \"4. **Synthesizes** the key arguments and conclusions from the provided sources. If sources present different perspectives or data, try to capture that nuance.\\n\"\n",
    "        \"5. Provides thorough explanations rather than superficial overviews, integrating information smoothly.\\n\"\n",
    "        \"6. For technical content, preserves methodologies, technical specifications, and implementation details.\\n\"\n",
    "        \"7. For comparative content, maintains all sides of the comparison with their specific attributes.\\n\\n\"\n",
    "\n",
    "        \"**Acknowledge that the input combines information potentially from multiple search results.** Your goal is to create a unified summary focused on the overall subtopic, not just list summaries of individual parts.\\n\\n\"\n",
    "\n",
    "        \"Remember that your summary serves as the foundation for generating a comprehensive research report. The quality and depth of the final research report depends directly on how comprehensive and well-synthesized your summary is. Ensure it captures the essence of all provided content relevant to the subtopic.\\n\\n\"\n",
    "\n",
    "        \"FORMAT YOUR SUMMARY AS:\\n\"\n",
    "        \"## Key Insights\\n\"\n",
    "        \"- [Most critical takeaway #1]\\n\"\n",
    "        \"- [Most critical takeaway #2]\\n\"\n",
    "        \"- [Most critical takeaway #3]\\n\"\n",
    "        \"- [Optional: Most critical takeaway #4]\\n\\n\"\n",
    "        \"## Extensive Synthesis\\n\"\n",
    "        \"Write a thorough, multi-paragraph synthesis that:\\n\"\n",
    "        \"- Integrates all important facts, statistics, findings, and insights relevant to the subtopic.\\n\"\n",
    "        \"- Preserves specific numbers, percentages, dates, and technical details.\\n\"\n",
    "        \"- Explains methodologies, technical specifications, and implementation details where relevant.\\n\"\n",
    "        \"- Highlights agreements, disagreements, and nuances between sources.\\n\"\n",
    "        \"- Uses industry-specific terminology and concepts.\\n\"\n",
    "        \"- Provides context, background, and implications for the findings.\\n\"\n",
    "        \"- Maintains logical flow: start with an overview, then go into specifics, and conclude with implications or open questions.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    output_type=str,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    instructions=(\n",
    "        \"## General Instructions\\n\"\n",
    "        \"You are a meticulous research analyst specializing in creating **long, comprehensive, authoritative** reports. \"\n",
    "        \"Your goal is to produce **in-depth, highly detailed** content that thoroughly analyzes all aspects of the research topic. \"\n",
    "        \"Furthermore, you must also demonstrate subject matter expertise with nuanced insights, technical details, and sophisticated analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Style & Format:\\n\"\n",
    "        \"- **Default to paragraphs.** Present your findings in cohesive, well-structured paragraphs rather than excessive bullet points.\\n\"\n",
    "        \"- **Use bullet points sparingly.** Only use them when they add genuine clarity—e.g., summarizing key data.\\n\"\n",
    "        \"- **Structure** the report with a clear hierarchy, but avoid excessive nesting. Aim for a balanced structure:\\n\"\n",
    "        \"   - Use main sections and occasional subsections where needed.\\n\"\n",
    "        \"   - Avoid over-fragmentation by limiting sub-subsections unless absolutely necessary.\\n\"\n",
    "        \"   - Favor broader thematic groupings to maintain narrative flow and reduce section clutter.\\n\"\n",
    "        \"   - With that said, if a subtopic would benefit from a sub-subsection, feel free to add it.\\n\"\n",
    "        \"- **Data visualizations** (e.g., tables, charts, diagrams) in Markdown are encouraged wherever they enhance understanding.\\n\"\n",
    "        \"- Maintain a logical, flowing structure so each subsection builds upon the prior sections.\\n\"\n",
    "        \"- **Citations:** Use IEEE style: [1], [2], etc. Provide a 'References' section at the end of your report with only the sources cited in the text.\\n\\n\"\n",
    "        \n",
    "        \"### Long & Comprehensive Requirement:\\n\"\n",
    "        \"- The final report must be the equivalent of **10 to 12 pages** of substantive text, approximately **7000-9000 words**.\\n\"\n",
    "        \"- Each major section should have **extensive exploration** (ideally 800-1000 words per section).\\n\"\n",
    "        \"- Ensure thorough coverage of the topic with **well-developed paragraphs**, plenty of detail, and rigorous analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Depth Requirements:\\n\"\n",
    "        \"- Include **quantitative data**, statistics, and specific examples to support your arguments.\\n\"\n",
    "        \"- Compare and contrast **multiple perspectives** on complex topics.\\n\"\n",
    "        \"- Integrate ideas across sections for a cohesive, synthesized analysis rather than isolated observations.\\n\\n\"\n",
    "        \n",
    "        \"### Workflow\\n\"\n",
    "        \"- When given the research objective and content, develop a **long-form narrative** with detailed explanations.\\n\"\n",
    "        \"- If PeerReviewAgent provides feedback, revise thoroughly, addressing all points.\\n\"\n",
    "        \"- Once feedback is marked satisfactory, present the final report.\\n\\n\"\n",
    "        \n",
    "        \"### Important Guidelines\\n\"\n",
    "        \"- Retain high-quality content in any revision.\\n\"\n",
    "        \"- If feedback highlights missing info, propose specific research queries.\\n\"\n",
    "        \"- Avoid unnecessary repetition.\\n\\n\"\n",
    "\n",
    "        \"**REMINDER**:\"\n",
    "        \"Your output should be a single, cohesive Markdown document that reads like a well-developed academic or professional paper, with minimal use of bullet points. \"\n",
    "        \"Prefer broader thematic sections over excessive fragmentation. \"\n",
    "        \"Sub-subsections may be used where helpful, but structure should remain balanced and readable. \"\n",
    "        \"Lastly, do not forget to include the references section at the end of the report.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=ComprehensiveResearchReport,\n",
    ")\n",
    "\n",
    "\n",
    "peer_review_agent = Agent(\n",
    "    name=\"PeerReviewAgent\",\n",
    "    instructions=(\n",
    "        \"You are a critical yet constructive peer reviewer evaluating research reports. \"\n",
    "        \"Your goal is to provide detailed, actionable feedback using a structured evaluation framework.\\n\\n\"\n",
    "        \n",
    "        \"## Evaluation Framework:\\n\"\n",
    "        \"1. COMPLETENESS (0-10): Does the report thoroughly cover all aspects of the research topic?\\n\"\n",
    "        \"   - Are all required subtopics adequately addressed?\\n\"\n",
    "        \"   - Is there sufficient depth in each section (500+ words per major section)?\\n\"\n",
    "        \"   - Are there any obvious gaps or missing perspectives?\\n\\n\"\n",
    "        \n",
    "        \"2. CLARITY & STRUCTURE (0-10): Is the report well-organized and clearly written?\\n\"\n",
    "        \"   - Does it have a logical flow with clear sections and subsections?\\n\"\n",
    "        \"   - Are complex concepts explained in accessible language?\\n\"\n",
    "        \"   - Does it use formatting effectively (headings, lists, tables)?\\n\\n\"\n",
    "        \n",
    "        \"3. EVIDENCE & SUPPORT (0-10): Is information well-supported?\\n\"\n",
    "        \"   - Are claims backed by data, statistics, or authoritative sources?\\n\"\n",
    "        \"   - Are citations used appropriately and consistently?\\n\"\n",
    "        \"   - Does it include multiple perspectives when appropriate?\\n\\n\"\n",
    "        \n",
    "        \"4. ANALYSIS & INSIGHT (0-10): Does the report provide valuable analysis?\\n\"\n",
    "        \"   - Does it go beyond summarizing to provide meaningful insights?\\n\"\n",
    "        \"   - Does it connect ideas across different sections?\\n\"\n",
    "        \"   - Does it identify implications and future directions?\\n\\n\"\n",
    "        \n",
    "        \"## Response Guidelines:\\n\"\n",
    "        \"- For each criterion, provide a score (0-10) and specific feedback citing examples from the report\\n\"\n",
    "        \"- In your overall assessment, calculate a total score (0-40)\\n\"\n",
    "        \"- Reports scoring 32+ (80%) can be marked as satisfactory\\n\"\n",
    "        \"- For reports below 32, provide clear, prioritized improvement suggestions\\n\"\n",
    "        \"- Be constructive and specific - point to exact sections that need improvement\\n\"\n",
    "        \n",
    "        \"\\n\\n## Important Rules:\"\n",
    "        \"\\n- If the report meets all quality standards (score ≥32), simply confirm this by changing the is_satisfactory field to true and hand it back to ResearchAgent.\"\n",
    "        \"\\n- Always perform a handoff to ResearchAgent for final report generation.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=PeerReviewFeedback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hand-offs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent.handoffs = [peer_review_agent]\n",
    "peer_review_agent.handoffs = [research_agent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Web Content Scraping** → WebScraperAgent extracts, cleans, and filters relevant content from web pages\n",
    "5. **Analysis** → SummaryAgent processes scraped results, extracting key insights while preserving technical details\n",
    "6. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "7. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "8. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "9. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.2 (20251019.1705)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"162pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 162.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.700798 0.700798) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 2256.28,-227 2256.28,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1347.54,-8C1347.54,-8 2003.79,-8 2003.79,-8 2009.79,-8 2015.79,-14 2015.79,-20 2015.79,-20 2015.79,-203 2015.79,-203 2015.79,-209 2009.79,-215 2003.79,-215 2003.79,-215 1347.54,-215 1347.54,-215 1341.54,-215 1335.54,-209 1335.54,-203 1335.54,-203 1335.54,-20 1335.54,-20 1335.54,-14 1341.54,-8 1347.54,-8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1675.67\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.85,-72.79C133.42,-72.47 159.62,-72.62 216.49,-73.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.33,-76.71 226.36,-73.32 216.4,-69.71 216.33,-76.71\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.43,-72.26C370.75,-71.89 396.11,-72.04 445.47,-72.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.17,-76.21 455.22,-72.84 445.27,-69.21 445.17,-76.21\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- scraper -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>scraper</title>\n",
       "<path fill=\"#fff5cc\" stroke=\"#4472c4\" d=\"M822.54,-92.25C822.54,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 822.54,-55.75 822.54,-55.75 828.54,-55.75 834.54,-61.75 834.54,-67.75 834.54,-67.75 834.54,-80.25 834.54,-80.25 834.54,-86.25 828.54,-92.25 822.54,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"785.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ScraperAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"785.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Data Extraction</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;scraper -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;scraper</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.3,-71.02C636.13,-70.81 667.42,-71.34 725.15,-72.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"725.06,-76.12 735.14,-72.85 725.22,-69.13 725.06,-76.12\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M1183.29,-92.25C1183.29,-92.25 1006.04,-92.25 1006.04,-92.25 1000.04,-92.25 994.04,-86.25 994.04,-80.25 994.04,-80.25 994.04,-67.75 994.04,-67.75 994.04,-61.75 1000.04,-55.75 1006.04,-55.75 1006.04,-55.75 1183.29,-55.75 1183.29,-55.75 1189.29,-55.75 1195.29,-61.75 1195.29,-67.75 1195.29,-67.75 1195.29,-80.25 1195.29,-80.25 1195.29,-86.25 1189.29,-92.25 1183.29,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1094.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1094.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- scraper&#45;&gt;summary -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>scraper&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M834.66,-67.98C874.05,-63.85 903.47,-63.79 982.25,-67.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"982.02,-71.29 992.19,-68.31 982.38,-64.29 982.02,-71.29\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"914.29\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Cleaned Data</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1445.79,-92.25C1445.79,-92.25 1355.54,-92.25 1355.54,-92.25 1349.54,-92.25 1343.54,-86.25 1343.54,-80.25 1343.54,-80.25 1343.54,-67.75 1343.54,-67.75 1343.54,-61.75 1349.54,-55.75 1355.54,-55.75 1355.54,-55.75 1445.79,-55.75 1445.79,-55.75 1451.79,-55.75 1457.79,-61.75 1457.79,-67.75 1457.79,-67.75 1457.79,-80.25 1457.79,-80.25 1457.79,-86.25 1451.79,-92.25 1445.79,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1400.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1400.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1195.42,-65.59C1266.57,-60 1299.1,-58.99 1331.97,-62.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1331.33,-65.98 1341.68,-63.73 1332.18,-59.03 1331.33,-65.98\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1269.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1673.79,-52.25C1673.79,-52.25 1584.29,-52.25 1584.29,-52.25 1578.29,-52.25 1572.29,-46.25 1572.29,-40.25 1572.29,-40.25 1572.29,-27.75 1572.29,-27.75 1572.29,-21.75 1578.29,-15.75 1584.29,-15.75 1584.29,-15.75 1673.79,-15.75 1673.79,-15.75 1679.79,-15.75 1685.79,-21.75 1685.79,-27.75 1685.79,-27.75 1685.79,-40.25 1685.79,-40.25 1685.79,-46.25 1679.79,-52.25 1673.79,-52.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1629.04\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1629.04\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1458.28,-64.35C1510.39,-55.62 1538.37,-50.88 1560.78,-46.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1561.38,-50.32 1570.6,-45.1 1560.14,-43.43 1561.38,-50.32\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1515.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1907.94,-105.94C1907.94,-105.94 1841.39,-78.56 1841.39,-78.56 1835.84,-76.28 1835.84,-71.72 1841.39,-69.44 1841.39,-69.44 1907.94,-42.06 1907.94,-42.06 1913.49,-39.78 1924.59,-39.78 1930.14,-42.06 1930.14,-42.06 1996.69,-69.44 1996.69,-69.44 2002.24,-71.72 2002.24,-76.28 1996.69,-78.56 1996.69,-78.56 1930.14,-105.94 1930.14,-105.94 1924.59,-108.22 1913.49,-108.22 1907.94,-105.94\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1919.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1919.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1469.35,-72.63C1698.71,-68.06 1755.47,-67.33 1837.88,-70.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1469.38,-69.13 1459.45,-72.82 1469.52,-76.12 1469.38,-69.13\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1629.04\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1685.97,-38.17C1781.93,-45.29 1818.8,-48.76 1854.31,-56.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1853.35,-59.92 1863.88,-58.77 1854.94,-53.1 1853.35,-59.92\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1758.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"2183.16\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2183.16\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2183.16\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2006.35,-73.01C2052.44,-72.52 2079.95,-72.32 2102.43,-72.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2102.27,-75.92 2112.29,-72.49 2102.31,-68.92 2102.27,-75.92\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2060.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x23cd2d3f7a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram_scraper\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram_scraper()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affect on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "plan = await Runner().run(\n",
    "    starting_agent=planner_agent,\n",
    "    input=user_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is classical machine learning?',\n",
       " 'Definition of deep learning in artificial intelligence',\n",
       " 'What is generative AI and how does it work?',\n",
       " 'Difference between classical ML, deep learning, and generative AI']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.final_output.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. Multiple search queries are sent to gather diverse perspectives.\n",
    "2. The agent returns structured search results with titles, summaries, relevance scores, and URLs.\n",
    "3. Results are organized by subtopic for further processing.\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to identify promising sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics: 100%|██████████| 4/4 [04:43<00:00, 70.89s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.final_output.research_tasks, desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            message = project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=formatted_query,\n",
    "            )\n",
    "\n",
    "            # Process the run\n",
    "            run = project_client.agents.runs.create_and_process(\n",
    "                thread_id=thread.id,\n",
    "                agent_id=bing_search_agent.id\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 16\n",
      "\n",
      "Actually total search queries: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.final_output.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Web Content Scraping\n",
    "\n",
    "The WebScraperAgent processes the URLs and metadata returned by the BingSearchAgent. For each subtopic:\n",
    "\n",
    "1. Only URLs with a high enough relevance score are selected for scraping.\n",
    "2. The WebScraperAgent visits each selected URL and extracts the most relevant content, guided by the user query, subtopic, and search result summary.\n",
    "3. Extracted content is cleaned, deduplicated, and enriched with metadata such as title, source, published date, and extraction method.\n",
    "4. The resulting structured data is organized by subtopic for downstream analysis and summarization.\n",
    "\n",
    "This step ensures that only the most promising and contextually relevant web content is collected, providing a high-quality foundation for subsequent summarization and synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "class ScraperAgentInput(BaseModel):\n",
    "    url: str\n",
    "    subtopic: str\n",
    "    user_query: str\n",
    "    search_result_title: str\n",
    "    visited_urls: Set[str] = Field(default_factory=set)\n",
    "    max_content_length: int = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing scrape tasks...\n",
      "Found 63 unique URLs above threshold to scrape.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement a threshold for relevance score \n",
    "\n",
    "# --- Scraping Phase ---\n",
    "urls_to_process_map = {}\n",
    "\n",
    "print(\"Preparing scrape tasks...\")\n",
    "for subtopic_result in search_results:\n",
    "    subtopic = subtopic_result[\"subtopic\"]\n",
    "    for query_result in subtopic_result[\"queries\"]:\n",
    "        query = query_result[\"query\"]\n",
    "        for result in query_result[\"results\"]:\n",
    "            if result[\"url\"] not in urls_to_process_map:\n",
    "            # if result.relevance_score >= MIN_RELEVANCE_SCORE and result.url not in urls_to_process_map:\n",
    "                urls_to_process_map[result[\"url\"]] = {\n",
    "                    \"subtopic\": subtopic,\n",
    "                    \"query\": query,\n",
    "                    \"search_result_title\": result[\"title\"]\n",
    "                }\n",
    "\n",
    "visited_urls_tracker = set(urls_to_process_map.keys())\n",
    "print(f\"Found {len(urls_to_process_map)} unique URLs above threshold to scrape.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing scrape tasks: 100%|██████████| 63/63 [08:37<00:00,  8.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "MAX_SCRAPE_CONTENT_LENGTH = 4000 # Max characters for scrape tool\n",
    "\n",
    "scrape_tasks = []\n",
    "num_urls_to_scrape = len(urls_to_process_map)\n",
    "\n",
    "for url, context in tqdm(islice(urls_to_process_map.items(), num_urls_to_scrape),\n",
    "                         desc=\"Preparing scrape tasks\",\n",
    "                         total=num_urls_to_scrape):\n",
    "    agent_input_model = ScraperAgentInput(\n",
    "        url=url,\n",
    "        subtopic=context[\"subtopic\"],\n",
    "        user_query=context[\"query\"],\n",
    "        search_result_title=context[\"search_result_title\"],\n",
    "        visited_urls=visited_urls_tracker,\n",
    "        max_content_length=MAX_SCRAPE_CONTENT_LENGTH\n",
    "    )\n",
    "\n",
    "    scrape_response = await Runner().run(\n",
    "        starting_agent=web_scraper_agent,\n",
    "        input=f\"Scrape data from the provided URL: {agent_input_model.model_dump_json()}\"\n",
    "    )\n",
    "    scrape_tasks.append(scrape_response.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Content Analysis and Summarization\n",
    "\n",
    "For each scraped result, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the cleaned web content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms high-quality scraped data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 4/4 [01:36<00:00, 24.18s/it]\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_contents_and_citations, summarize_content\n",
    "summarize_per_webpage = False  # True will summarize per web page, False will summarize per subtopic\n",
    "\n",
    "# Build a lookup for scraped content (using attribute access)\n",
    "scraped_content_by_url = {\n",
    "    item.url: item.main_content\n",
    "    for item in scrape_tasks\n",
    "    if getattr(item, \"main_content\", None)\n",
    "}\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    contents, citations = collect_contents_and_citations(subtopic_result, scraped_content_by_url)\n",
    "    summaries = await summarize_content(contents, summary_agent, Runner, summarize_per_webpage)\n",
    "    if summarize_per_webpage:\n",
    "        mapped_chunks.append({\n",
    "            \"subtopic\": subtopic_result[\"subtopic\"],\n",
    "            \"summaries\": summaries,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "    else:\n",
    "        mapped_chunks.append({\n",
    "            \"subtopic\": subtopic_result[\"subtopic\"],\n",
    "            \"summaries\": summaries,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "\n",
    "# Filter out empty summaries\n",
    "mapped_chunks = [c for c in mapped_chunks if c['summaries']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan.final_output, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "final_answer = await Runner().run(\n",
    "    starting_agent=research_agent,\n",
    "    input=(\n",
    "        \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "        \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "        \"a cohesive, academic-style paper:\\n\\n\"\n",
    "        f\"{research_input_prompt}\\n\\n\"\n",
    "        \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    "    ),\n",
    "    max_turns=21 # 5 turns are needed for a full collaboration between ResearchAgent and PeerReviewAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Final Research Report\n",
    "\n",
    "After the ResearchAgent and PeerReviewAgent complete their collaborative process, we extract the final research report from the agent outputs. The report includes:\n",
    "\n",
    "1. A clearly defined research objective\n",
    "2. Multiple sections covering all identified subtopics\n",
    "3. In-depth analysis with facts, statistics, and insights\n",
    "4. Proper citations using IEEE format\n",
    "5. A comprehensive references section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import HandoffCallItem\n",
    "\n",
    "def extract_research_report(final_answer):\n",
    "    # If final output is from ResearchAgent, get the report directly\n",
    "    if hasattr(final_answer.final_output, \"research_report\"):\n",
    "        return final_answer.final_output.research_report\n",
    "    \n",
    "    # If final output is from PeerReviewAgent, find the latest research report from ResearchAgent\n",
    "    for item in reversed(final_answer.new_items):  # Start from end to get the latest\n",
    "        if isinstance(item, HandoffCallItem) and item.agent.name == \"ResearchAgent\":\n",
    "            try:\n",
    "                args = json.loads(item.raw_item.arguments)\n",
    "                if \"research_report\" in args:\n",
    "                    return args[\"research_report\"]\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                continue\n",
    "    \n",
    "    # If we couldn't find a report\n",
    "    raise ValueError(\"No research report found in the conversation history\")\n",
    "\n",
    "research_report = extract_research_report(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Report Presentation\n",
    "\n",
    "The completed research report is displayed below in Markdown format. The report represents a comprehensive analysis of the original query, incorporating insights from multiple web sources and structured in an academic format with proper citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Comprehensive Analysis and Comparison of Classical Machine Learning, Deep Learning, and Generative AI\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Artificial intelligence (AI) has undergone a remarkable transformation over the past several decades, evolving from rule-based systems to sophisticated models capable of autonomous learning and creative synthesis. This progression has given rise to distinct but interconnected subfields: classical machine learning (ML), deep learning (DL), and generative AI (GenAI). Each approach embodies unique methodologies, capabilities, and applications, yet their boundaries often blur, reflecting a continuum of technological advancement. Understanding the definitions, methodologies, applications, strengths, limitations, and interrelationships among these paradigms is essential for researchers, practitioners, and decision-makers seeking to harness AI's full potential. This report provides an in-depth, authoritative analysis of these three pillars of modern AI, integrating quantitative data, technical details, and comparative insights to illuminate their roles in contemporary and future innovation.\n",
       "\n",
       "## 1. Definitions and Core Concepts\n",
       "\n",
       "### 1.1 Artificial Intelligence: The Umbrella Concept\n",
       "\n",
       "Artificial Intelligence (AI) refers broadly to computer systems designed to simulate human intelligence, enabling machines to perform tasks such as reasoning, learning, perception, and decision-making. AI encompasses a spectrum of technologies, from expert systems and symbolic reasoning to data-driven learning algorithms. Its primary goal is to create systems that can adapt to new information, solve complex problems, and interact naturally with humans and their environments [1].\n",
       "\n",
       "### 1.2 Classical Machine Learning\n",
       "\n",
       "Classical machine learning (ML) is a subset of AI focused on algorithms that learn from data to make predictions or decisions without being explicitly programmed for each task. Classical ML typically relies on statistical methods and manual feature engineering, where domain experts select and transform input variables to optimize model performance. Algorithms such as decision trees, support vector machines (SVMs), logistic regression, linear regression, and clustering are foundational to classical ML. These models excel with structured data and are well-suited for tasks where interpretability, efficiency, and limited data are paramount [2][3].\n",
       "\n",
       "Classical ML models are generally categorized as discriminative, meaning they learn boundaries between classes for classification or regression tasks. Their strengths lie in their simplicity, lower computational requirements, and ease of implementation. However, they struggle with complex or unstructured data and lack the adaptability of more advanced AI paradigms.\n",
       "\n",
       "### 1.3 Deep Learning\n",
       "\n",
       "Deep learning (DL) represents a significant leap within ML, utilizing artificial neural networks with multiple layers—often called multilayered or \"deep\" networks. Inspired by biological neuroscience, DL models stack artificial neurons into layers, enabling the system to learn complex hierarchical features from raw data. Unlike classical ML, DL automates feature extraction, reducing the need for manual intervention and allowing models to handle large, unstructured datasets such as images, audio, and text [4][5].\n",
       "\n",
       "The depth of a neural network is measured by its credit assignment path (CAP), which tracks the chain of transformations from input to output. Deep learning is generally considered to involve CAP depths greater than two. Architectures such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers have enabled breakthroughs in computer vision, speech recognition, and natural language processing. DL models require significant computational resources and large labeled datasets but achieve state-of-the-art results in many domains.\n",
       "\n",
       "### 1.4 Generative AI\n",
       "\n",
       "Generative AI (GenAI) is a specialized branch of AI, typically built atop deep learning architectures, that focuses on creating new content rather than merely analyzing or predicting. Generative models, such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based architectures (e.g., GPT, Llama), learn the underlying probability distribution of training data and can generate novel outputs that closely resemble the original data [6][7].\n",
       "\n",
       "GenAI models require vast amounts of unstructured data and significant computational resources for training, often involving thousands of GPUs and weeks of processing. The resulting foundation models—large neural networks with billions of parameters—can autonomously generate text, images, audio, video, and even multimodal content in response to user prompts. Generative AI differs fundamentally from discriminative AI: while discriminative models classify or label input data based on learned boundaries, generative models synthesize new samples by extrapolating from learned patterns.\n",
       "\n",
       "### 1.5 Evolution and Interrelationships\n",
       "\n",
       "The evolution from classical ML to DL and GenAI reflects a shift from manual, rule-based systems to autonomous, data-driven models capable of complex reasoning and content creation. Classical ML remains relevant for structured, interpretable, and resource-efficient tasks, while DL and GenAI unlock new possibilities for handling unstructured data and automating creative processes. The distinctions between these fields—structured vs. unstructured data, manual vs. automatic feature extraction, prediction vs. synthesis—are critical for selecting the appropriate AI technology for a given application [8].\n",
       "\n",
       "#### Table 1: Hierarchical Breakdown of AI Paradigms\n",
       "\n",
       "| Level           | Paradigm               | Key Characteristics                          |\n",
       "|-----------------|-----------------------|----------------------------------------------|\n",
       "| AI              | Artificial Intelligence| Reasoning, learning, perception, problem-solving |\n",
       "| ML (subset of AI)| Machine Learning      | Data-driven learning, manual feature engineering |\n",
       "| DL (subset of ML)| Deep Learning         | Multilayer neural networks, automatic feature extraction |\n",
       "| GenAI (built on DL)| Generative AI        | Content synthesis, large models, multimodal outputs |\n",
       "\n",
       "## 2. Methodologies and Algorithms\n",
       "\n",
       "### 2.1 Classical Machine Learning Methodologies\n",
       "\n",
       "Classical ML is characterized by its use of statistical and computational algorithms to parse data, learn from it, and make predictions or decisions. The methodologies are grounded in mathematical rigor and often require manual intervention for feature selection and engineering. Key algorithms include:\n",
       "\n",
       "- **Linear Regression:** Predicts continuous values based on linear relationships between input variables.\n",
       "- **Logistic Regression:** Used for binary classification, modeling the probability of a categorical outcome.\n",
       "- **Decision Trees:** Hierarchical models that split data based on feature thresholds, offering interpretability and rule-based classification.\n",
       "- **Support Vector Machines (SVMs):** Identify optimal boundaries between classes in high-dimensional spaces.\n",
       "- **K-Nearest Neighbors (KNN):** Instance-based learning for classification and regression based on proximity in feature space.\n",
       "- **Naive Bayes:** Probabilistic classification assuming feature independence.\n",
       "- **Ensemble Methods:** Combine multiple models (e.g., random forests, gradient boosting) to improve accuracy and robustness.\n",
       "- **Clustering Algorithms:** Group data into clusters based on similarity (e.g., k-means, hierarchical clustering).\n",
       "\n",
       "Evaluation metrics for classical ML include accuracy, precision, recall, F1-score, and ROC-AUC, providing quantitative measures of model performance [9][10].\n",
       "\n",
       "### 2.2 Deep Learning Architectures and Algorithms\n",
       "\n",
       "Deep learning leverages neural networks with multiple layers to automatically extract hierarchical features from raw data. The architecture of a typical DL model includes an input layer, several hidden layers, and an output layer. Training involves adjusting millions or billions of parameters—weights and biases—using large datasets and iterative optimization.\n",
       "\n",
       "#### Key Deep Learning Architectures:\n",
       "\n",
       "- **Convolutional Neural Networks (CNNs):** Specialized for spatial data (images, video), using convolutional layers to capture local patterns.\n",
       "- **Recurrent Neural Networks (RNNs):** Designed for sequential data (time series, text), maintaining memory of previous inputs.\n",
       "- **Long Short-Term Memory (LSTM) Networks:** Address the vanishing gradient problem in RNNs, enabling learning of long-term dependencies.\n",
       "- **Autoencoders:** Unsupervised models for dimensionality reduction and feature learning.\n",
       "- **Generative Adversarial Networks (GANs):** Consist of a generator and discriminator in a competitive framework, enabling realistic content generation.\n",
       "- **Transformers:** Utilize self-attention mechanisms for parallel processing of sequences, foundational for large language models (LLMs) [11][12].\n",
       "\n",
       "Optimization techniques such as Stochastic Gradient Descent (SGD), AdaGrad, RMSProp, and Adam are crucial for training deep networks, each offering trade-offs in convergence speed, stability, and adaptability to sparse or noisy gradients. DL models require significant computational resources and large labeled datasets but achieve state-of-the-art results in computer vision, speech recognition, and natural language processing [13].\n",
       "\n",
       "### 2.3 Generative AI Algorithms\n",
       "\n",
       "Generative AI builds on deep learning architectures to create new, original content. The methodologies focus on learning the underlying probability distribution of training data and generating new samples from it.\n",
       "\n",
       "#### Core Generative AI Models:\n",
       "\n",
       "- **Generative Adversarial Networks (GANs):** Two neural networks (generator and discriminator) compete, with the generator creating samples and the discriminator evaluating their authenticity. This adversarial process leads to highly realistic outputs.\n",
       "- **Variational Autoencoders (VAEs):** Encode input data into a latent space and decode it to generate new samples, balancing reconstruction accuracy and diversity.\n",
       "- **Transformer-Based Models (e.g., GPT, BERT, Llama):** Use self-attention mechanisms to process and generate text, images, and other modalities. Large language models (LLMs) are pre-trained on massive datasets and fine-tuned for specific tasks.\n",
       "- **Multimodal Large Language Models (MLLMs):** Extend transformer architectures to handle multiple modalities (text, image, audio, video), enabling richer and more versatile content generation [14][15].\n",
       "\n",
       "Generative AI is driving rapid innovation and adoption across industries, with businesses reporting up to 70% faster time-to-value compared to traditional AI approaches. The flexibility and scalability of generative AI, powered by foundation models trained on massive unlabeled datasets, are expected to further accelerate adoption and innovation [16].\n",
       "\n",
       "#### Table 2: Comparison of Key Algorithms\n",
       "\n",
       "| Approach         | Typical Algorithms          | Data Type      | Feature Engineering | Computational Demand | Output Type         |\n",
       "|------------------|----------------------------|----------------|---------------------|---------------------|---------------------|\n",
       "| Classical ML     | Linear/Logistic Regression, Decision Trees, SVM, KNN, Naive Bayes, Clustering | Structured      | Manual              | Low to Moderate     | Predictions, Labels |\n",
       "| Deep Learning    | CNN, RNN, LSTM, Autoencoder, Transformer | Unstructured    | Automatic           | High                | Predictions, Features|\n",
       "| Generative AI    | GAN, VAE, Transformer (LLM, MLLM) | Unstructured/Multimodal | Automatic           | Very High           | New Content         |\n",
       "\n",
       "## 3. Applications and Use Cases\n",
       "\n",
       "### 3.1 Classical Machine Learning Applications\n",
       "\n",
       "Classical ML remains foundational in many domains, particularly where structured data and interpretability are critical. Common applications include:\n",
       "\n",
       "- **Predictive Analytics:** Forecasting sales, demand, and market trends using regression and classification models.\n",
       "- **Fraud Detection:** Identifying anomalous transactions in finance and banking through clustering and supervised learning.\n",
       "- **Medical Diagnosis:** Assisting clinicians in disease prediction and risk assessment based on patient data.\n",
       "- **Spam Filtering:** Classifying emails and messages using discriminative models.\n",
       "- **Customer Segmentation:** Grouping users for targeted marketing using clustering algorithms.\n",
       "\n",
       "These applications benefit from classical ML's efficiency, transparency, and robustness, especially when data is well-structured and labeled [17].\n",
       "\n",
       "### 3.2 Deep Learning Use Cases\n",
       "\n",
       "Deep learning has revolutionized fields reliant on unstructured data, enabling breakthroughs in perception, understanding, and automation. Notable use cases include:\n",
       "\n",
       "- **Image and Video Recognition:** CNNs power facial recognition, object detection, and medical imaging analysis, achieving accuracy rates exceeding 95% in some benchmarks.\n",
       "- **Speech Processing:** RNNs and transformers enable real-time speech-to-text conversion, voice assistants, and language translation.\n",
       "- **Natural Language Understanding:** Transformers underpin chatbots, sentiment analysis, and document summarization, supporting applications in customer service, legal, and healthcare sectors.\n",
       "- **Autonomous Vehicles:** DL models interpret sensor data for navigation, obstacle detection, and decision-making in self-driving cars.\n",
       "- **Financial Forecasting:** DL architectures model complex temporal patterns in stock prices and economic indicators [18][19].\n",
       "\n",
       "The scalability and adaptability of DL have made it indispensable for organizations seeking to leverage large, heterogeneous datasets for advanced analytics and automation.\n",
       "\n",
       "### 3.3 Generative AI: Transformative Applications\n",
       "\n",
       "Generative AI is being rapidly adopted across industries, with real-world use cases spanning content creation, healthcare, supply chain optimization, customer service, marketing, and more. The technology is projected to unlock up to $4.4 trillion in annual global economic value by 2030, with adoption rates soaring—79% of surveyed organizations integrating AI into their workflows by 2025 [20].\n",
       "\n",
       "#### Key Use Cases:\n",
       "\n",
       "- **Content Creation & Natural Language Processing:** Marketers use AI-powered chatbots to automate customer responses, FAQs, and support articles, improving engagement metrics by 30%. Language models like GPT-4 summarize lengthy reports and emails, enabling executives to digest information rapidly. Real-time translation tools break language barriers in global communications.\n",
       "- **Healthcare & Life Sciences:** AI-generated clinical notes automate documentation, saving hours of charting and reducing administrative burden. Generative models enhance medical imaging, aiding radiologists in early and accurate anomaly detection. AI-driven drug discovery accelerates molecule generation and screening, reducing candidate identification time by 30–50%.\n",
       "- **Supply Chain & Operations:** GenAI analyzes historical sales and external signals to predict demand with over 90% accuracy, reducing stockouts and inventory costs by 15%. AI-generated logistics designs optimize delivery routes, cutting fuel costs and delivery times by 20%.\n",
       "- **Customer Experience & Service:** E-commerce platforms leverage generative AI for hyper-personalized product recommendations, boosting average order value by up to 25%. AI chatbots provide 24/7 support, handling routine inquiries and escalating complex issues, dramatically reducing response times.\n",
       "- **Marketing & Creative Industries:** Agencies use generative AI to brainstorm ad concepts, generate visuals, and A/B test creatives at scale, reducing campaign launch times. AI music generators and video tools enable rapid production of jingles, scores, and promotional videos.\n",
       "- **Code & Knowledge Work Automation:** Tools like GitHub Copilot assist developers in drafting code, automating QA, and scripting internal tools. AI agents improve knowledge access, search, and collaborative workflows in tech companies.\n",
       "\n",
       "#### Sector-Specific Case Studies\n",
       "\n",
       "A database of 650+ case studies from over 100 companies (Netflix, Airbnb, Uber, Dropbox, Mercedes Benz, etc.) documents practical generative AI deployments. For instance, Mercari’s AI chatbot reduced human agent workloads by 20% and delivered a 500% ROI. Virgin Voyages used text-to-video AI to create thousands of personalized ads and emails, maintaining brand consistency while scaling content production. In fintech, Ramp improved customer classification using retrieval-augmented generation (RAG) and LLMs, while Plaid grew AI coding adoption to boost engineer productivity [21][22].\n",
       "\n",
       "#### Table 3: Impact Assessment Matrix Across Industries\n",
       "\n",
       "| Industry          | Classical ML        | Deep Learning        | Generative AI        |\n",
       "|-------------------|--------------------|----------------------|----------------------|\n",
       "| Healthcare        | Risk prediction, diagnosis | Medical imaging, genomics | Clinical notes, drug discovery |\n",
       "| Finance           | Fraud detection, credit scoring | Forecasting, anomaly detection | Automated reporting, synthetic data |\n",
       "| Retail/E-commerce | Customer segmentation | Recommendation systems | Personalized content, chatbots |\n",
       "| Manufacturing     | Predictive maintenance | Quality control, robotics | Design automation, scenario simulation |\n",
       "| Media/Marketing   | Sentiment analysis | Image/video tagging | Ad generation, music/video synthesis |\n",
       "\n",
       "### 3.4 Comparative Insights and Nuances\n",
       "\n",
       "Comparative studies highlight the strengths and limitations of generative AI versus classical ML and deep learning approaches. Retrieval-based chatbots (ML/DL) excel in factual accuracy and structured tasks, while generative-based chatbots (LLMs) provide superior engagement and adaptability in open-ended conversations. Trade-offs include dependency on curated datasets for retrieval systems and the risk of plausible but inaccurate outputs from generative models. Quantitative metrics (BLEU, ROUGE, user satisfaction scores) and qualitative analyses guide practitioners in aligning architecture choices with application requirements [23].\n",
       "\n",
       "### 3.5 Emerging Trends and Future Directions\n",
       "\n",
       "Generative AI is evolving toward multimodal capabilities, combining text, image, and audio generation for richer user experiences. AI copilots are becoming integral in knowledge work, and responsible AI deployment is gaining traction to address ethical concerns. The technology’s integration into everyday systems signals a shift from standalone tools to embedded, workflow-centric solutions. As organizations continue to experiment and deploy generative AI, the landscape will further expand, driving efficiency, personalization, and new product development at unprecedented scale [24].\n",
       "\n",
       "## 4. Strengths, Limitations, and Interrelationships\n",
       "\n",
       "### 4.1 Strengths of Classical Machine Learning\n",
       "\n",
       "Classical ML offers several advantages, particularly in domains where data is structured and interpretability is essential. Its strengths include:\n",
       "\n",
       "- **Efficiency:** Classical ML models are less computationally intensive, allowing for rapid training and deployment on standard hardware.\n",
       "- **Interpretability:** Models such as decision trees and linear regression provide transparent decision-making processes, facilitating trust and regulatory compliance.\n",
       "- **Robustness:** Well-established statistical foundations enable reliable performance on basic, well-defined tasks.\n",
       "- **Low Data Requirements:** Classical ML can operate effectively with smaller datasets, making it accessible to organizations with limited data resources [25].\n",
       "\n",
       "### 4.2 Limitations of Classical Machine Learning\n",
       "\n",
       "Despite its strengths, classical ML faces notable limitations:\n",
       "\n",
       "- **Manual Feature Engineering:** Requires domain expertise and significant effort to select and transform input variables.\n",
       "- **Limited Scalability:** Struggles with large, complex, or unstructured datasets.\n",
       "- **Restricted Adaptability:** Cannot learn or improve from new environments without substantial reprogramming.\n",
       "- **Lower Accuracy in Complex Tasks:** Outperformed by DL and GenAI in domains requiring hierarchical or abstract feature extraction [26].\n",
       "\n",
       "### 4.3 Strengths of Deep Learning\n",
       "\n",
       "Deep learning has transformed AI by enabling models to learn complex representations from raw data. Its strengths include:\n",
       "\n",
       "- **Automatic Feature Extraction:** Eliminates the need for manual intervention, accelerating model development.\n",
       "- **High Accuracy:** Achieves state-of-the-art results in image recognition, speech processing, and natural language understanding.\n",
       "- **Scalability:** Handles massive, heterogeneous datasets, unlocking new possibilities in automation and analytics.\n",
       "- **Versatility:** Applicable across diverse domains, from healthcare to autonomous vehicles [27].\n",
       "\n",
       "### 4.4 Limitations of Deep Learning\n",
       "\n",
       "DL’s transformative potential is accompanied by significant challenges:\n",
       "\n",
       "- **Data Hunger:** Requires millions of labeled examples, raising barriers in domains with limited data.\n",
       "- **Computational Demands:** Training and deployment necessitate specialized hardware (GPUs, TPUs), substantial memory, and significant energy consumption.\n",
       "- **Lack of Interpretability:** Often described as \"black boxes,\" DL models are difficult to audit or explain, especially in regulated industries.\n",
       "- **Vulnerability to Adversarial Attacks:** Susceptible to small, intentional perturbations that can cause incorrect outputs.\n",
       "- **Limited Symbolic Reasoning:** Struggles with tasks requiring logic, long-term planning, or algorithmic manipulation [28][29].\n",
       "\n",
       "### 4.5 Strengths of Generative AI\n",
       "\n",
       "Generative AI extends DL’s capabilities to content synthesis, offering:\n",
       "\n",
       "- **Creative Automation:** Generates text, images, audio, and code, augmenting or automating human work.\n",
       "- **Personalization:** Enables hyper-personalized experiences in marketing, customer service, and product design.\n",
       "- **Scalability:** Foundation models can be fine-tuned for domain-specific tasks, supporting rapid deployment across industries.\n",
       "- **Democratization:** Low-cost, accessible tools empower non-technical users to leverage advanced AI capabilities [30].\n",
       "\n",
       "### 4.6 Limitations and Challenges of Generative AI\n",
       "\n",
       "Generative AI introduces additional complexities:\n",
       "\n",
       "- **Data Privacy and Security:** Training requires vast amounts of sensitive data, raising concerns about privacy and compliance.\n",
       "- **Bias and Quality Control:** Models can perpetuate stereotypes, misinformation, or produce inaccurate outputs.\n",
       "- **Intellectual Property Risks:** Generated content may inadvertently infringe on copyrights or patents.\n",
       "- **Resource Intensiveness:** Training foundation models is costly and environmentally demanding.\n",
       "- **Ethical and Regulatory Concerns:** Potential for misuse in generating deepfakes or malicious content necessitates robust governance [31][32].\n",
       "\n",
       "### 4.7 Interrelationships and Overlaps\n",
       "\n",
       "The boundaries between classical ML, DL, and GenAI are increasingly fluid. Classical ML provides the foundation for many DL techniques, and DL architectures underpin most GenAI models. Hybrid approaches are emerging, combining symbolic reasoning with neural networks to address limitations in interpretability and reasoning. Continuous evaluation, the development of explainable models, and the establishment of ethical standards are essential for the sustainable and trustworthy integration of these technologies into society [33].\n",
       "\n",
       "#### Figure 1: Timeline of Major Developments in AI\n",
       "\n",
       "```mermaid\n",
       "gantt\n",
       "    dateFormat  YYYY\n",
       "    title Timeline of Major AI Developments\n",
       "    section Classical ML\n",
       "    Linear Regression      :done,    des1, 1958, 1970\n",
       "    Decision Trees         :done,    des2, 1963, 1986\n",
       "    SVMs                  :done,    des3, 1992, 1995\n",
       "    section Deep Learning\n",
       "    CNNs                  :done,    des4, 1998, 2012\n",
       "    RNNs                  :done,    des5, 1986, 2015\n",
       "    LSTMs                 :done,    des6, 1997, 2015\n",
       "    Transformers          :done,    des7, 2017, 2020\n",
       "    section Generative AI\n",
       "    GANs                  :done,    des8, 2014, 2019\n",
       "    LLMs                  :done,    des9, 2018, 2023\n",
       "    Multimodal Models     :done,    des10, 2022, 2025\n",
       "```\n",
       "\n",
       "### 4.8 Quantitative Adoption and Performance Metrics\n",
       "\n",
       "Statistical data underscores the rapid adoption and impact of these technologies:\n",
       "\n",
       "- **AI Adoption:** 35% of businesses globally are actively using AI, with another 42% exploring its potential.\n",
       "- **Generative AI Impact:** Up to $4.4 trillion in annual global economic value projected by 2030.\n",
       "- **Customer Service:** Businesses report 30% improvements in engagement and 25% boosts in e-commerce order value through GenAI.\n",
       "- **Healthcare:** AI-driven drug discovery reduces candidate identification time by 30–50% [34].\n",
       "\n",
       "#### Figure 2: AI Adoption Rates by Technology (2025)\n",
       "\n",
       "```markdown\n",
       "table\n",
       "| Technology        | Adoption Rate (%) |\n",
       "|-------------------|------------------|\n",
       "| Classical ML      | 35               |\n",
       "| Deep Learning     | 28               |\n",
       "| Generative AI     | 79               |\n",
       "```\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The landscape of artificial intelligence is defined by the interplay between classical machine learning, deep learning, and generative AI. Each approach offers distinct methodologies, strengths, and limitations, yet their evolution reflects a continuum of innovation driven by advances in data, computation, and algorithmic design. Classical ML remains indispensable for structured, interpretable tasks, while deep learning unlocks the potential of unstructured data and complex feature hierarchies. Generative AI, built on DL foundations, is transforming industries by automating creativity and personalization at scale. The interrelationships among these paradigms are increasingly pronounced, with hybrid models and interdisciplinary collaboration paving the way for future breakthroughs. As AI continues to reshape business, society, and knowledge work, responsible deployment, ethical governance, and continuous innovation will be paramount in realizing its full potential.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] Classic and Adaptive machines - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/classic-and-adaptive-machines/\n",
       "[2] Overview of Machine Learning Part 1: Fundamentals and Classic ..., https://www.sciencedirect.com/science/article/pii/S1052514920300629\n",
       "[3] Deep learning - Wikipedia, https://en.wikipedia.org/wiki/Deep_learning\n",
       "[4] What is deep learning? - IBM, https://www.ibm.com/think/topics/deep-learning\n",
       "[5] What Is Deep Learning? Definition, Examples, and Careers, https://www.coursera.org/articles/what-is-deep-learning\n",
       "[6] Generative AI – What is it and How Does it Work? - NVIDIA, https://www.nvidia.com/en-us/glossary/data-science/generative-ai/\n",
       "[7] What is generative AI? - IBM, https://www.ibm.com/think/topics/generative-ai\n",
       "[8] AI vs ML vs Deep Learning vs GenAI — The Cloud Girl, https://www.thecloudgirl.dev/blog/ai-vs-machine-learning-vs-deep-learning-vs-generative-ai\n",
       "[9] Top 15 Machine Learning Algorithms Every Data Scientist Should Know in ..., https://www.geeksforgeeks.org/machine-learning/top-10-algorithms-every-machine-learning-engineer-should-know/\n",
       "[10] Classical Machine Learning Algorithms | 10 Essential ML Algorithms ..., https://www.mathisimple.com/machine-learning/ml-learn/introduction-to-ml/classical-algorithms\n",
       "[11] Top 10 Deep Learning Algorithms in 2025 - GeeksforGeeks, https://www.geeksforgeeks.org/deep-learning/top-deep-learning-algorithms/\n",
       "[12] A Comprehensive Review of Deep Learning: Architectures, Recent Advances ..., https://www.mdpi.com/2078-2489/15/12/755\n",
       "[13] [2310.20360] Mathematical Introduction to Deep Learning: Methods ..., https://arxiv.org/abs/2310.20360\n",
       "[14] Technology Foundations of Generative AI: Architectures, Algorithms, and ..., https://www.pwc.de/en/digitale-transformation/generative-ai-artificial-intelligence/the-genai-building-blocks/technology-foundations-of-generative-ai-architectures-algorithms-and-innovations.html\n",
       "[15] Machine Learning vs Deep Learning vs Generative AI - What are the ..., https://www.freecodecamp.org/news/machine-learning-vs-deep-learning-vs-generative-ai/\n",
       "[16] Difference between AI, ML, LLM, and generative AI - Toloka, https://toloka.ai/blog/difference-between-ai-ml-llm-and-generative-ai/\n",
       "[17] Machine Learning Examples, Applications & Use Cases | IBM, https://www.ibm.com/think/topics/machine-learning-use-cases\n",
       "[18] Deep Learning Examples: Practical Applications in Real Life, https://www.geeksforgeeks.org/deep-learning/deep-learning-examples/\n",
       "[19] Top 20 Applications of Deep Learning in 2025 Across Industries, https://www.mygreatlearning.com/blog/deep-learning-applications/\n",
       "[20] 10 Generative AI Use Cases Transforming Industries in 2025, https://www.digitalocean.com/resources/articles/generative-ai-use-cases\n",
       "[21] 28 Generative AI Examples (2025): Use Cases Across Industries, https://www.lindy.ai/blog/generative-ai-examples\n",
       "[22] Real-world gen AI use cases from the world's leading organizations ..., https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders\n",
       "[23] A comparative study of retrieval-based and generative-based chatbots ..., https://www.sciencedirect.com/science/article/pii/S2772442523000655\n",
       "[24] Generative AI Use Cases 2025 | Real Applications Explained, https://futurense.com/blog/gen-ai-use-cases\n",
       "[25] 5 Reasons Why Traditional Machine Learning is Alive and Well in the Age ..., https://machinelearningmastery.com/5-reasons-why-traditional-machine-learning-is-alive-and-well-in-the-age-of-llms/\n",
       "[26] Classical ML vs Deep Learning 2023 | by Anirban Bose | Medium, https://medium.com/@bosea949/classical-ml-vs-deep-learning-2023-3ade040dfddb\n",
       "[27] Top 41 Deep Learning Use Cases & Examples in 2025 - ExpertBeacon, https://expertbeacon.com/deep-learning-applications/\n",
       "[28] Challenges in Deep Learning - GeeksforGeeks, https://www.geeksforgeeks.org/deep-learning/challenges-in-deep-learning/\n",
       "[29] THE COMPUTATIONAL LIMITS OF DEEP LEARNING - MIT Initiative on the ..., https://ide.mit.edu/wp-content/uploads/2020/09/RBN.Thompson.pdf\n",
       "[30] On the Challenges and Opportunities in Generative AI, https://arxiv.org/html/2403.00025v3\n",
       "[31] 10 Major Challenges of Generative AI & How to Overcome Them, https://www.theiotacademy.co/blog/challenges-of-generative-ai/\n",
       "[32] A Critical Analysis of Generative AI: Challenges, Opportunities, and ..., https://link.springer.com/article/10.1007/s11831-025-10355-z\n",
       "[33] Machine Learning vs Deep Learning vs Generative AI - What are the ..., https://www.freecodecamp.org/news/machine-learning-vs-deep-learning-vs-generative-ai/\n",
       "[34] Evidently AI - ML and LLM system design: 650 case studies, https://www.evidentlyai.com/ml-system-design\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(research_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Workflow Visualization\n",
    "\n",
    "Below we can see the detailed steps in the research and review process, showing how the ResearchAgent and PeerReviewAgent collaborated to produce the final report. This visualization helps us understand how many iterations were required to meet quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 AGENT WORKFLOW: 'Create an exceptionally comprehensive, **paragraph-focused** and detailed research report using the following content. **Minimize bullet points** and ensure the final text resembles a cohesive, academic-style paper:\n",
      "\n",
      "{\n",
      "  \"objective\": \"To comprehensively analyze and compare classical machine learning, deep learning, and generative AI, highlighting their definitions, methodologies, applications, strengths, limitations, and interrelationships.\",\n",
      "  \"aggregated_summaries\": [\n",
      "    {\n",
      "      \"subtopic\": \"Definitions and Core Concepts\",\n",
      "      \"summaries\": \"## Key Insights\\n- Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Generative AI (GenAI) are distinct yet interconnected fields, each with unique methodologies, capabilities, and applications.\\n- Classical Machine Learning (ML) relies on statistical algorithms, manual feature engineering, and is best suited for structured data and predictive tasks; Deep Learning (DL) uses multilayered neural networks for automatic f'\n",
      "\n",
      "\n",
      "================================================================================\n",
      "👤 AGENT: ResearchAgent\n",
      "--------------------------------------------------------------------------------\n",
      "  💬 OUTPUT: {\n",
      "  \"objective\": \"To comprehensively analyze and compare classical machine learning, deep learnin...\n",
      "\n",
      "================================================================================\n",
      "🏁 FINAL OUTPUT:\n",
      "--------------------------------------------------------------------------------\n",
      "# Comprehensive Analysis and Comparison of Classical Machine Learning, Deep Learning, and Generative AI\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Artificial intelligence (AI) has undergone a remarkable transformation over th...\n"
     ]
    }
   ],
   "source": [
    "from common.helper import pretty_print_agent_workflow\n",
    "pretty_print_agent_workflow(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
