{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search & Scraping**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow now includes a dedicated scraping phase for extracting and cleaning web content:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Web Content Scraping** - Extracting, cleaning, and filtering relevant content from web pages using a ScraperAgent\n",
    "4. **Content Analysis** - Summarizing scraped results and extracting key insights\n",
    "5. **Report Generation** - Creating detailed research reports with proper citations\n",
    "6. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- WebScraperAgent - Extracts, cleans, and filters relevant content from web pages\n",
    "- SummaryAgent - Extracts key insights from scraped content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Projects, and the OpenAI Agents SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Azure OpenAI to work with OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    set_default_openai_client,\n",
    "    set_tracing_disabled,\n",
    "    OpenAIChatCompletionsModel\n",
    ")\n",
    "\n",
    "# setup settings\n",
    "from openai import AsyncAzureOpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Use the synchronous client instead of the async one\n",
    "openai_client = AsyncAzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AOAI_KEY\"),\n",
    "    api_version=os.environ.get(\"AOAI_API_VERSION\", \"2024-02-01\")\n",
    ")\n",
    "\n",
    "# Configure SDK\n",
    "set_default_openai_client(openai_client)\n",
    "set_tracing_disabled(True)\n",
    "\n",
    "reasoningModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"reasoningModel\"), \n",
    "    openai_client=openai_client\n",
    ")\n",
    "\n",
    "chatModel = OpenAIChatCompletionsModel(\n",
    "    model=os.getenv(\"chatModel\"),\n",
    "    openai_client=openai_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models for Research Workflow\n",
    "\n",
    "The following Pydantic models define the structured data used throughout our research process:\n",
    "\n",
    "1. **ResearchTask** - Represents an individual research task with specific search queries\n",
    "2. **ResearchPlan** - Contains the overall plan with research objectives and tasks\n",
    "3. **Citation** - Stores source information for proper attribution\n",
    "4. **ComprehensiveResearchReport** - Defines the structure of the final research output\n",
    "5. **PeerReviewFeedback** - Contains structured feedback on report quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResearchTask(BaseModel):\n",
    "    id: Optional[str] = Field(None, description=\"Unique identifier for the task\")\n",
    "    subtopic: str = Field(..., description=\"Subtopic to research\")\n",
    "    search_queries: List[str] = Field(..., description=\"List of search queries to explore this subtopic\")\n",
    "    completed: bool = Field(..., description=\"Status of task completion\")\n",
    "\n",
    "class ResearchPlan(BaseModel):\n",
    "    query: str = Field(..., description=\"The original user query that prompted this research\")\n",
    "    objective: str = Field(..., description=\"The overall research objective, clearly defined\")\n",
    "    success_criteria: List[str] = Field(..., description=\"Criteria to determine when the research is sufficiently complete.\")\n",
    "    related_topics: List[str] = Field(..., description=\"List of related topics that may be useful for the research.\")\n",
    "    research_tasks: List[ResearchTask] = Field(..., description=\"List of specific research tasks to complete. Each task focuses on a subtopic.\")\n",
    "\n",
    "class ScrapedWebPage(BaseModel):\n",
    "    url: str = Field(..., description=\"The original URL that was scraped\")\n",
    "    title: Optional[str] = Field(None, description=\"The page title (if available, else None)\")\n",
    "    main_content: Optional[str] = Field(None, description=\"The main textual content of the page, cleaned and potentially truncated (if available, else None)\")\n",
    "    source: Optional[str] = Field(None, description=\"The name of the source (if available, else None)\")\n",
    "    published_date: Optional[str] = Field(None, description=\"YYYY-MM-DD (if available, else None)\")\n",
    "    scrape_error: Optional[str] = Field(None, description=\"Error message if scraping failed, else None\")\n",
    "    # Fields below might be added by the agent based on instructions, not the tool directly\n",
    "    extraction_method: Optional[str] = Field(None, description=\"How content was extracted (e.g., 'tool_extracted', 'agent_filtered')\") \n",
    "    relevance_score_agent: Optional[float] = Field(None, description=\"Agent's assessment of relevance (0-10)\")\n",
    "    matched_sections: Optional[List[str]] = Field(None, description=\"Sections identified by the agent as relevant\")\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "\n",
    "class ComprehensiveResearchReport(BaseModel):\n",
    "    objective: str = Field(..., description=\"The original research objective\")\n",
    "    research_report: str = Field(..., description=(\n",
    "        \"Comprehensive research report in markdown. \"\n",
    "        \"It should be structured with meaningful headings and subsections, but emphasize **fully-developed paragraphs**. \"\n",
    "        \"It should be long and detailed, and it should fully addresses the objectives, \"\n",
    "        \"and the various subtopics required to achieve the success criteria. \"\n",
    "        \"Use bullet points or lists **only** when they genuinely improve clarity (e.g., summarizing key data). \"\n",
    "        \"Tables and other data visualizations are encouraged. \"\n",
    "        \"The research report should always be long and detailed.\\n\\n\" \n",
    "        \"For citations, please use the IEEE (Institute of Electrical and Electronics Engineers). \"\n",
    "        \"How it works:\\n\\n\"\n",
    "        \"   1. In the text, use numbered citations in brackets [1].\\n\"\n",
    "        \"   2. At the end of the report, provide a list of citations in the format \"\n",
    "        \"(the list should ONLY contain the sources used in the free text of the research report. \"\n",
    "        \"Do NOT list sources which are not cited in the free text of the research report.):\\n\\n\"\n",
    "        \"       [1] Title of the source, URL.\"\n",
    "    ))\n",
    "    citations: List[Citation] = Field(..., description=(\n",
    "        \"List of citations (title and URL), corresponding to references actually used in research_report. \"\n",
    "        \"Do not add references that are not cited within the text.\"\n",
    "    ))\n",
    "    identified_gaps: Optional[List[str]] = Field(default=None, description=\"Identified information gaps.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Suggestions for additional research.\")\n",
    "\n",
    "class PeerReviewFeedback(BaseModel):\n",
    "    overall_feedback: str = Field(..., description=\"General feedback on the report.\")\n",
    "    strengths: List[str] = Field(..., description=\"Aspects of the report that are well done.\")\n",
    "    suggested_improvements: List[str] = Field(..., description=\"Specific suggestions to improve clarity, completeness, accuracy, or structure.\")\n",
    "    additional_queries: Optional[List[str]] = Field(default=None, description=\"Additional research queries that could strengthen the report.\")\n",
    "    is_satisfactory: bool = Field(..., description=\"Indicates if the report meets all quality standards and no further revisions are needed.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "The research workflow is powered by two types of agents:\n",
    "\n",
    "1. **Azure AI Agents** - Created using Azure AI Projects for web search capabilities\n",
    "2. **OpenAI Agents** - For specialized research tasks\n",
    "\n",
    "Let's configure each type of agent with their specific instructions and capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will ***create*** an **Azure AI Agent**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.ai.projects.models import BingGroundingTool\n",
    "\n",
    "# bing_connection = project_client.connections.get(\n",
    "#     connection_name=os.environ[\"BING_CONNECTION_NAME\"]\n",
    "# )\n",
    "\n",
    "# bing_tool = BingGroundingTool(connection_id=bing_connection.id)\n",
    "\n",
    "# bing_search_agent = project_client.agents.create_agent(\n",
    "#     name=\"BingSearchAgent\",\n",
    "#     description=\"Agent to perform web searches using Bing.\",\n",
    "#     model=\"gpt-4o\",\n",
    "#     temperature=0.5,\n",
    "#     tools=bing_tool.definitions,\n",
    "#     instructions=\"\"\"You are a helpful research assistant. \n",
    "# Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "# When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "# Provide a comprehensive answer based on the search results.\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have an Azure AI Agent, run this cell to update it's instructions with today's date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful research assistant.\n",
      "\n",
      "Today's date is 2025-05-26.\n",
      "\n",
      "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
      "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
      "Provide a comprehensive answer based on the search results.\n"
     ]
    }
   ],
   "source": [
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "bing_search_agent.instructions = f\"\"\"\n",
    "You are a helpful research assistant.\n",
    "\n",
    "Today's date is {current_date}.\n",
    "\n",
    "Use your available tools (like Bing web search) to find information relevant to the user's query.\n",
    "When you use information from a search result in your answer, please cite the source clearly using the tool's citation capabilities.\n",
    "Provide a comprehensive answer based on the search results.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(bing_search_agent.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenAI Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    Agent,\n",
    "    ModelSettings\n",
    ")\n",
    "\n",
    "from common.utils_scraping import scrape_web_page\n",
    "\n",
    "chatModelSettings=ModelSettings(\n",
    "        max_tokens=32768,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "\n",
    "    You are an expert research planner specializing in creating detailed research plans your task is to analyze a user's research query and create a structured research plan.\n",
    "    with the following components:\n",
    "    \n",
    "    1. DOMAIN CLASSIFICATION:\n",
    "       Classify the query into a fitting domain (e.g., technology, business, etc.).\n",
    "       The Domain is not included in the output, but it is important for the other components in the research plan.\n",
    "       The domain should be a single word (e.g., technology, business, etc.).\n",
    "       \n",
    "    2. RESEARCH OBJECTIVE:\n",
    "       Create a clear, comprehensive objective statement for the research\n",
    "       \n",
    "    3. SUBTOPICS:\n",
    "       Generate relevant subtopics that should be explored to thoroughly answer the query (Important. generate no less than 4 subtopics)\n",
    "       \n",
    "    4. SEARCH QUERIES:\n",
    "       For each subtopic, provide search queries that will yield valuable results (Important. It's better to generate more queries than less queries, but at least 2 queries per subtopic)\n",
    "       \n",
    "    5. SUCCESS CRITERIA:\n",
    "       List the criteria that will determine when the research is complete (Important. generate no less than 4 success criteria)\n",
    "       Take all of the above into account (e.g., the domain, objective, subtopics, and search queries) to create the success criteria.\n",
    "       \n",
    "    6. RELATED TOPICS:\n",
    "       suggest related topics that may be useful for the research (Important. generate no less than 3 related topics)\n",
    "    \n",
    "    Ensure each subtopic is thorough and directly relevant to the research query.\n",
    "    The search queries should be specific enough to return high-quality results.\n",
    "    \"\"\".strip(),\n",
    "    model=chatModel,\n",
    "    output_type=ResearchPlan,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "web_scraper_agent = Agent(\n",
    "    name=\"WebScraperAgent\",\n",
    "    instructions=f\"\"\"\n",
    "    Today's date is {current_date}.\n",
    "    \n",
    "    You are a robust, context-aware web scraping specialist. Your primary tool is 'scrape_web_page'.\n",
    "\n",
    "    Your input is a JSON string containing: 'url', 'subtopic', 'user_query', 'search_result_title', 'visited_urls', and 'max_content_length'. Parse this JSON to get the necessary information.\n",
    "\n",
    "    **Workflow:**\n",
    "    1.  **Parse Input:** Extract 'url', 'user_query', 'subtopic', 'search_result_summary', and 'max_content_length' from the input JSON string.\n",
    "    2.  **Call Scraping Tool:** Call the `scrape_web_page` tool with the 'url' and 'max_content_length'.\n",
    "    3.  **Analyze Tool Output:** Receive the dictionary from the tool containing `url`, `title`, `main_content`, `source`, `published_date`, `scrape_error`.\n",
    "    4.  **Contextual Filtering (If Content Exists and No Error):**\n",
    "        - If `scrape_error` is None and `main_content` exists:\n",
    "            - Review the `main_content`.\n",
    "            - Use the `user_query`, `subtopic`, and `search_result_summary` to identify ONLY the most relevant paragraphs or sections.\n",
    "            - If the entire `main_content` seems relevant or is short, keep it all.\n",
    "            - If filtering, replace `main_content` with ONLY the relevant extracted parts. Set `extraction_method` to 'agent_filtered'.\n",
    "            - Estimate a `relevance_score_agent` (0-10).\n",
    "            - Optionally list `matched_sections`.\n",
    "        - If `scrape_error` is present, ensure the `scrape_error` field in your output reflects the tool's error.\n",
    "    5.  **Format Output:** Return a SINGLE JSON object matching the `ScrapedWebPage` Pydantic model, including all fields based on the tool's output and your filtering. If the tool failed, `main_content` should be None/empty, and `scrape_error` should be set.\n",
    "    6.  **Return JSON object:** Return ONLY the final object formatted as a single, valid JSON. Do NOT add any explanatory text before or after the JSON.\n",
    "\n",
    "    **Constraints:**\n",
    "    - Your final output MUST be ONLY a valid JSON representing the scraped and processed data.\n",
    "    - Adhere strictly to the field names defined in the conceptual `ScrapedWebPage` structure when creating the JSON.\n",
    "    - Prioritize accuracy and relevance based on the provided context.\n",
    "    \"\"\",\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    tools=[scrape_web_page],\n",
    "    output_type=ScrapedWebPage\n",
    ")\n",
    "\n",
    "summary_agent = Agent(\n",
    "    name=\"SummaryAgent\",\n",
    "    instructions=(\n",
    "        \"You are a comprehensive research summarization specialist. Your task is to **synthesize information from combined search result content** related to a specific subtopic (which will be mentioned in the input prompt). \"\n",
    "        \"Create a **single, coherent, detailed, and information-rich summary** that:\\n\\n\"\n",
    "        \"1. Extracts ALL important facts, statistics, findings, and insights **relevant to the specified subtopic** from the combined text.\\n\"\n",
    "        \"2. Preserves specific numbers, percentages, dates, and technical details whenever present.\\n\"\n",
    "        \"3. Includes industry-specific terminology and concepts that add depth to the research.\\n\"\n",
    "        \"4. **Synthesizes** the key arguments and conclusions from the provided sources. If sources present different perspectives or data, try to capture that nuance.\\n\"\n",
    "        \"5. Provides thorough explanations rather than superficial overviews, integrating information smoothly.\\n\"\n",
    "        \"6. For technical content, preserves methodologies, technical specifications, and implementation details.\\n\"\n",
    "        \"7. For comparative content, maintains all sides of the comparison with their specific attributes.\\n\\n\"\n",
    "\n",
    "        \"**Acknowledge that the input combines information potentially from multiple search results.** Your goal is to create a unified summary focused on the overall subtopic, not just list summaries of individual parts.\\n\\n\"\n",
    "\n",
    "        \"Remember that your summary serves as the foundation for generating a comprehensive research report. The quality and depth of the final research report depends directly on how comprehensive and well-synthesized your summary is. Ensure it captures the essence of all provided content relevant to the subtopic.\\n\\n\"\n",
    "\n",
    "        \"FORMAT YOUR SUMMARY AS:\\n\"\n",
    "        \"## Key Insights\\n\"\n",
    "        \"- [Most critical takeaway #1]\\n\"\n",
    "        \"- [Most critical takeaway #2]\\n\"\n",
    "        \"- [Most critical takeaway #3]\\n\"\n",
    "        \"- [Optional: Most critical takeaway #4]\\n\\n\"\n",
    "        \"## Extensive Synthesis\\n\"\n",
    "        \"Write a thorough, multi-paragraph synthesis that:\\n\"\n",
    "        \"- Integrates all important facts, statistics, findings, and insights relevant to the subtopic.\\n\"\n",
    "        \"- Preserves specific numbers, percentages, dates, and technical details.\\n\"\n",
    "        \"- Explains methodologies, technical specifications, and implementation details where relevant.\\n\"\n",
    "        \"- Highlights agreements, disagreements, and nuances between sources.\\n\"\n",
    "        \"- Uses industry-specific terminology and concepts.\\n\"\n",
    "        \"- Provides context, background, and implications for the findings.\\n\"\n",
    "        \"- Maintains logical flow: start with an overview, then go into specifics, and conclude with implications or open questions.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    output_type=str,\n",
    "    model_settings=chatModelSettings\n",
    ")\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    instructions=(\n",
    "        \"## General Instructions\\n\"\n",
    "        \"You are a meticulous research analyst specializing in creating **long, comprehensive, authoritative** reports. \"\n",
    "        \"Your goal is to produce **in-depth, highly detailed** content that thoroughly analyzes all aspects of the research topic. \"\n",
    "        \"Furthermore, you must also demonstrate subject matter expertise with nuanced insights, technical details, and sophisticated analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Style & Format:\\n\"\n",
    "        \"- **Default to paragraphs.** Present your findings in cohesive, well-structured paragraphs rather than excessive bullet points.\\n\"\n",
    "        \"- **Use bullet points sparingly.** Only use them when they add genuine clarity—e.g., summarizing key data.\\n\"\n",
    "        \"- **Structure** the report with a clear hierarchy, but avoid excessive nesting. Aim for a balanced structure:\\n\"\n",
    "        \"   - Use main sections and occasional subsections where needed.\\n\"\n",
    "        \"   - Avoid over-fragmentation by limiting sub-subsections unless absolutely necessary.\\n\"\n",
    "        \"   - Favor broader thematic groupings to maintain narrative flow and reduce section clutter.\\n\"\n",
    "        \"   - With that said, if a subtopic would benefit from a sub-subsection, feel free to add it.\\n\"\n",
    "        \"- **Data visualizations** (e.g., tables, charts, diagrams) in Markdown are encouraged wherever they enhance understanding.\\n\"\n",
    "        \"- Maintain a logical, flowing structure so each subsection builds upon the prior sections.\\n\"\n",
    "        \"- **Citations:** Use IEEE style: [1], [2], etc. Provide a 'References' section at the end of your report with only the sources cited in the text.\\n\\n\"\n",
    "        \n",
    "        \"### Long & Comprehensive Requirement:\\n\"\n",
    "        \"- The final report must be the equivalent of **10 to 12 pages** of substantive text, approximately **7000-9000 words**.\\n\"\n",
    "        \"- Each major section should have **extensive exploration** (ideally 800-1000 words per section).\\n\"\n",
    "        \"- Ensure thorough coverage of the topic with **well-developed paragraphs**, plenty of detail, and rigorous analysis.\\n\\n\"\n",
    "        \n",
    "        \"### Depth Requirements:\\n\"\n",
    "        \"- Include **quantitative data**, statistics, and specific examples to support your arguments.\\n\"\n",
    "        \"- Compare and contrast **multiple perspectives** on complex topics.\\n\"\n",
    "        \"- Integrate ideas across sections for a cohesive, synthesized analysis rather than isolated observations.\\n\\n\"\n",
    "        \n",
    "        \"### Workflow\\n\"\n",
    "        \"- When given the research objective and content, develop a **long-form narrative** with detailed explanations.\\n\"\n",
    "        \"- If PeerReviewAgent provides feedback, revise thoroughly, addressing all points.\\n\"\n",
    "        \"- Once feedback is marked satisfactory, present the final report.\\n\\n\"\n",
    "        \n",
    "        \"### Important Guidelines\\n\"\n",
    "        \"- Retain high-quality content in any revision.\\n\"\n",
    "        \"- If feedback highlights missing info, propose specific research queries.\\n\"\n",
    "        \"- Avoid unnecessary repetition.\\n\\n\"\n",
    "\n",
    "        \"**REMINDER**:\"\n",
    "        \"Your output should be a single, cohesive Markdown document that reads like a well-developed academic or professional paper, with minimal use of bullet points. \"\n",
    "        \"Prefer broader thematic sections over excessive fragmentation. \"\n",
    "        \"Sub-subsections may be used where helpful, but structure should remain balanced and readable. \"\n",
    "        \"Lastly, do not forget to include the references section at the end of the report.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=ComprehensiveResearchReport,\n",
    ")\n",
    "\n",
    "\n",
    "peer_review_agent = Agent(\n",
    "    name=\"PeerReviewAgent\",\n",
    "    instructions=(\n",
    "        \"You are a critical yet constructive peer reviewer evaluating research reports. \"\n",
    "        \"Your goal is to provide detailed, actionable feedback using a structured evaluation framework.\\n\\n\"\n",
    "        \n",
    "        \"## Evaluation Framework:\\n\"\n",
    "        \"1. COMPLETENESS (0-10): Does the report thoroughly cover all aspects of the research topic?\\n\"\n",
    "        \"   - Are all required subtopics adequately addressed?\\n\"\n",
    "        \"   - Is there sufficient depth in each section (500+ words per major section)?\\n\"\n",
    "        \"   - Are there any obvious gaps or missing perspectives?\\n\\n\"\n",
    "        \n",
    "        \"2. CLARITY & STRUCTURE (0-10): Is the report well-organized and clearly written?\\n\"\n",
    "        \"   - Does it have a logical flow with clear sections and subsections?\\n\"\n",
    "        \"   - Are complex concepts explained in accessible language?\\n\"\n",
    "        \"   - Does it use formatting effectively (headings, lists, tables)?\\n\\n\"\n",
    "        \n",
    "        \"3. EVIDENCE & SUPPORT (0-10): Is information well-supported?\\n\"\n",
    "        \"   - Are claims backed by data, statistics, or authoritative sources?\\n\"\n",
    "        \"   - Are citations used appropriately and consistently?\\n\"\n",
    "        \"   - Does it include multiple perspectives when appropriate?\\n\\n\"\n",
    "        \n",
    "        \"4. ANALYSIS & INSIGHT (0-10): Does the report provide valuable analysis?\\n\"\n",
    "        \"   - Does it go beyond summarizing to provide meaningful insights?\\n\"\n",
    "        \"   - Does it connect ideas across different sections?\\n\"\n",
    "        \"   - Does it identify implications and future directions?\\n\\n\"\n",
    "        \n",
    "        \"## Response Guidelines:\\n\"\n",
    "        \"- For each criterion, provide a score (0-10) and specific feedback citing examples from the report\\n\"\n",
    "        \"- In your overall assessment, calculate a total score (0-40)\\n\"\n",
    "        \"- Reports scoring 32+ (80%) can be marked as satisfactory\\n\"\n",
    "        \"- For reports below 32, provide clear, prioritized improvement suggestions\\n\"\n",
    "        \"- Be constructive and specific - point to exact sections that need improvement\\n\"\n",
    "        \n",
    "        \"\\n\\n## Important Rules:\"\n",
    "        \"\\n- If the report meets all quality standards (score ≥32), simply confirm this by changing the is_satisfactory field to true and hand it back to ResearchAgent.\"\n",
    "        \"\\n- Always perform a handoff to ResearchAgent for final report generation.\"\n",
    "    ),\n",
    "    model=chatModel,\n",
    "    model_settings=chatModelSettings,\n",
    "    output_type=PeerReviewFeedback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hand-offs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent.handoffs = [peer_review_agent]\n",
    "peer_review_agent.handoffs = [research_agent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Web Content Scraping** → WebScraperAgent extracts, cleans, and filters relevant content from web pages\n",
    "5. **Analysis** → SummaryAgent processes scraped results, extracting key insights while preserving technical details\n",
    "6. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "7. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "8. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "9. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"162pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 161.88\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.700798 0.700798) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 2256.28,-227 2256.28,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1347.54,-8C1347.54,-8 2003.79,-8 2003.79,-8 2009.79,-8 2015.79,-14 2015.79,-20 2015.79,-20 2015.79,-203 2015.79,-203 2015.79,-209 2009.79,-215 2003.79,-215 2003.79,-215 1347.54,-215 1347.54,-215 1341.54,-215 1335.54,-209 1335.54,-203 1335.54,-203 1335.54,-20 1335.54,-20 1335.54,-14 1341.54,-8 1347.54,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"1675.67\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.85,-72.79C133.42,-72.47 159.62,-72.62 216.49,-73.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.33,-76.71 226.36,-73.32 216.4,-69.71 216.33,-76.71\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.43,-72.26C370.75,-71.89 396.11,-72.04 445.47,-72.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.17,-76.21 455.22,-72.84 445.27,-69.21 445.17,-76.21\"/>\n",
       "<text text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- scraper -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>scraper</title>\n",
       "<path fill=\"#fff5cc\" stroke=\"#4472c4\" d=\"M822.54,-92.25C822.54,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 822.54,-55.75 822.54,-55.75 828.54,-55.75 834.54,-61.75 834.54,-67.75 834.54,-67.75 834.54,-80.25 834.54,-80.25 834.54,-86.25 828.54,-92.25 822.54,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"785.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ScraperAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"785.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Data Extraction</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;scraper -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;scraper</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.3,-71.02C636.13,-70.81 667.42,-71.34 725.15,-72.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"725.06,-76.12 735.14,-72.85 725.22,-69.13 725.06,-76.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M1183.29,-92.25C1183.29,-92.25 1006.04,-92.25 1006.04,-92.25 1000.04,-92.25 994.04,-86.25 994.04,-80.25 994.04,-80.25 994.04,-67.75 994.04,-67.75 994.04,-61.75 1000.04,-55.75 1006.04,-55.75 1006.04,-55.75 1183.29,-55.75 1183.29,-55.75 1189.29,-55.75 1195.29,-61.75 1195.29,-67.75 1195.29,-67.75 1195.29,-80.25 1195.29,-80.25 1195.29,-86.25 1189.29,-92.25 1183.29,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1094.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1094.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- scraper&#45;&gt;summary -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>scraper&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M834.66,-67.98C874.05,-63.85 903.47,-63.79 982.25,-67.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"982.02,-71.29 992.19,-68.31 982.38,-64.29 982.02,-71.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"914.29\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Cleaned Data</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1445.79,-92.25C1445.79,-92.25 1355.54,-92.25 1355.54,-92.25 1349.54,-92.25 1343.54,-86.25 1343.54,-80.25 1343.54,-80.25 1343.54,-67.75 1343.54,-67.75 1343.54,-61.75 1349.54,-55.75 1355.54,-55.75 1355.54,-55.75 1445.79,-55.75 1445.79,-55.75 1451.79,-55.75 1457.79,-61.75 1457.79,-67.75 1457.79,-67.75 1457.79,-80.25 1457.79,-80.25 1457.79,-86.25 1451.79,-92.25 1445.79,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1400.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1400.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1195.42,-65.59C1266.57,-60 1299.1,-58.99 1331.97,-62.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1331.33,-65.98 1341.68,-63.73 1332.18,-59.03 1331.33,-65.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"1269.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1673.79,-52.25C1673.79,-52.25 1584.29,-52.25 1584.29,-52.25 1578.29,-52.25 1572.29,-46.25 1572.29,-40.25 1572.29,-40.25 1572.29,-27.75 1572.29,-27.75 1572.29,-21.75 1578.29,-15.75 1584.29,-15.75 1584.29,-15.75 1673.79,-15.75 1673.79,-15.75 1679.79,-15.75 1685.79,-21.75 1685.79,-27.75 1685.79,-27.75 1685.79,-40.25 1685.79,-40.25 1685.79,-46.25 1679.79,-52.25 1673.79,-52.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1629.04\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1629.04\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1458.28,-64.35C1510.39,-55.62 1538.37,-50.88 1560.78,-46.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1561.38,-50.32 1570.6,-45.1 1560.14,-43.43 1561.38,-50.32\"/>\n",
       "<text text-anchor=\"middle\" x=\"1515.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1907.94,-105.94C1907.94,-105.94 1841.39,-78.56 1841.39,-78.56 1835.84,-76.28 1835.84,-71.72 1841.39,-69.44 1841.39,-69.44 1907.94,-42.06 1907.94,-42.06 1913.49,-39.78 1924.59,-39.78 1930.14,-42.06 1930.14,-42.06 1996.69,-69.44 1996.69,-69.44 2002.24,-71.72 2002.24,-76.28 1996.69,-78.56 1996.69,-78.56 1930.14,-105.94 1930.14,-105.94 1924.59,-108.22 1913.49,-108.22 1907.94,-105.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"1919.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text text-anchor=\"middle\" x=\"1919.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1469.35,-72.63C1698.71,-68.06 1755.47,-67.33 1837.88,-70.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1469.38,-69.13 1459.45,-72.82 1469.52,-76.12 1469.38,-69.13\"/>\n",
       "<text text-anchor=\"middle\" x=\"1629.04\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1685.97,-38.17C1781.93,-45.29 1818.8,-48.76 1854.31,-56.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1853.35,-59.92 1863.88,-58.77 1854.94,-53.1 1853.35,-59.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"1758.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"2183.16\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"2183.16\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text text-anchor=\"middle\" x=\"2183.16\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2006.35,-73.01C2052.44,-72.52 2079.95,-72.32 2102.43,-72.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2102.27,-75.92 2112.29,-72.49 2102.31,-68.92 2102.27,-75.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"2060.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1f758dc83d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram_scraper\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram_scraper()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query=\"What big industries will AI have the most affected on?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "plan = await Runner().run(\n",
    "    starting_agent=planner_agent,\n",
    "    input=user_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['industries most affected by artificial intelligence',\n",
       " 'which sectors are being transformed by AI',\n",
       " 'AI impact on major industries 2024',\n",
       " 'top industries disrupted by AI']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.final_output.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. Multiple search queries are sent to gather diverse perspectives.\n",
    "2. The agent returns structured search results with titles, summaries, relevance scores, and URLs.\n",
    "3. Results are organized by subtopic for further processing.\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to identify promising sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics: 100%|██████████| 4/4 [02:39<00:00, 39.97s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"bingSearchAgentID\"))\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.final_output.research_tasks, desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.create_thread()\n",
    "            message = project_client.agents.create_message(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=formatted_query,\n",
    "            )\n",
    "\n",
    "            # Process the run\n",
    "            run = project_client.agents.create_and_process_run(\n",
    "                thread_id=thread.id,\n",
    "                agent_id=bing_search_agent.id\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.delete_thread(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 16\n",
      "\n",
      "Actually total search queries: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.final_output.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Web Content Scraping\n",
    "\n",
    "The WebScraperAgent processes the URLs and metadata returned by the BingSearchAgent. For each subtopic:\n",
    "\n",
    "1. Only URLs with a high enough relevance score are selected for scraping.\n",
    "2. The WebScraperAgent visits each selected URL and extracts the most relevant content, guided by the user query, subtopic, and search result summary.\n",
    "3. Extracted content is cleaned, deduplicated, and enriched with metadata such as title, source, published date, and extraction method.\n",
    "4. The resulting structured data is organized by subtopic for downstream analysis and summarization.\n",
    "\n",
    "This step ensures that only the most promising and contextually relevant web content is collected, providing a high-quality foundation for subsequent summarization and synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "class ScraperAgentInput(BaseModel):\n",
    "    url: str\n",
    "    subtopic: str\n",
    "    user_query: str\n",
    "    search_result_title: str\n",
    "    visited_urls: Set[str] = Field(default_factory=set)\n",
    "    max_content_length: int = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing scrape tasks...\n",
      "Found 40 unique URLs above threshold to scrape.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement a threshold for relevance score \n",
    "\n",
    "# --- Scraping Phase ---\n",
    "urls_to_process_map = {}\n",
    "\n",
    "print(\"Preparing scrape tasks...\")\n",
    "for subtopic_result in search_results:\n",
    "    subtopic = subtopic_result[\"subtopic\"]\n",
    "    for query_result in subtopic_result[\"queries\"]:\n",
    "        query = query_result[\"query\"]\n",
    "        for result in query_result[\"results\"]:\n",
    "            if result[\"url\"] not in urls_to_process_map:\n",
    "            # if result.relevance_score >= MIN_RELEVANCE_SCORE and result.url not in urls_to_process_map:\n",
    "                urls_to_process_map[result[\"url\"]] = {\n",
    "                    \"subtopic\": subtopic,\n",
    "                    \"query\": query,\n",
    "                    \"search_result_title\": result[\"title\"]\n",
    "                }\n",
    "\n",
    "visited_urls_tracker = set(urls_to_process_map.keys())\n",
    "print(f\"Found {len(urls_to_process_map)} unique URLs above threshold to scrape.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing scrape tasks:   8%|▊         | 3/40 [00:20<04:23,  7.13s/it]WARNING:trafilatura.utils:invalid ZSTD file\n",
      "ERROR:trafilatura.utils:parsed tree length: 0, wrong data type or not valid HTML\n",
      "ERROR:trafilatura.core:empty HTML tree: None\n",
      "WARNING:trafilatura.core:discarding data: None\n",
      "ERROR:trafilatura.utils:parsed tree length: 0, wrong data type or not valid HTML\n",
      "Preparing scrape tasks:  10%|█         | 4/40 [00:23<03:16,  5.45s/it]WARNING:trafilatura.metadata:error in JSON metadata extraction: argument of type 'NoneType' is not iterable\n",
      "Preparing scrape tasks:  12%|█▎        | 5/40 [00:28<03:07,  5.37s/it]WARNING:trafilatura.utils:invalid ZSTD file\n",
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "ERROR:trafilatura.core:empty HTML tree: None\n",
      "WARNING:trafilatura.core:discarding data: None\n",
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "Preparing scrape tasks:  15%|█▌        | 6/40 [00:38<03:50,  6.79s/it]WARNING:trafilatura.utils:invalid ZSTD file\n",
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "ERROR:trafilatura.core:empty HTML tree: None\n",
      "WARNING:trafilatura.core:discarding data: None\n",
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "Preparing scrape tasks:  18%|█▊        | 7/40 [00:41<03:07,  5.70s/it]ERROR:trafilatura.downloads:not a 200 response: 403 for URL https://www.sciencedirect.com/science/article/pii/S2773207X24001386\n",
      "Preparing scrape tasks:  30%|███       | 12/40 [01:12<02:53,  6.20s/it]WARNING:trafilatura.utils:invalid ZSTD file\n",
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "ERROR:trafilatura.core:empty HTML tree: None\n",
      "WARNING:trafilatura.core:discarding data: None\n",
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "Preparing scrape tasks:  40%|████      | 16/40 [01:39<02:32,  6.34s/it]WARNING:trafilatura.utils:invalid ZSTD file\n",
      "ERROR:trafilatura.downloads:not a 200 response: 403 for URL https://calbizjournal.com/5-industries-that-will-be-the-most-heavily-impacted-by-ai/\n",
      "Preparing scrape tasks:  48%|████▊     | 19/40 [01:56<02:11,  6.28s/it]ERROR:trafilatura.downloads:not a 200 response: 403 for URL https://www.weforum.org/stories/2025/03/ai-transforming-global-health/\n",
      "Preparing scrape tasks:  50%|█████     | 20/40 [01:58<01:41,  5.07s/it]WARNING:trafilatura.core:discarding data: None\n",
      "Preparing scrape tasks:  78%|███████▊  | 31/40 [03:38<01:18,  8.67s/it]WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=0, read=None, redirect=2, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)'))': /ai-powered-optimization-supply-chain-operations-883640\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=0, read=None, redirect=2, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)'))': /ai-powered-optimization-supply-chain-operations-883640\n",
      "ERROR:trafilatura.downloads:download error: https://www.ibtimes.co.in/ai-powered-optimization-supply-chain-operations-883640 HTTPSConnectionPool(host='www.ibtimes.co.in', port=443): Max retries exceeded with url: /ai-powered-optimization-supply-chain-operations-883640 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Preparing scrape tasks:  82%|████████▎ | 33/40 [04:21<01:39, 14.22s/it]WARNING:trafilatura.utils:invalid ZSTD file\n",
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "ERROR:trafilatura.core:empty HTML tree: None\n",
      "WARNING:trafilatura.core:discarding data: None\n",
      "ERROR:trafilatura.utils:parsed tree length: 1, wrong data type or not valid HTML\n",
      "Preparing scrape tasks: 100%|██████████| 40/40 [05:14<00:00,  7.87s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "MAX_SCRAPE_CONTENT_LENGTH = 4000 # Max characters for scrape tool\n",
    "\n",
    "scrape_tasks = []\n",
    "num_urls_to_scrape = len(urls_to_process_map)\n",
    "\n",
    "for url, context in tqdm(islice(urls_to_process_map.items(), num_urls_to_scrape),\n",
    "                         desc=\"Preparing scrape tasks\",\n",
    "                         total=num_urls_to_scrape):\n",
    "    agent_input_model = ScraperAgentInput(\n",
    "        url=url,\n",
    "        subtopic=context[\"subtopic\"],\n",
    "        user_query=context[\"query\"],\n",
    "        search_result_title=context[\"search_result_title\"],\n",
    "        visited_urls=visited_urls_tracker,\n",
    "        max_content_length=MAX_SCRAPE_CONTENT_LENGTH\n",
    "    )\n",
    "\n",
    "    scrape_response = await Runner().run(\n",
    "        starting_agent=web_scraper_agent,\n",
    "        input=f\"Scrape data from the provided URL: {agent_input_model.model_dump_json()}\"\n",
    "    )\n",
    "    scrape_tasks.append(scrape_response.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Content Analysis and Summarization\n",
    "\n",
    "For each scraped result, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the cleaned web content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms high-quality scraped data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 4/4 [01:09<00:00, 17.44s/it]\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_contents_and_citations, summarize_content\n",
    "summarize_per_webpage = False  # True will summarize per web page, False will summarize per subtopic\n",
    "\n",
    "# Build a lookup for scraped content (using attribute access)\n",
    "scraped_content_by_url = {\n",
    "    item.url: item.main_content\n",
    "    for item in scrape_tasks\n",
    "    if getattr(item, \"main_content\", None)\n",
    "}\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    contents, citations = collect_contents_and_citations(subtopic_result, scraped_content_by_url)\n",
    "    summaries = await summarize_content(contents, summary_agent, Runner, summarize_per_webpage)\n",
    "    if summarize_per_webpage:\n",
    "        mapped_chunks.append({\n",
    "            \"subtopic\": subtopic_result[\"subtopic\"],\n",
    "            \"summaries\": summaries,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "    else:\n",
    "        mapped_chunks.append({\n",
    "            \"subtopic\": subtopic_result[\"subtopic\"],\n",
    "            \"summaries\": summaries,\n",
    "            \"citations\": citations\n",
    "        })\n",
    "\n",
    "# Filter out empty summaries\n",
    "mapped_chunks = [c for c in mapped_chunks if c['summaries']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "final_answer = await Runner().run(\n",
    "    starting_agent=research_agent,\n",
    "    input=(\n",
    "        \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "        \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "        \"a cohesive, academic-style paper:\\n\\n\"\n",
    "        f\"{research_input_prompt}\\n\\n\"\n",
    "        \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    "    ),\n",
    "    max_turns=21 # 5 turns are needed for a full collaboration between ResearchAgent and PeerReviewAgent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Final Research Report\n",
    "\n",
    "After the ResearchAgent and PeerReviewAgent complete their collaborative process, we extract the final research report from the agent outputs. The report includes:\n",
    "\n",
    "1. A clearly defined research objective\n",
    "2. Multiple sections covering all identified subtopics\n",
    "3. In-depth analysis with facts, statistics, and insights\n",
    "4. Proper citations using IEEE format\n",
    "5. A comprehensive references section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import HandoffCallItem\n",
    "\n",
    "def extract_research_report(final_answer):\n",
    "    # If final output is from ResearchAgent, get the report directly\n",
    "    if hasattr(final_answer.final_output, \"research_report\"):\n",
    "        return final_answer.final_output.research_report\n",
    "    \n",
    "    # If final output is from PeerReviewAgent, find the latest research report from ResearchAgent\n",
    "    for item in reversed(final_answer.new_items):  # Start from end to get the latest\n",
    "        if isinstance(item, HandoffCallItem) and item.agent.name == \"ResearchAgent\":\n",
    "            try:\n",
    "                args = json.loads(item.raw_item.arguments)\n",
    "                if \"research_report\" in args:\n",
    "                    return args[\"research_report\"]\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                continue\n",
    "    \n",
    "    # If we couldn't find a report\n",
    "    raise ValueError(\"No research report found in the conversation history\")\n",
    "\n",
    "research_report = extract_research_report(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Report Presentation\n",
    "\n",
    "The completed research report is displayed below in Markdown format. The report represents a comprehensive analysis of the original query, incorporating insights from multiple web sources and structured in an academic format with proper citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The Transformative Impact of Artificial Intelligence on Major Industries: Nature, Scale, and Implications\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Artificial intelligence (AI) has rapidly evolved from a niche technological curiosity to a central driver of industrial transformation, economic growth, and societal change. As we approach the mid-2020s, AI is no longer confined to experimental pilots or isolated use cases; it is becoming deeply embedded in the core operations and strategic priorities of leading organizations across the globe. This comprehensive report examines the industries most significantly affected by AI, the nature and extent of these impacts, the current and emerging applications driving change, and the future trends poised to reshape the global economic landscape. Drawing on recent data, expert forecasts, and industry case studies, the analysis provides a nuanced, integrated perspective on how AI is redefining value creation, competitive advantage, and the very fabric of work and society.\n",
       "\n",
       "## Identification of Major Industries Impacted by AI\n",
       "\n",
       "### Overview of Industry Transformation\n",
       "\n",
       "AI’s influence is pervasive, but its impact is particularly pronounced in several key sectors: healthcare, finance, retail, manufacturing, automotive, logistics, education, and creative industries. These sectors are not only adopting AI at scale but are also experiencing fundamental shifts in their operating models, value propositions, and workforce dynamics. The convergence of AI with other digital technologies—such as the Internet of Things (IoT), cloud computing, and advanced analytics—further amplifies its transformative potential, enabling new forms of automation, personalization, and data-driven decision-making.\n",
       "\n",
       "### Healthcare\n",
       "\n",
       "Healthcare stands at the forefront of AI-driven transformation. The integration of AI into diagnostics, personalized medicine, operational efficiency, and patient management is revolutionizing care delivery. AI-powered imaging systems, predictive analytics, and robotic-assisted surgeries are enhancing accuracy, reducing costs, and making advanced care more accessible. The sector is also witnessing the rise of digital health ecosystems, where AI-driven platforms support chronic disease management, real-time monitoring, and patient engagement on an unprecedented scale [1], [2].\n",
       "\n",
       "### Finance\n",
       "\n",
       "The finance industry is undergoing a radical metamorphosis, leveraging AI for advanced risk management, fraud detection, autonomous trading, and personalized financial services. AI’s ability to process vast datasets in real time enables financial institutions to identify patterns, anticipate risks, and deliver tailored solutions to clients. The adoption of generative AI and intelligent chatbots is streamlining regulatory compliance and customer service, positioning AI as a core differentiator for competitive advantage [2], [3].\n",
       "\n",
       "### Retail\n",
       "\n",
       "Retailers are harnessing AI to deliver hyper-personalized shopping experiences, optimize inventory and supply chains, and automate marketing and customer service. AI-driven recommendation engines, virtual assistants, and demand forecasting tools are enhancing both consumer satisfaction and operational efficiency. The sector is moving from experimental pilots to scalable, business-aligned AI deployments that directly support strategic objectives [1], [2].\n",
       "\n",
       "### Manufacturing\n",
       "\n",
       "Manufacturing is embracing the era of Industry 4.0, where AI and IoT converge to create smart factories. AI monitors production lines, predicts equipment failures, and optimizes resource allocation, reducing downtime and improving product quality. The integration of AI-powered robotics and advanced vision systems is transforming quality control, safety, and workforce roles [2], [4].\n",
       "\n",
       "### Automotive\n",
       "\n",
       "The automotive sector is experiencing a paradigm shift with the advent of AI-enabled autonomous vehicles, advanced driver-assistance systems (ADAS), and smart manufacturing. AI is central to the development of self-driving cars, predictive maintenance, and personalized in-vehicle experiences. The market for automotive AI is projected to exceed $47 billion by 2033, with compound annual growth rates above 25% [5], [6].\n",
       "\n",
       "### Logistics\n",
       "\n",
       "Logistics and supply chain management are being revolutionized by AI-driven demand forecasting, route optimization, warehouse automation, and predictive maintenance. The sector is achieving measurable reductions in costs, downtime, and inventory levels, while enhancing customer-centricity and global reach [7], [8].\n",
       "\n",
       "### Education and Creative Industries\n",
       "\n",
       "Education is leveraging AI for intelligent tutoring, personalized learning, and administrative automation, while creative industries are adopting generative AI for content creation, design, and media production. These sectors exemplify the broadening scope of AI’s impact beyond traditional industrial domains [9], [10].\n",
       "\n",
       "### Comparative Assessment\n",
       "\n",
       "The following table provides a comparative overview of AI’s impact across major industries, highlighting key applications and projected economic value:\n",
       "\n",
       "| Industry      | Key AI Applications                                 | Projected Economic Value (2030) | Notable Trends                  |\n",
       "|---------------|-----------------------------------------------------|-------------------------------|---------------------------------|\n",
       "| Healthcare    | Diagnostics, personalized medicine, workflow automation | $150B annual savings (US)      | Digital health ecosystems, femtech |\n",
       "| Finance       | Risk management, fraud detection, robo-advisors     | $447B annual savings           | Generative AI, compliance automation |\n",
       "| Retail        | Personalization, inventory optimization, chatbots   | $800B value creation           | Hyper-personalization, marketing automation |\n",
       "| Manufacturing | Smart factories, predictive maintenance, robotics   | $1.5–$2.2T annual value        | Industry 4.0, quality control    |\n",
       "| Automotive    | Autonomous driving, predictive maintenance, personalization | $47B+ market size (2033)       | Level 3+ autonomy, smart cabins  |\n",
       "| Logistics     | Demand forecasting, route optimization, warehouse automation | $1.3–$2T annual value (global) | Real-time data, cross-border platforms |\n",
       "| Education     | Intelligent tutoring, personalized learning         | $100B+ (global)                | AI-driven content, adaptive platforms |\n",
       "| Creative      | Generative design, media production                 | $2.6–$4.4T (GenAI, all sectors)| Synthetic content, automation    |\n",
       "\n",
       "*Sources: [1]–[10]*\n",
       "\n",
       "## Nature and Extent of AI Impact in Key Industries\n",
       "\n",
       "### Healthcare: Toward Integrated, AI-Driven Digital Health\n",
       "\n",
       "The definition of digital health is shifting from isolated telemedicine and digital therapeutics toward integrated, AI-powered solutions that enhance patient-provider relationships and support sustainable economics. AI is rapidly expanding the capabilities of digital health, influencing everything from personalized care and chronic disease management to workflow automation and diagnostic accuracy. Real-time monitoring devices, advanced sleep-tracking, and femtech innovations are transforming patient support, while AI tools empower providers with personalized treatment and evidence-based decision-making [11].\n",
       "\n",
       "AI’s impact on healthcare is both quantitative and qualitative. Predictive analytics enable early identification of health risks, reducing hospitalizations and improving outcomes. AI-powered imaging systems achieve diagnostic accuracy rates exceeding 95%, while robotic surgeries and virtual assistants are making advanced care more accessible. Operationally, AI streamlines administrative tasks, reduces human error, and optimizes supply chains, contributing to significant cost savings and efficiency gains. The integration of smart implants and wearable devices allows for continuous, remote monitoring, facilitating proactive management of chronic conditions and enhancing quality of life.\n",
       "\n",
       "A notable development is the rise of femtech, which addresses long-standing gaps in women’s healthcare. Innovations are focusing on redesigning traditional medical hardware and creating interoperable ecosystems that pool women’s health data, driving improved outcomes. AI-driven decision-support tools are becoming mainstream, granting clinicians immediate access to the latest research and treatment guidelines. At the organizational level, AI is orchestrating entire workflows, managing complete patient episodes across multiple departments, and continuously learning to drive improvements in efficiency and clinical outcomes.\n",
       "\n",
       "### Finance: Autonomous, Secure, and Personalized Services\n",
       "\n",
       "In finance, AI is central to risk management, fraud detection, autonomous trading, and personalized financial services. AI systems analyze enormous volumes of financial data in real time, identifying patterns and anomalies that would be impossible for humans to detect. This capability is particularly valuable for fraud detection, where AI can flag suspicious transactions instantly, reducing financial crime and enhancing security for both institutions and customers.\n",
       "\n",
       "Advanced risk models powered by machine learning enable financial institutions to better anticipate and mitigate potential threats. Automated financial planning and robo-advisors are becoming more sophisticated, offering personalized investment advice and financial strategies around the clock. AI-driven recommendation systems and credit risk assessment tools streamline operations and improve customer engagement. Generative AI is being used to synthesize large datasets for analysts, automate regulatory compliance, and support customer service through intelligent chatbots. The finance sector’s data-driven nature makes it particularly well-suited to AI adoption, and by 2025, AI will be a core differentiator for competitive advantage in the industry [2], [3].\n",
       "\n",
       "### Retail: Hyper-Personalization and Operational Optimization\n",
       "\n",
       "Retailers are leveraging AI to deliver hyper-personalized shopping experiences, both online and in-store. By 2025, AI will enable retailers to analyze consumer behavior, predict purchasing trends, and tailor product recommendations, discounts, and marketing content to individual preferences. AI-powered virtual assistants and chatbots are enhancing customer service by providing instant support, order tracking, and personalized suggestions, freeing human staff for higher-value tasks.\n",
       "\n",
       "Operationally, AI optimizes inventory management, pricing, and demand forecasting. By analyzing sales data and market trends, AI systems help retailers maintain optimal stock levels, reduce waste, and improve supply chain efficiency. Marketing teams are using generative AI to automate campaign creation, content generation, and customer segmentation, increasing both scale and effectiveness. The retail industry is also seeing a shift from experimental AI pilots to scalable, business-aligned use cases. Retailers are focusing on integrating AI into strategic priorities—such as customer engagement, digital commerce, and operational efficiency—rather than deploying AI for its own sake [2], [3].\n",
       "\n",
       "### Manufacturing: Smart Factories and Predictive Maintenance\n",
       "\n",
       "Manufacturing is embracing Industry 4.0, where AI and the Internet of Things (IoT) converge to create smart factories. AI monitors production lines in real time, predicts equipment failures through predictive maintenance, and optimizes inventory and supply chain management. These capabilities reduce downtime, lower costs, and improve product quality while minimizing human error.\n",
       "\n",
       "AI-powered robots are taking over repetitive and hazardous tasks, allowing human workers to focus on more complex and creative roles. Dynamic scheduling and real-time data analysis enable manufacturers to optimize resource allocation, reduce waste, and maintain continuous production. AI vision systems are enhancing quality control by detecting defects that might escape human inspectors. Predictive maintenance solutions, such as Siemens’ Senseye, integrate with SCADA, MES, ERP, and CMMS platforms to monitor thousands of assets in real time, delivering results such as a 12% reduction in unplanned downtime within 12 weeks of deployment [4], [5].\n",
       "\n",
       "### Automotive: Autonomous Vehicles and Smart Mobility\n",
       "\n",
       "The automotive industry is experiencing a paradigm shift with the advent of AI-enabled autonomous vehicles, advanced driver-assistance systems (ADAS), and smart manufacturing. AI is central to the development of self-driving cars, predictive maintenance, and personalized in-vehicle experiences. The market for automotive AI is projected to exceed $47 billion by 2033, with compound annual growth rates above 25% [5], [6].\n",
       "\n",
       "AI is central to the evolution of autonomous vehicles (AVs) and ADAS. In 2025, Level 3 and Level 4 autonomous driving are gaining commercial traction, with Mercedes-Benz achieving regulatory approval for Level 3 autonomy in Germany and parts of the U.S. Companies like Waymo and Cruise are expanding robotaxi operations, leveraging AI for route optimization, real-time decision-making, and safety. AI-powered perception systems—combining LiDAR, cameras, radar, and neural networks—enable vehicles to interpret complex environments and make split-second decisions. The global autonomous vehicle market is expected to reach $126.8 billion by 2030 (CAGR 22.3% from 2024). Notably, Waymo’s AI-driven vehicles have demonstrated an 85% reduction in crash-related injuries compared to human drivers, with only three injury-causing accidents over more than 7 million miles [5], [6].\n",
       "\n",
       "### Logistics: Intelligent Supply Chains and Automation\n",
       "\n",
       "Logistics and supply chain management are being revolutionized by AI-driven demand forecasting, route optimization, warehouse automation, and predictive maintenance. The sector is achieving measurable reductions in costs, downtime, and inventory levels, while enhancing customer-centricity and global reach. AI-driven route optimization analyzes real-time traffic and weather data to reduce fuel costs and delivery times, supporting sustainability goals. Companies using AI in logistics report operational cost reductions of up to 50% and improved safety rates by 90% [7], [8].\n",
       "\n",
       "AI-powered robotics and computer vision are transforming warehouses into intelligent, automated hubs. These systems manage inventory, sort and organize products, and enhance worker safety. Automated document processing (OCR) accelerates shipment handling and reduces manual errors. Predictive maintenance in logistics, powered by AI and IoT sensors, detects anomalies in equipment performance (heat, vibration, cycle times), reducing downtime by 50%, breakdowns by 70%, and maintenance costs by 25%. For example, BMW’s AI-supported systems save over 500 minutes of disruption per plant annually [7], [8].\n",
       "\n",
       "### Education and Creative Industries: Personalization and Generative AI\n",
       "\n",
       "Education is leveraging AI for intelligent tutoring, personalized learning, and administrative automation, while creative industries are adopting generative AI for content creation, design, and media production. These sectors exemplify the broadening scope of AI’s impact beyond traditional industrial domains. AI-powered education tools are anticipated to democratize access to quality learning, reducing education costs by 20–30% and potentially increasing workforce participation among women and underrepresented groups by 15–20% [9], [10].\n",
       "\n",
       "## Current and Emerging AI Applications in These Industries\n",
       "\n",
       "### Healthcare: AI-Driven Digital Health Ecosystems\n",
       "\n",
       "The maturation of AI technologies, particularly generative AI (GenAI), is poised to influence every facet of healthcare. AI’s expanding role is evident in its application to chronic disease management—such as heart failure, diabetes, and mental health—where digital solutions are being leveraged to close persistent gaps in care. The integration of smart implants and wearable devices allows for continuous, remote monitoring of key biological functions like cardiac activity and blood glucose levels. This real-time data collection not only facilitates proactive management of chronic conditions but also enhances patients’ quality of life by enabling timely interventions [11].\n",
       "\n",
       "Sleep, increasingly recognized as a critical biomarker for overall health, is another area where digital health is innovating. Advanced sleep-tracking technologies are being developed to provide more accurate and actionable insights, reflecting a broader trend toward individualized health monitoring. Digital platforms and mobile apps are giving patients unprecedented control over their health, offering predictive analytics to anticipate flare-ups and suggesting real-time interventions. AI chatbots and virtual assistants are expected to become mainstream, providing immediate answers to health-related questions and supporting patient engagement.\n",
       "\n",
       "A notable development is the rise of femtech, which seeks to address long-standing gaps in women’s healthcare. Innovations are focusing on redesigning traditional medical hardware, such as the speculum, with the female experience at the center. This shift is urgently needed, as evidenced by a recent BCG X survey indicating that only 41% of women globally feel their specific health concerns are adequately addressed by existing services. The maturation of partnerships between femtech and wellness brands is fostering interoperable ecosystems that pool women’s health data, with the potential to drive significantly improved outcomes.\n",
       "\n",
       "On the provider side, AI is empowering clinicians by enabling the processing of vast quantities of personalized patient data. This supports the delivery of highly tailored medical treatments, informed by continuous monitoring, lifestyle factors, and genetic information. Providers can dynamically adjust care plans in real time, enhancing both efficacy and patient safety. AI-powered decision-support tools are set to become mainstream in 2025, granting clinicians immediate access to the latest evidence-based research and treatment guidelines. GenAI applications are expected to accelerate diagnostic processes, reduce errors, and improve the accuracy of outcome predictions, thus streamlining patient care delivery.\n",
       "\n",
       "At the organizational level, the role of AI is expanding from automating discrete tasks to orchestrating entire workflows. Instead of isolated tools for note-taking or appointment scheduling, intelligent AI agents will manage complete patient episodes—from intake through treatment planning—across multiple departments. These systems will continuously learn and adapt, driving improvements in both efficiency and clinical outcomes at the patient and system levels.\n",
       "\n",
       "### Automotive: Autonomous Driving, Smart Manufacturing, and Personalization\n",
       "\n",
       "AI is fundamentally transforming the automotive industry, driving efficiency, cost savings, safety, and innovation across the entire value chain. In the realm of autonomous driving, AI adoption is accelerating in Level 3+ autonomy, predictive maintenance, smart manufacturing, generative design, and personalized in-vehicle experiences. The global automotive AI market is projected to reach between $47.3 billion (by 2033, IMARC Group) and $48.59 billion (by 2034, various sources), with compound annual growth rates (CAGR) ranging from 24.1% to 29.61% [5], [6].\n",
       "\n",
       "#### Autonomous Driving and Advanced Driver-Assistance Systems (ADAS)\n",
       "\n",
       "AI is central to the evolution of autonomous vehicles (AVs) and ADAS. In 2025, Level 3 and Level 4 autonomous driving are gaining commercial traction, with Mercedes-Benz achieving regulatory approval for Level 3 autonomy in Germany and parts of the U.S. Companies like Waymo and Cruise are expanding robotaxi operations, leveraging AI for route optimization, real-time decision-making, and safety. AI-powered perception systems—combining LiDAR, cameras, radar, and neural networks—enable vehicles to interpret complex environments and make split-second decisions. The global autonomous vehicle market is expected to reach $126.8 billion by 2030 (CAGR 22.3% from 2024). Notably, Waymo’s AI-driven vehicles have demonstrated an 85% reduction in crash-related injuries compared to human drivers, with only three injury-causing accidents over more than 7 million miles [5], [6].\n",
       "\n",
       "#### Manufacturing, Predictive Maintenance, and Quality Control\n",
       "\n",
       "AI is revolutionizing automotive manufacturing through smart factories, predictive maintenance, and AI-driven quality control. Machine learning (ML) and deep learning (DL) are used to analyze vast datasets from thousands of connected assets—such as stamping machines, robotic welders, and inspection systems. Predictive maintenance solutions, like Siemens’ Senseye, integrate with SCADA, MES, ERP, and CMMS platforms to monitor over 10,000 assets in real time, delivering results such as a 12% reduction in unplanned downtime within 12 weeks of deployment. AI-based image recognition systems, like those in BMW’s “Factory of the Future,” achieve defect detection accuracy above 98%. AI-driven manufacturing can reduce operational costs by up to 20% (McKinsey), and predictive maintenance can cut maintenance costs by 10-40% and unplanned downtime by up to 50% (Deloitte) [5], [6].\n",
       "\n",
       "#### In-Vehicle Experience and Personalization\n",
       "\n",
       "AI is transforming the in-cabin experience through natural language processing (NLP), voice assistants (Amazon Alexa, Google Assistant, Mercedes-Benz MBUX), and real-time edge AI processing (NVIDIA, Qualcomm). Vehicles are becoming “smartphones on wheels,” offering personalized settings, predictive suggestions, and adaptive infotainment. By 2025, AI-powered personalization is expected to become mainstream, with vehicles remembering user preferences and adapting cabin environments accordingly.\n",
       "\n",
       "#### Economic Impact and Adoption Metrics\n",
       "\n",
       "AI adoption is widespread: 54 million cars with some level of automation were on the roads last year, up from 31 million in 2019. 75% of automotive companies are experimenting with generative AI, with the remainder planning adoption within a year. AI-driven transformations have reduced automotive industry costs by 8-12%, with potential returns on investment of 10-15x within three years. In dealerships, 81% anticipate increased AI budgets for 2025, and 37% report revenue increases of 20-30% due to AI solutions [5], [6].\n",
       "\n",
       "#### Supply Chain and Logistics Integration\n",
       "\n",
       "AI enhances supply chain visibility, real-time tracking, and inventory optimization. AI-driven analytics enable proactive management of inventory, supplier performance, and logistics, reducing stockouts and improving customer satisfaction. In the aftermarket, AI automates diagnostics, predictive parts ordering, and customer service, further streamlining operations.\n",
       "\n",
       "### Logistics: Demand Forecasting, Route Optimization, and Warehouse Automation\n",
       "\n",
       "AI is revolutionizing logistics by enabling accurate demand forecasting (reducing errors by 20-50%), optimizing inventory levels (reductions of 35%), and boosting service levels (up to 65%). AI-driven route optimization analyzes real-time traffic and weather data to reduce fuel costs and delivery times, supporting sustainability goals. Companies using AI in logistics report operational cost reductions of up to 50% and improved safety rates by 90% [7], [8].\n",
       "\n",
       "AI-powered robotics and computer vision are transforming warehouses into intelligent, automated hubs. These systems manage inventory, sort and organize products, and enhance worker safety. Automated document processing (OCR) accelerates shipment handling and reduces manual errors. Predictive maintenance in logistics, powered by AI and IoT sensors, detects anomalies in equipment performance (heat, vibration, cycle times), reducing downtime by 50%, breakdowns by 70%, and maintenance costs by 25%. For example, BMW’s AI-supported systems save over 500 minutes of disruption per plant annually [7], [8].\n",
       "\n",
       "AI-driven platforms like ShipToBox.com streamline global shopping and shipping, offering real-time tracking, customs automation, and embedded fintech solutions for seamless international commerce. AI enhances customer experiences through proactive notifications, personalized service, and adaptive logistics workflows. AI adoption in logistics could generate $1.3–$2 trillion per year in economic value over the next two decades. Companies like Microsoft are providing reference architectures and AI-enhanced cloud solutions to accelerate digital transformation across inbound and outbound logistics, warehouse management, and customer service [7], [8].\n",
       "\n",
       "### Cross-Industry Trends: Generative AI, Data Quality, and Strategic Alignment\n",
       "\n",
       "A significant trend across all industries is the rapid adoption of generative AI (gen AI) and multimodal AI agents. These technologies are moving from experimental pilots to practical, value-generating deployments. Use cases include AI-powered search, customer experience personalization, content generation, and even deepfake defense. According to a Google Cloud-commissioned study, about one-third of organizations are still evaluating or testing gen AI use cases, but momentum is building as executives recognize AI’s potential as a business differentiator [2], [3].\n",
       "\n",
       "The success of AI initiatives is increasingly tied to data quality and integration. Organizations are investing heavily in improving data infrastructure, recognizing that effective AI relies on high-quality, well-integrated data. This shift marks a departure from previous attitudes that dismissed data projects as low priority. Executives are now challenged to build robust AI strategies that align with core business objectives, select appropriate AI models, and navigate cultural and organizational changes. The boardroom is as involved in AI decisions as the IT department, reflecting the strategic importance of AI for future competitiveness [2], [3].\n",
       "\n",
       "## Future Trends and Forecasts for AI in Major Industries\n",
       "\n",
       "### Macroeconomic Impact and Regional Dynamics\n",
       "\n",
       "Artificial intelligence is poised to be a transformative force for the global economy, with projections indicating a contribution of up to $15.7 trillion by 2030—surpassing the current combined output of China and India. This value will be realized through two main channels: $6.6 trillion from labor productivity improvements and $9.1 trillion from consumption-side effects, such as enhanced product personalization, variety, and affordability. Notably, 45% of the total economic gains by 2030 are expected to stem from product enhancements that stimulate consumer demand [12], [13].\n",
       "\n",
       "Regionally, the economic impact will be concentrated, with China and North America accounting for nearly 70% of global gains. China is forecasted to see a 26% GDP boost, translating to $10.7 trillion, while North America is expected to experience a 14.5% increase. These gains are attributed to early and strategic investments in AI technologies, rapid adoption, and leadership in innovation [12], [13].\n",
       "\n",
       "### Industry Transformations and Value Creation\n",
       "\n",
       "AI is already reshaping industries, with the most advanced adoption seen in banking and finance, retail and eCommerce, media and marketing, and IT. In healthcare, AI-powered diagnostics, personalized medicine, and operational efficiencies are projected to save $150 billion annually in the U.S. by 2030. Manufacturing will benefit from smart factories leveraging AI and IoT, adding $1.5–$2.2 trillion in annual value through efficiency gains, predictive maintenance, and quality control. The finance sector stands to save over $447 billion by 2030 via fraud detection, process automation, and customer experience improvements [12], [13].\n",
       "\n",
       "Generative AI, in particular, is expected to generate $2.6–$4.4 trillion in value across industries, with 50% of 2023 work activities potentially automatable by 2060. AI’s ability to process vast datasets, reduce costs, and provide predictive analytics is driving widespread adoption: 32% of businesses have already implemented AI, and 42% are exploring future adoption [12], [13].\n",
       "\n",
       "### Workforce and Societal Implications\n",
       "\n",
       "The labor market will be profoundly affected. By 2027, AI is expected to create 97 million new jobs globally while displacing 85 million, resulting in a net positive but requiring significant reskilling and upskilling. Roles in high demand will include AI ethicists, machine learning engineers, and AI trainers. By 2030, 50% of the global workforce will need retraining due to AI integration. AI-powered education tools are anticipated to democratize access to quality learning, reducing education costs by 20–30% and potentially increasing workforce participation among women and underrepresented groups by 15–20% [12], [13].\n",
       "\n",
       "### Investment, Regulation, and Emerging Markets\n",
       "\n",
       "Global AI investments are projected to reach $1.5 trillion by 2030, driven by advancements in generative AI, autonomous systems, and AI-driven R&D. Emerging markets such as Africa and Southeast Asia are poised for rapid growth due to lower adoption costs and rising digital literacy, offering opportunities to leapfrog more developed economies. Governments are responding with regulatory frameworks to manage AI risks, ensure transparency, and address ethical concerns. The global AI governance market is expected to grow to $50 billion by 2030. The EU AI Act and similar legislation are coming into effect, requiring businesses to maintain AI inventories and comply with staggered enforcement measures [12], [13].\n",
       "\n",
       "### Technical and Implementation Trends\n",
       "\n",
       "AI technology is evolving rapidly. By 2026, 30% of new apps will feature AI-driven personalized adaptive interfaces, and 75% of businesses will use generative AI to create synthetic customer data. By 2027, over 50% of generative AI models will be industry- or function-specific, enhancing precision and utility. The use of synthetic data is expected to become the norm, addressing data privacy and quality issues. By 2028, 50% of enterprises will move away from building large AI models from scratch due to cost, complexity, and technical debt. Instead, they will favor more specialized, modular solutions. Machine customers—autonomous agents making purchases—will account for 20% of digital storefront revenue by 2030, fundamentally altering e-commerce and marketing strategies [12], [13].\n",
       "\n",
       "### Environmental and Security Implications\n",
       "\n",
       "AI will play a crucial role in addressing climate change, with AI-driven solutions projected to reduce global carbon emissions by up to 10% by 2030 through optimized energy use, precision agriculture, and supply chain efficiencies. However, the proliferation of AI also introduces new cybersecurity risks, with AI-driven cyberattacks potentially costing businesses $10 trillion annually by 2030 [12], [13].\n",
       "\n",
       "### Challenges and Barriers\n",
       "\n",
       "Despite its promise, AI adoption faces significant hurdles. Ethical concerns—such as bias, data privacy, and the potential misuse of AI—remain unresolved. Economic inequality may be exacerbated by disparities in AI access and implementation. Regulatory complexity, particularly harmonizing standards across jurisdictions, will be an ongoing challenge. Additionally, technical barriers such as poor data quality, inadequate risk controls, and unclear business value have led to high abandonment rates (30% of GenAI projects post-POC in 2025) [12], [13].\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "By 2025 and beyond, artificial intelligence will be deeply embedded in the fabric of major industries, driving unprecedented levels of efficiency, personalization, and innovation. Healthcare, finance, retail, manufacturing, automotive, and logistics are leading the way, but the ripple effects of AI adoption are being felt across the entire economy and society. The organizations that succeed will be those that strategically align AI with their core value chains, invest in data quality, and adapt to the evolving landscape of technology, regulation, and workforce dynamics. The future promises not just smarter businesses, but also more responsive, accessible, and human-centered services powered by AI. However, realizing the full potential of AI will require addressing complex challenges related to ethics, regulation, workforce transformation, and data governance. The pace of change will be rapid, and adaptability will be critical for capturing the immense value AI promises to deliver by 2030 and beyond.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] AI in 2025 - Reshaping Healthcare, Finance, and Retail, https://www.capitalnumbers.com/blog/ai-in-2025-healthcare-finance-retail/\n",
       "\n",
       "[2] AI's impact on industries in 2025 | Google Cloud Blog, https://cloud.google.com/transform/ai-impact-industries-2025\n",
       "\n",
       "[3] The Future of Artificial Intelligence (AI) in 2025: Transforming ..., https://www.linkedin.com/pulse/future-artificial-intelligence-ai-2025-transforming-industries-sinha-cjjbc\n",
       "\n",
       "[4] AI in 2025: How Artificial Intelligence is Reshaping Industries and Society, https://topnewsvoice.com/in-depth-reports/ai-in-2025-how-artificial-intelligence-is-reshaping-industries-and-society/\n",
       "\n",
       "[5] Top AI Trends Reshaping the Global Automotive Industry (2025 Edition), https://autotechdrive.com/top-ai-trends-reshaping-the-global-automotive-industry/\n",
       "\n",
       "[6] AI in Automotive: A Strategic Guide [2025-2030] | StartUs Insights, https://www.startus-insights.com/innovators-guide/ai-in-automotive/\n",
       "\n",
       "[7] AI in Logistics 2025: Real Use Cases & Industry Results, https://noloco.io/blog/ai-in-logistics\n",
       "\n",
       "[8] Top AI Trends for the Logistics Industry 2025, https://api4.ai/blog/top-ai-trends-for-the-logistics-industry-2025\n",
       "\n",
       "[9] AI Forecast: Industries we can expect to transform by 2030, https://www.infobip.com/blog/industries-affected-by-ai\n",
       "\n",
       "[10] The AI Revolution: Changing Industries in 2024 - AI Tech Daily, https://www.aitechdaily.com/the-ai-revolution-changing-industries-in-2024/\n",
       "\n",
       "[11] How Digital & AI Will Reshape Health Care in 2025 | BCG, https://www.bcg.com/publications/2025/digital-ai-solutions-reshape-health-care-2025\n",
       "\n",
       "[12] PwC's Global Artificial Intelligence Study | PwC, https://www.pwc.com/gx/en/issues/artificial-intelligence/publications/artificial-intelligence-study.html\n",
       "\n",
       "[13] Economic Impact and Projections Report: The Integration of AI and ..., https://www.joineta.org/blog/economic-impact-and-projections-report-the-integration-of-ai-and-emerging-technologies-2025-2030\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(research_report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Workflow Visualization\n",
    "\n",
    "Below we can see the detailed steps in the research and review process, showing how the ResearchAgent and PeerReviewAgent collaborated to produce the final report. This visualization helps us understand how many iterations were required to meet quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 AGENT WORKFLOW: 'Create an exceptionally comprehensive, **paragraph-focused** and detailed research report using the following content. **Minimize bullet points** and ensure the final text resembles a cohesive, academic-style paper:\n",
      "\n",
      "{\n",
      "  \"objective\": \"To identify and analyze the major industries that are and will be most significantly impacted by artificial intelligence (AI), including the nature, scale, and implications of these impacts.\",\n",
      "  \"aggregated_summaries\": [\n",
      "    {\n",
      "      \"subtopic\": \"Identification of Major Industries Impacted by AI\",\n",
      "      \"summaries\": \"Acknowledging that the input combines information from multiple search results, here is a unified, comprehensive summary focused on the subtopic: **The Impact of Artificial Intelligence on Key Industries by 2025**.\\n\\n---\\n\\n## Key Insights\\n\\n- **AI will be a transformative force across healthcare, finance, retail, manufacturing, and more by 2025, driving efficiency, innovation, and competitive advantage.**\\n- **Healthcare will see AI revolut'\n",
      "\n",
      "\n",
      "================================================================================\n",
      "👤 AGENT: ResearchAgent\n",
      "--------------------------------------------------------------------------------\n",
      "  💬 OUTPUT: {\"objective\":\"To identify and analyze the major industries that are and will be most significantl...\n",
      "\n",
      "================================================================================\n",
      "🏁 FINAL OUTPUT:\n",
      "--------------------------------------------------------------------------------\n",
      "# The Transformative Impact of Artificial Intelligence on Major Industries: Nature, Scale, and Implications\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Artificial intelligence (AI) has rapidly evolved from a niche technologica...\n"
     ]
    }
   ],
   "source": [
    "from common.helper import pretty_print_agent_workflow\n",
    "pretty_print_agent_workflow(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson-deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
