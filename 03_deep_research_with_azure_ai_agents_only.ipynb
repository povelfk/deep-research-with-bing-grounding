{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Agent Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will **create the Azure AI Agents**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common.create_azure_ai_agents import (\n",
    "#     create_bing_search_agent,\n",
    "#     create_research_plan_agent,\n",
    "#     create_summary_agent,\n",
    "#     create_research_report_agent,\n",
    "#     create_peer_review_agent\n",
    "# )\n",
    "\n",
    "# planner_agent = create_research_plan_agent(project_client=project_client)\n",
    "# bing_search_agent = create_bing_search_agent(project_client=project_client)\n",
    "# summary_agent = create_summary_agent(project_client=project_client)\n",
    "# research_agent = create_research_report_agent(project_client=project_client)\n",
    "# peer_review_agent = create_peer_review_agent(project_client=project_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch agents from your AI Foundry Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PlannerAgentID\"))\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"BingSearchAgentID\"))\n",
    "summary_agent = project_client.agents.get_agent(agent_id=os.getenv(\"SummaryAgentID\"))\n",
    "research_agent = project_client.agents.get_agent(agent_id=os.getenv(\"ResearchAgentID\"))\n",
    "peer_review_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PeerReviewAgentID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update their system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.update_instructions import (\n",
    "    update_planner_instructions,\n",
    "    update_bing_instructions,\n",
    "    update_summary_instructions,\n",
    "    update_research_instructions,\n",
    "    update_peer_review_instructions\n",
    ")\n",
    "\n",
    "planner_agent = update_planner_instructions(agent=planner_agent)\n",
    "bing_search_agent = update_bing_instructions(agent=bing_search_agent)\n",
    "summary_agent = update_summary_instructions(agent=summary_agent)\n",
    "research_agent = update_research_instructions(agent=research_agent)\n",
    "peer_review_agent = update_peer_review_instructions(agent=peer_review_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"183pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 182.68\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.790802 0.790802) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 1999.03,-227 1999.03,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1090.29,-8C1090.29,-8 1746.54,-8 1746.54,-8 1752.54,-8 1758.54,-14 1758.54,-20 1758.54,-20 1758.54,-203 1758.54,-203 1758.54,-209 1752.54,-215 1746.54,-215 1746.54,-215 1090.29,-215 1090.29,-215 1084.29,-215 1078.29,-209 1078.29,-203 1078.29,-203 1078.29,-20 1078.29,-20 1078.29,-14 1084.29,-8 1090.29,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"1418.42\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.86,-72.6C133.43,-72.24 159.62,-72.4 216.49,-73.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.32,-76.59 226.37,-73.22 216.41,-69.59 216.32,-76.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.46,-71.88C370.78,-71.43 396.13,-71.62 445.49,-72.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.18,-75.92 455.23,-72.59 445.29,-68.92 445.18,-75.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M926.04,-92.25C926.04,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 926.04,-55.75 926.04,-55.75 932.04,-55.75 938.04,-61.75 938.04,-67.75 938.04,-67.75 938.04,-80.25 938.04,-80.25 938.04,-86.25 932.04,-92.25 926.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;summary -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.28,-69C638.59,-68.14 669.02,-68.56 725.16,-70.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.73,-73.76 734.83,-70.57 724.94,-66.76 724.73,-73.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1188.54,-92.25C1188.54,-92.25 1098.29,-92.25 1098.29,-92.25 1092.29,-92.25 1086.29,-86.25 1086.29,-80.25 1086.29,-80.25 1086.29,-67.75 1086.29,-67.75 1086.29,-61.75 1092.29,-55.75 1098.29,-55.75 1098.29,-55.75 1188.54,-55.75 1188.54,-55.75 1194.54,-55.75 1200.54,-61.75 1200.54,-67.75 1200.54,-67.75 1200.54,-80.25 1200.54,-80.25 1200.54,-86.25 1194.54,-92.25 1188.54,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M881.86,-55.34C964.88,-21.4 990.44,-20.14 1081.1,-51.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.86,-54.82 1090.45,-54.83 1082.17,-48.22 1079.86,-54.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"1012.17\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1416.54,-52.25C1416.54,-52.25 1327.04,-52.25 1327.04,-52.25 1321.04,-52.25 1315.04,-46.25 1315.04,-40.25 1315.04,-40.25 1315.04,-27.75 1315.04,-27.75 1315.04,-21.75 1321.04,-15.75 1327.04,-15.75 1327.04,-15.75 1416.54,-15.75 1416.54,-15.75 1422.54,-15.75 1428.54,-21.75 1428.54,-27.75 1428.54,-27.75 1428.54,-40.25 1428.54,-40.25 1428.54,-46.25 1422.54,-52.25 1416.54,-52.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1200.81,-63.21C1253.32,-53.35 1281.27,-48.19 1303.85,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1304.14,-47.88 1313.43,-42.79 1302.99,-40.97 1304.14,-47.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"1257.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1650.69,-105.94C1650.69,-105.94 1584.14,-78.56 1584.14,-78.56 1578.59,-76.28 1578.59,-71.72 1584.14,-69.44 1584.14,-69.44 1650.69,-42.06 1650.69,-42.06 1656.24,-39.78 1667.34,-39.78 1672.89,-42.06 1672.89,-42.06 1739.44,-69.44 1739.44,-69.44 1744.99,-71.72 1744.99,-76.28 1739.44,-78.56 1739.44,-78.56 1672.89,-105.94 1672.89,-105.94 1667.34,-108.22 1656.24,-108.22 1650.69,-105.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1211.83,-72.2C1443.6,-66.13 1499.16,-65.21 1583.06,-69.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1212.08,-68.69 1202.17,-72.45 1212.26,-75.69 1212.08,-68.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.68,-37.82C1526.04,-44.45 1562.55,-47.76 1598.61,-56.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.31,-59.39 1607.86,-58.37 1598.98,-52.59 1597.31,-59.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"1500.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"1925.91\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1748.73,-72.86C1794.97,-72.28 1822.55,-72.05 1845.08,-72.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1844.92,-75.66 1854.95,-72.24 1844.98,-68.66 1844.92,-75.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"1803.67\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2222801b9a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageRole\n",
    "from common.data_models import ResearchPlan\n",
    "from common.utils_ai_agents import (\n",
    "    add_user_message_to_thread,\n",
    "    invoke_agent\n",
    ")\n",
    "import json\n",
    "\n",
    "# create a thread and add the user message\n",
    "thread = project_client.agents.threads.create()\n",
    "add_user_message_to_thread(project_client, thread.id, user_query)\n",
    "\n",
    "# invoke the planner agent to create a research plan\n",
    "planner_agent_output, thread = invoke_agent(\n",
    "    project_client=project_client,\n",
    "    thread=thread,\n",
    "    agent=planner_agent\n",
    ")\n",
    "\n",
    "# parse the output to a ResearchPlan object\n",
    "plan_data = json.loads(planner_agent_output)\n",
    "plan = ResearchPlan(**plan_data)\n",
    "\n",
    "# delete the thread\n",
    "project_client.agents.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is classical machine learning?',\n",
       " 'Definition of deep learning in AI',\n",
       " 'What is generative AI?',\n",
       " 'Overview of classical machine learning vs deep learning vs generative AI',\n",
       " 'Key characteristics of classical ML, deep learning, and generative AI']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics: 100%|██████████| 5/5 [03:55<00:00, 47.06s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.research_tasks, desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, formatted_query)\n",
    "\n",
    "            bing_search_agent_output, thread = invoke_agent(\n",
    "                project_client=project_client,\n",
    "                thread=thread,\n",
    "                agent=bing_search_agent\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 25\n",
      "\n",
      "Actually total search queries: 25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 5/5 [01:36<00:00, 19.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    all_agent_responses_for_subtopic, unique_citations_for_subtopic = collect_responses_and_citations(subtopic_result)\n",
    "\n",
    "    # --- Summarize the combined agent responses ONCE per subtopic ---\n",
    "    content_to_summarize = \"\\n\\n---\\n\\n\".join(all_agent_responses_for_subtopic)\n",
    "\n",
    "    subtopic_summary = \"No content found to summarize for this subtopic.\" # Default value\n",
    "    if content_to_summarize:\n",
    "        summary_prompt = f\"Summarize the following information related to the subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content_to_summarize}\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, summary_prompt)\n",
    "            # Invoke the summary agent to summarize the content\n",
    "            summary_agent_output, thread = invoke_agent(\n",
    "                project_client=project_client,\n",
    "                thread=thread,\n",
    "                agent=summary_agent\n",
    "            )\n",
    "\n",
    "            # run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=summary_agent.id)\n",
    "            # subtopic_summary = get_last_message_by_role(project_client, thread.id, MessageRole.AGENT)\n",
    "            subtopic_summary = summary_agent_output.strip()  # Ensure we get the text output\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}': {e}\")\n",
    "            subtopic_summary = f\"Error during summarization for subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}'. Details: {e}\"\n",
    "            # Depending on requirements, you might want to raise the exception, log it, or handle it differently\n",
    "\n",
    "    # --- Convert set of tuples back to list of dictionaries (or Citation objects) ---\n",
    "    citations_list = [\n",
    "        {\"title\": title, \"url\": url}\n",
    "        for title, url in unique_citations_for_subtopic\n",
    "    ]\n",
    "\n",
    "    # --- Append the consolidated result ---\n",
    "    mapped_chunks.append({\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"), # Use .get for safety\n",
    "        \"summary\": subtopic_summary,\n",
    "        \"citations\": citations_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_thread_messages(thread):\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for m in messages:\n",
    "        print(f\"roll: {m.role}\")\n",
    "        print(f\"agent_id: {m.agent_id}\")\n",
    "        print(f\"content: {m.content[0]['text']['value']}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_models import ComprehensiveResearchReport, PeerReviewFeedback\n",
    "from common.utils_ai_agents import add_user_message_to_thread\n",
    "\n",
    "def loop_agents(project_client, agent_a, agent_b, initial_input, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Loop between two agents until agent B produces the target output.\n",
    "    \n",
    "    Args:\n",
    "        agent_a: Function that takes input and returns output\n",
    "        agent_b: Function that takes input and returns output\n",
    "        initial_input: Starting input for agent A\n",
    "        max_iterations: Safety limit to prevent infinite loops\n",
    "    \n",
    "    Returns:\n",
    "        The final output from agent B, or None if max iterations reached\n",
    "    \"\"\"\n",
    "    current_input = initial_input\n",
    "    thread = project_client.agents.threads.create()\n",
    "    add_user_message_to_thread(project_client, thread.id, current_input)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # Agent A processes the input and produces output\n",
    "        a_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_a\n",
    "        )\n",
    "\n",
    "        handover_message = f\"A research agent has produced a research report. Please review it.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "        \n",
    "        # Agent B reviews the output\n",
    "        b_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_b\n",
    "        )\n",
    "\n",
    "        b_output_json = json.loads(b_output)\n",
    "        review = PeerReviewFeedback(**b_output_json)\n",
    "\n",
    "        # Check if B produced the target output\n",
    "        if review.is_satisfactory is not False:\n",
    "            print(f\"Target output reached after {i+1} iterations!\")\n",
    "            report_json = json.loads(a_output)\n",
    "            final_report = ComprehensiveResearchReport(**report_json)\n",
    "\n",
    "            # delete the thread\n",
    "            # print_thread_messages(thread)\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            return final_report\n",
    "        \n",
    "        # Use B's output as input for the next iteration\n",
    "        current_input = b_output\n",
    "        \n",
    "        handover_message = f\"Peer review agent has provided feedback. Please revise the research report based on the feedback.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "\n",
    "    # delete the thread\n",
    "    # print_thread_messages(thread)\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"Max iterations ({max_iterations}) reached without finding target output\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target output reached after 1 iterations!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "research_query = (\n",
    "    \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "    \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "    \"a cohesive, academic-style paper:\\n\\n\"\n",
    "    f\"{research_input_prompt}\\n\\n\"\n",
    "    \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    ")\n",
    "\n",
    "# Run the loop\n",
    "final_report = loop_agents(\n",
    "    project_client=project_client,\n",
    "    agent_a=research_agent,\n",
    "    agent_b=peer_review_agent,\n",
    "    initial_input=research_query,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The Evolution and Distinction of Classical Machine Learning, Deep Learning, and Generative AI: Definitions, Methodologies, Applications, and Implications\n",
       "\n",
       "## Introduction\n",
       "\n",
       "The field of artificial intelligence (AI) has undergone a profound transformation over the past several decades, evolving from rule-based symbolic systems to sophisticated, data-driven models capable of perception, reasoning, and creative generation. At the heart of this evolution are three major paradigms: classical machine learning, deep learning, and generative AI. Each represents a distinct approach to modeling, learning, and problem-solving, shaped by advances in theory, computational power, and the ever-increasing availability of data. This report aims to provide a comprehensive, nuanced, and authoritative analysis of these paradigms, elucidating their definitions, methodologies, real-world applications, strengths, limitations, and historical trajectories. Through a detailed comparative exploration, we seek to clarify not only how these approaches differ but also how they collectively underpin the expanding landscape of intelligent systems and automation in society.\n",
       "\n",
       "## Definitions and Core Concepts\n",
       "\n",
       "A clear understanding of the foundational concepts behind classical machine learning, deep learning, and generative AI is essential for appreciating their respective methodologies and applications. While these domains are interrelated, each is defined by unique principles, data requirements, and operational goals.\n",
       "\n",
       "### Classical Machine Learning\n",
       "\n",
       "Classical machine learning encompasses a suite of statistical algorithms designed primarily for the analysis of structured data—datasets organized in tabular form, with well-defined features and labels. The core premise of classical ML is to learn patterns or relationships from data to make predictions or uncover hidden structures. This is achieved through two primary paradigms: supervised learning, where models are trained on labeled data to predict outcomes (e.g., regression, classification), and unsupervised learning, where models seek to identify clusters or latent structures without explicit labels (e.g., clustering, dimensionality reduction).\n",
       "\n",
       "A defining characteristic of classical ML is the reliance on feature engineering. Here, domain experts manually select, transform, or construct input variables to optimize model performance. This process injects human insight directly into the modeling pipeline, enhancing interpretability but often limiting scalability to complex or high-dimensional data. Classical algorithms such as support vector machines (SVM), decision trees, linear and logistic regression, k-nearest neighbors (KNN), and ensemble methods like random forests and gradient boosting remain foundational in business, healthcare, and finance due to their transparency and computational efficiency [1][2].\n",
       "\n",
       "### Deep Learning\n",
       "\n",
       "Deep learning, a transformative subset of machine learning, leverages artificial neural networks with multiple layers—hence the term \"deep\"—to learn directly from raw, often unstructured, data. Unlike classical ML, deep learning models are capable of automatic feature extraction, identifying hierarchical representations of data without explicit human intervention. This enables these models to excel in domains characterized by high-dimensional, complex, and unstructured data, such as images, audio, and natural language text.\n",
       "\n",
       "Key architectures within deep learning include convolutional neural networks (CNNs) for spatial data (e.g., images), recurrent neural networks (RNNs) and their variants (LSTMs, GRUs) for sequential data (e.g., speech, time series), and transformers for tasks requiring long-range context and parallel processing (e.g., language modeling, translation). Deep learning's capacity to scale with data and computational resources has driven breakthroughs in perception, automation, and natural language understanding, albeit at the cost of interpretability and resource intensity [3][4].\n",
       "\n",
       "### Generative AI\n",
       "\n",
       "Generative AI represents a specialized domain within artificial intelligence focused on the creation of new, original content. Rather than merely predicting labels or extracting information, generative AI models synthesize novel outputs—text, images, audio, code—by learning the underlying structure and distribution of their training data. This is achieved through advanced generative models such as generative adversarial networks (GANs), variational autoencoders (VAEs), diffusion models, and large language models (LLMs) like GPT.\n",
       "\n",
       "A hallmark of generative AI is its prompt-based interaction, where users provide instructions or context and the model generates relevant content in response. Applications span text and image synthesis, code generation, creative design, and more. Generative AI systems are notable for their adaptability, often allowing fine-tuning for domain-specific tasks and enabling the automation of creative and professional content generation [5][6].\n",
       "\n",
       "### Comparative Overview\n",
       "\n",
       "To crystallize the distinctions among these paradigms, the following table summarizes key aspects:\n",
       "\n",
       "| Aspect                | Classical ML          | Deep Learning                | Generative AI                  |\n",
       "|-----------------------|----------------------|------------------------------|-------------------------------|\n",
       "| Data type             | Structured           | Unstructured (and structured)| Unstructured (mostly)         |\n",
       "| Feature Engineering   | Manual               | Automatic (representation)   | Automatic (representation)    |\n",
       "| Model Complexity      | Lower                | High (many layers)           | Very high (large models)      |\n",
       "| Output                | Predictions/Labels   | Predictions/Labels           | New content/data              |\n",
       "| Example Algorithms    | SVM, Decision Trees  | CNN, RNN, Transformers       | GANs, VAEs, LLMs              |\n",
       "\n",
       "While deep learning and generative AI share a foundation in neural networks and automated representation learning, generative AI distinguishes itself through its creative capacity, producing original content beyond traditional prediction tasks. Classical machine learning, meanwhile, remains a mainstay for structured data analysis, prized for its interpretability and efficiency [1][3][5].\n",
       "\n",
       "## Methodologies and Architectures\n",
       "\n",
       "The methodologies and architectural choices underlying classical machine learning, deep learning, and generative AI reflect the increasing complexity and ambition of modern AI systems. Each paradigm is optimized for particular data types, computational constraints, and application domains, with trade-offs in interpretability, scalability, and generative capacity.\n",
       "\n",
       "### Classical Machine Learning Methodologies and Architectures\n",
       "\n",
       "Classical ML is grounded in a diverse set of algorithmic techniques, each tailored to specific tasks and data structures. Supervised learning algorithms include linear regression (for continuous value prediction), logistic regression (for binary classification), decision trees (for recursive partitioning), SVMs (for optimal class separation), and ensemble methods like random forests and gradient boosting (for improved accuracy and robustness). Unsupervised learning encompasses k-means clustering (for grouping similar data points), principal component analysis (for dimensionality reduction), and hierarchical clustering.\n",
       "\n",
       "A defining methodological feature is the explicit, domain-driven feature engineering process. Practitioners must carefully select and transform input variables to capture relevant patterns, often relying on statistical intuition and domain expertise. Model evaluation employs metrics such as accuracy, precision, recall, and cross-validation to ensure generalizability and guard against overfitting. Classical ML models are typically computationally efficient, interpretable, and well-suited for small to medium-sized structured datasets, but their performance degrades on unstructured or high-dimensional data [2][7].\n",
       "\n",
       "### Deep Learning Architectures and Methodologies\n",
       "\n",
       "Deep learning introduces a paradigm shift by enabling models to learn complex, hierarchical representations directly from raw data. The most prominent architectures include:\n",
       "\n",
       "- **Convolutional Neural Networks (CNNs):** Designed for spatial data, CNNs use convolutional and pooling layers to extract local and global features from images, excelling in image classification, object detection, and segmentation.\n",
       "- **Recurrent Neural Networks (RNNs):** Tailored for sequential data, RNNs (and their variants LSTMs and GRUs) capture temporal dependencies, making them ideal for language modeling, speech recognition, and time-series analysis.\n",
       "- **Transformers:** Revolutionizing natural language processing, transformers employ self-attention mechanisms to model long-range dependencies and enable parallel processing. Architectures like BERT and GPT have set new benchmarks in translation, summarization, and code generation.\n",
       "- **Autoencoders:** Encoder-decoder pairs for unsupervised representation learning, supporting dimensionality reduction and anomaly detection.\n",
       "\n",
       "Deep learning models are data-hungry, requiring large labeled datasets and significant computational resources (often GPUs or TPUs) for training. They excel in extracting features from unstructured data, automating tasks that previously required manual intervention. However, their complexity introduces challenges in interpretability, training stability, and energy consumption [3][4][8].\n",
       "\n",
       "### Generative AI Methodologies and Architectural Innovations\n",
       "\n",
       "Generative AI builds upon deep learning foundations, introducing architectures specifically designed for content creation:\n",
       "\n",
       "- **Generative Adversarial Networks (GANs):** Comprising a generator and discriminator in adversarial training, GANs produce synthetic data that closely matches the distribution of real data, enabling realistic image and data generation.\n",
       "- **Variational Autoencoders (VAEs):** Probabilistic models that encode data into a latent space and decode it to generate new samples, supporting anomaly detection and novel content creation.\n",
       "- **Diffusion Models:** Learn to denoise data progressively, transforming random noise into coherent outputs, achieving high fidelity in synthetic image and audio generation.\n",
       "- **Transformer-based Large Language Models (LLMs):** Models like GPT and BERT, with billions of parameters, generate high-quality text, code, and multimodal content, leveraging self-supervised learning and vast pretraining corpora.\n",
       "\n",
       "Generative AI models often employ self-supervised or unsupervised objectives, reducing the need for labeled data and enabling transfer learning and few-shot adaptation. Recent trends include multimodal architectures capable of integrating text, image, and audio inputs/outputs, and agentic retrieval systems that combine LLMs with search and embedding retrieval for richer, context-aware responses [5][7][9].\n",
       "\n",
       "### Comparative Context: Methodological and Architectural Trade-offs\n",
       "\n",
       "The progression from classical ML to deep learning and generative AI is marked by increasing abstraction in data representation, model complexity, and computational demand. Classical ML is optimal for structured, interpretable, and resource-efficient applications; deep learning unlocks automatic feature discovery for complex, unstructured data; and generative AI pushes the frontier of content creation, requiring even greater resources and raising new challenges in evaluation, bias, and control [2][7][10].\n",
       "\n",
       "## Applications and Use Cases\n",
       "\n",
       "The practical impact of classical machine learning, deep learning, and generative AI is evident across a wide array of industries and domains. Each paradigm addresses distinct challenges, shaped by data structure, interpretability requirements, and the desired outcome—prediction, recognition, or generation.\n",
       "\n",
       "### Classical Machine Learning Applications\n",
       "\n",
       "Classical ML remains indispensable in scenarios involving structured or tabular data and where transparency is paramount. In healthcare, algorithms like SVMs and logistic regression are used for disease diagnosis, risk prediction, and patient stratification, while decision trees and KNN assist in medical image analysis and tumor detection. In finance, linear regression and decision trees underpin credit scoring models, fraud detection, and risk assessment, providing clear justifications for decisions—a necessity in regulated environments. Retail and marketing leverage clustering and regression for customer segmentation, targeted campaigns, and sales forecasting. Manufacturing applies classical ML for predictive maintenance and quality control, using sensor and inspection data to anticipate equipment failures and ensure product standards. Transportation systems utilize KNN for route optimization and regression for traffic forecasting. Text and speech processing applications include spam detection and sentiment analysis, essential for communication moderation and consumer feedback analysis. The interpretability and efficiency of classical ML make it the preferred choice in high-trust, operationally sensitive domains [11][12].\n",
       "\n",
       "### Deep Learning Applications\n",
       "\n",
       "Deep learning has enabled breakthroughs in domains characterized by massive, unstructured datasets and complex, nonlinear relationships. In healthcare, deep learning models analyze imaging data (X-rays, MRIs, CT scans) with accuracy rivaling or surpassing human experts, as demonstrated by DeepMind's AI for eye disease detection. Pharmaceutical research employs deep learning for drug discovery, modeling molecular interactions, and predicting new compounds. Finance benefits from deep learning in fraud detection, algorithmic trading, and advanced credit assessments, ingesting diverse, high-dimensional data. Retail and e-commerce platforms deploy deep networks for real-time recommendations, visual search, and dynamic inventory management. Autonomous vehicles rely on deep learning for perception, object and lane detection, and adaptive traffic forecasting. Manufacturing uses deep models for predictive maintenance and quality assurance via sophisticated visual inspections. Security applications include facial recognition and anomaly detection, enhancing both physical and cyber defenses. The capacity of deep learning to discern intricate patterns underpins advances in voice recognition, natural language processing, and autonomous system control [13][14][15].\n",
       "\n",
       "### Generative AI Applications\n",
       "\n",
       "Generative AI represents the latest leap in AI-driven innovation, characterized by models capable of producing novel content across modalities. As of 2024, adoption has surged in both consumer and enterprise settings, powered by transformer-based architectures like GPT-4, DALL-E, and Midjourney. In content creation and marketing, generative AI automates ideation, drafting, and production of copy, social posts, articles, and video assets, scaling personalization and creativity. Search engines have integrated generative components to facilitate conversational, interactive queries, presenting users with AI-organized, contextually rich results. Software engineering benefits from tools that auto-generate code, conduct real-time debugging, and create technical documentation, boosting developer productivity. Customer service has been transformed by advanced chatbots and virtual assistants, resolving a growing proportion of inquiries and offering 24/7 support. The creative sector leverages generative tools for graphic design, video editing, and music composition, empowering rapid iteration and experimentation. Healthcare applications include generating candidate molecular structures for drug discovery and producing synthetic medical data for improved modeling. Finance utilizes generative AI for scenario analysis, risk management, and compliance report generation. Education and corporate training employ AI-powered personalized tutoring and content creation to enhance engagement and learning outcomes. Analysts estimate that generative AI could add up to $4.4 trillion annually across major business use cases, signaling a profound macroeconomic impact [16][17][18].\n",
       "\n",
       "### Comparative Analysis of Sector-Specific Alignment\n",
       "\n",
       "The alignment of each paradigm with industry needs is shaped by the nature of the data, the requirement for explainability, and the complexity or creativity of the task. Classical ML is ideal for high-trust environments with structured inputs and regulatory demands for transparency. Deep learning opens opportunities in perception, automation, and inference from high-dimensional, complex data. Generative AI bridges prediction and creativity, enabling entirely new products and interactive experiences. Increasingly, hybrid systems and problem-specific tailoring blur the boundaries, offering a spectrum of solutions to match operational constraints, innovation goals, and data realities [12][14][17].\n",
       "\n",
       "## Strengths and Limitations\n",
       "\n",
       "A nuanced understanding of the strengths and limitations of classical machine learning, deep learning, and generative AI is essential for informed model selection, risk management, and responsible deployment.\n",
       "\n",
       "### Classical Machine Learning\n",
       "\n",
       "Classical ML algorithms are celebrated for their interpretability, computational efficiency, and reliability on smaller datasets. Their mathematical transparency allows practitioners to trace and rationalize decision-making, making them suitable for domains where explainability is critical. Fast training times and modest hardware requirements facilitate rapid prototyping and iterative development. However, classical ML struggles with complex or high-dimensional data, especially where relationships are nonlinear or the data is unstructured. Manual feature engineering is often required, necessitating domain expertise and extra development time. Scalability is a challenge for instance-based methods as datasets grow, and models require explicit retraining to adapt to new data distributions [19][20].\n",
       "\n",
       "### Deep Learning\n",
       "\n",
       "Deep learning offers transformative advantages in environments with large volumes of unstructured data. Its ability to learn hierarchical representations from raw data underlies its dominant performance in image recognition, natural language processing, and speech-to-text applications. Model performance often improves with increased data and computational resources, pushing the boundaries of AI capabilities. However, deep learning is resource- and time-intensive, requiring specialized hardware and massive labeled datasets. Interpretability is low, with complex internal representations making it difficult to trace decisions or ensure compliance. Overfitting is a risk if models are not properly regularized, and transfer to new tasks often demands considerable retraining [21][22][23].\n",
       "\n",
       "### Generative AI\n",
       "\n",
       "Generative AI models excel in automatic content creation, fueling innovation in chatbots, content synthesis, simulation, and creative industries. Advances in architectures and pre-training have introduced transfer and few-shot learning, reducing data needs for adaptation. However, generative AI faces critical obstacles. Outputs can perpetuate or amplify biases in training data, raising ethical and fairness concerns. The phenomenon of \"hallucination\"—generating plausible but incorrect outputs—limits reliability in high-stakes contexts. Generative models may struggle with rare, novel, or nuanced situations and pose risks related to data privacy. Resource demands are extreme, with high computational and energy costs. Interpretability and controllability are low, and the ability to synthesize convincing content opens avenues for misuse, necessitating rigorous monitoring and safeguards [24][25][26].\n",
       "\n",
       "### Cross-Cutting Challenges\n",
       "\n",
       "Across all paradigms, challenges persist regarding data quality, model interpretability, and generalization. Biased, incomplete, or noisy datasets can propagate errors and unfairness. As model complexity increases, interpretability decreases, posing compliance hurdles and eroding trust. Generalization—the ability to perform well on unseen data—remains the defining test of robustness, requiring sophisticated validation and ongoing monitoring. The choice of approach hinges on use case specifics, available resources, interpretability requirements, and the nature of the input data [19][21][24].\n",
       "\n",
       "## Historical and Technological Evolution\n",
       "\n",
       "The evolution of artificial intelligence and machine learning is marked by a series of transformative phases, each catalyzed by breakthroughs in theory, methodology, and application. Understanding this trajectory provides critical context for the current state and future direction of AI.\n",
       "\n",
       "### Foundational Decades (1940s–1970s)\n",
       "\n",
       "AI's genesis can be traced to Alan Turing's pioneering work in the 1950s, including the Turing Test, which posed foundational questions about machine intelligence. The Dartmouth Conference in 1956 officially inaugurated the field. Early decades focused on symbolic reasoning, pattern recognition, and computational learning theory. Frank Rosenblatt's 1957 invention of the perceptron—a simple neural network—demonstrated machine learning from data. However, early neural networks were limited to linearly separable problems, leading to a focus on rule-based and expert systems [27][28].\n",
       "\n",
       "### Statistical Machine Learning and Neural Resurgence (1970s–1990s)\n",
       "\n",
       "The 1970s and 1980s saw a shift toward statistical methods, including decision trees and ensemble methodologies. The backpropagation algorithm, popularized in 1986, enabled the training of multi-layer neural networks, reigniting interest in connectionist approaches. The 1990s brought powerful tools like SVMs, random forests, and boosting, which improved predictive performance on structured data, albeit requiring extensive feature engineering [29][30].\n",
       "\n",
       "### Data-Driven Approaches and Practical Applications (2000s)\n",
       "\n",
       "The 2000s witnessed a surge in practical ML applications, propelled by increased computing power and large-scale digital datasets. Techniques such as k-means clustering, principal component analysis, and naive Bayes became standard tools across finance, healthcare, and marketing. Kernel methods and robust ensemble strategies gained traction, while advances in parallel computation and GPU hardware further boosted performance [31].\n",
       "\n",
       "### Deep Learning Revolution (2010s)\n",
       "\n",
       "A crucial inflection point occurred in 2006 with the introduction of unsupervised pre-training for deep architectures. The 2012 victory of AlexNet—a deep CNN—in the ImageNet competition marked the ascendancy of deep learning, showcasing its superiority in image recognition. Deep learning models automated the extraction of hierarchical features from unstructured data, scaling effectively with data and unlocking capabilities in computer vision, speech recognition, and NLP [32][33].\n",
       "\n",
       "### Generative AI and Foundation Models (Late 2010s–Present)\n",
       "\n",
       "The emergence of generative AI marks the latest chapter in AI's evolution. Generative models such as GANs (introduced in 2014), transformers, and LLMs like BERT (2018) and GPT-3 (2020) have become foundational, capable of ingesting massive datasets, understanding context, and producing novel content at superhuman fluency and scale. Foundation models, trained on diverse corpora, serve as general-purpose engines adaptable to myriad tasks. The implementation of agentic retrieval and semantic search in enterprise environments and major search platforms illustrates how generative AI is transforming user experiences and information retrieval [34][35][36].\n",
       "\n",
       "### Broader Impact and Nuances\n",
       "\n",
       "Each technological leap has been enabled by advances in hardware (notably GPUs and distributed cloud infrastructure) and the exponential growth in digital data. Classical ML remains relevant for applications demanding interpretability and efficiency, while deep learning and generative AI dominate tasks involving unstructured or multimodal data. The present era, characterized by generative AI and foundation models, signals unprecedented potential and new challenges as the field continues its rapid trajectory [27][32][34].\n",
       "\n",
       "### Timeline of Major Developments\n",
       "\n",
       "| Year | Milestone                                             |\n",
       "|------|-------------------------------------------------------|\n",
       "| 1950 | Turing Test proposed                                  |\n",
       "| 1957 | Perceptron invented                                   |\n",
       "| 1967 | Nearest Neighbor algorithm introduced                 |\n",
       "| 1986 | Backpropagation popularized                           |\n",
       "| 1995 | Support Vector Machines (SVMs) developed              |\n",
       "| 2006 | Unsupervised pre-training for deep architectures      |\n",
       "| 2012 | AlexNet wins ImageNet (deep learning breakthrough)    |\n",
       "| 2014 | Generative Adversarial Networks (GANs) introduced     |\n",
       "| 2018 | BERT (transformer-based LLM) released                 |\n",
       "| 2020 | GPT-3 (large-scale generative language model) launched|\n",
       "| 2024 | Widespread adoption of generative AI in industry      |\n",
       "\n",
       "## Synthesis and Future Directions\n",
       "\n",
       "The distinctions among classical machine learning, deep learning, and generative AI are both clear and consequential. Classical ML offers interpretability and efficiency for structured data, deep learning unlocks automatic feature discovery and excels in unstructured domains, and generative AI enables unprecedented content creation and automation. Each paradigm is shaped by its methodological foundations, data requirements, and application domains, with strengths and limitations that inform responsible deployment.\n",
       "\n",
       "The historical evolution from rule-based systems to generative models reflects a continual move toward automation, adaptability, and generalization. As AI systems become more autonomous and context-aware, new challenges arise—ranging from ethical risk and bias to interpretability and sustainability. The future of AI will likely be defined by hybrid approaches, integrating the strengths of each paradigm, and by advances in governance, transparency, and human-AI collaboration.\n",
       "\n",
       "In conclusion, a comprehensive understanding of these paradigms is essential for navigating the rapidly evolving AI landscape, enabling informed decision-making, responsible innovation, and the realization of AI's transformative potential across society and industry.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] What is Generative AI? - IBM, https://www.ibm.com/think/topics/generative-ai  \n",
       "[2] AI explained: What is generative AI? | Article | Visma, https://www.visma.com/resources/content/ai-explained-what-is-generative-ai  \n",
       "[3] Deep Learning Definition | DeepAI, https://deepai.org/machine-learning-glossary-and-terms/deep-learning  \n",
       "[4] What Is Deep Learning? - IBM, https://www.ibm.com/think/topics/deep-learning  \n",
       "[5] What Is Generative AI? Definition, Applications, and Impact, https://www.coursera.org/articles/what-is-generative-ai  \n",
       "[6] Generative artificial intelligence - Wikipedia, https://en.wikipedia.org/wiki/Generative_artificial_intelligence  \n",
       "[7] The Evolution of AI Architecture: From Traditional Machine Learning to ..., https://aimresearch.co/generative-ai/the-evolution-of-ai-architecture-from-traditional-machine-learning-to-generative-ai  \n",
       "[8] Transformer (deep learning architecture) - Wikipedia, https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)  \n",
       "[9] Modern AI: GenAI vs Machine Learning vs Deep Learning vs LLMs - Cloud4C, https://www.cloud4c.com/blogs/genai-vs-machine-learning-vs-deep-learning-vs-llms  \n",
       "[10] Generative AI vs Traditional AI - GeeksforGeeks, https://www.geeksforgeeks.org/difference-between-generative-ai-and-traditional-ai/  \n",
       "[11] Top 20 Deep Learning Case Studies [Detailed Analysis] [2025], https://digitaldefynd.com/IQ/deep-learning-case-studies/  \n",
       "[12] 20 Deep Learning Applications in 2024 Across Industries, https://www.pickl.ai/blog/deep-learning-applications/  \n",
       "[13] Top 41 Deep Learning Use Cases & Examples in 2025 - Expertbeacon, https://expertbeacon.com/deep-learning-applications/  \n",
       "[14] Introducing agentic retrieval in Azure AI Search: an automated query ..., https://techcommunity.microsoft.com/blog/azure-ai-services-blog/introducing-agentic-retrieval-in-azure-ai-search/4414677  \n",
       "[15] Google I/O 2024: New generative AI experiences in Search, https://blog.google/products/search/generative-ai-google-search-may-2024/  \n",
       "[16] Generative AI Trends And Use Cases To Follow In 2024 - Forbes, https://www.forbes.com/councils/forbestechcouncil/2024/02/21/generative-ai-trends-and-use-cases-to-follow-in-2024/  \n",
       "[17] Trends defining generative AI in 2024 - Implement, https://implementconsultinggroup.com/article/eight-trends-of-generative-ai-2024  \n",
       "[18] The state of AI in early 2024: Gen AI adoption spikes and starts to ..., https://www.mckinsey.com/~/media/mckinsey/business%20functions/quantumblack/our%20insights/the%20state%20of%20ai/2024/the-state-of-ai-in-early-2024-final.pdf  \n",
       "[19] Challenges in Deep Learning - GeeksforGeeks, https://www.geeksforgeeks.org/challenges-in-deep-learning/  \n",
       "[20] Advantages and Disadvantages of Deep Learning - GeeksforGeeks, https://www.geeksforgeeks.org/advantages-and-disadvantages-of-deep-learning/  \n",
       "[21] Deep learning: systematic review, models, challenges, and research ..., https://link.springer.com/article/10.1007/s00521-023-08957-4  \n",
       "[22] Review of deep learning: concepts, CNN architectures, challenges ..., https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00444-8  \n",
       "[23] A Survey on State-of-the-art Deep Learning Applications and Challenges, https://arxiv.org/abs/2403.17561  \n",
       "[24] Semrush Report: AI Overviews’ Impact on Search in 2025, https://www.semrush.com/blog/semrush-ai-overviews-study/  \n",
       "[25] Agentic Retrieval - Azure AI Search | Microsoft Learn, https://learn.microsoft.com/en-us/azure/search/search-agentic-retrieval-concept  \n",
       "[26] Generative AI vs Traditional AI: Key Differences in ML and DL - K21Academy, https://k21academy.com/ai-ml/deep-learning-ml-generative-ai/  \n",
       "[27] The History of AI: A Timeline of Artificial Intelligence, https://www.coursera.org/articles/history-of-ai  \n",
       "[28] The Evolution of Machine Learning: A Brief History and Timeline, https://machinelearningmodels.org/the-evolution-of-machine-learning-a-brief-history-and-timeline/  \n",
       "[29] AI Timeline: Key Events in Artificial Intelligence from 1950-2025, https://www.theainavigator.com/ai-timeline  \n",
       "[30] Milestones in Machine Learning: Key Moments That Shaped AI as We Know ..., https://discoverwildscience.com/milestones-in-machine-learning-key-moments-that-shaped-ai-as-we-know-it-1-302584/  \n",
       "[31] 10 AI milestones of the last 10 years - Royal Institution, https://www.rigb.org/explore-science/explore/blog/10-ai-milestones-last-10-years  \n",
       "[32] Timeline of machine learning - Wikipedia, https://en.wikipedia.org/wiki/Timeline_of_machine_learning  \n",
       "[33] AI Mode in Google Search: Updates from Google I/O 2025 - The Keyword, https://blog.google/products/search/google-search-ai-mode-update/  \n",
       "[34] Semrush Report: AI Overviews’ Impact on Search in 2025, https://www.semrush.com/blog/semrush-ai-overviews-study/  \n",
       "[35] Introducing agentic retrieval in Azure AI Search: an automated query ..., https://techcommunity.microsoft.com/blog/azure-ai-services-blog/introducing-agentic-retrieval-in-azure-ai-search/4414677  \n",
       "[36] Agentic Retrieval - Azure AI Search | Microsoft Learn, https://learn.microsoft.com/en-us/azure/search/search-agentic-retrieval-concept\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(final_report.research_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson-deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
