{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Projects, and the OpenAI Agents SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "The research workflow is powered by Azure AI Agents, with Semantic Kernel serving as the orchestration framework to coordinate between different specialized agents.\n",
    "\n",
    "All agents are created using Azure AI Projects and are orchestrated through Semantic Kernel to handle various research tasks including web search capabilities and specialized analysis.\n",
    "\n",
    "Let's configure each agent with their specific instructions and capabilities using the Semantic Kernel framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will **create the Azure AI Agents**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common.create_azure_ai_agents import (\n",
    "#     create_bing_search_agent,\n",
    "#     create_research_plan_agent,\n",
    "#     create_summary_agent,\n",
    "#     create_research_report_agent,\n",
    "#     create_peer_review_agent\n",
    "# )\n",
    "\n",
    "# planner_agent = create_research_plan_agent(project_client=project_client)\n",
    "# bing_search_agent = create_bing_search_agent(project_client=project_client)\n",
    "# summary_agent = create_summary_agent(project_client=project_client)\n",
    "# research_agent = create_research_report_agent(project_client=project_client)\n",
    "# peer_review_agent = create_peer_review_agent(project_client=project_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch agents from Ai Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PlannerAgentID\"))\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"BingSearchAgentID\"))\n",
    "summary_agent = project_client.agents.get_agent(agent_id=os.getenv(\"SummaryAgentID\"))\n",
    "research_agent = project_client.agents.get_agent(agent_id=os.getenv(\"ResearchAgentID\"))\n",
    "peer_review_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PeerReviewAgentID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update their system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.update_instructions import (\n",
    "    update_planner_instructions,\n",
    "    update_bing_instructions,\n",
    "    update_summary_instructions,\n",
    "    update_research_instructions,\n",
    "    update_peer_review_instructions\n",
    ")\n",
    "\n",
    "planner_agent = update_planner_instructions(agent=planner_agent)\n",
    "bing_search_agent = update_bing_instructions(agent=bing_search_agent)\n",
    "summary_agent = update_summary_instructions(agent=summary_agent)\n",
    "research_agent = update_research_instructions(agent=research_agent)\n",
    "peer_review_agent = update_peer_review_instructions(agent=peer_review_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Azure AI Agents with Semantic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from semantic_kernel.agents import AzureAIAgent, AzureAIAgentThread\n",
    "\n",
    "# # NOT THE SAME PROJECT CLIENT AS THE ONE USED TO CREATE AGENTS\n",
    "# project_client_sk = AzureAIAgent.create_client(\n",
    "#         credential=DefaultAzureCredential(),\n",
    "#         endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    "#     )\n",
    "\n",
    "# planner_agent = AzureAIAgent(client=project_client_sk, definition=planner_agent)\n",
    "# bing_search_agent = AzureAIAgent(client=project_client_sk, definition=bing_search_agent)\n",
    "# summary_agent = AzureAIAgent(client=project_client_sk, definition=summary_agent)\n",
    "# research_agent = AzureAIAgent(client=project_client_sk, definition=research_agent)\n",
    "# peer_review_agent = AzureAIAgent(client=project_client_sk, definition=peer_review_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Handoffs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from semantic_kernel.agents import OrchestrationHandoffs\n",
    "\n",
    "# handoffs = (\n",
    "#     OrchestrationHandoffs()\n",
    "#     .add(\n",
    "#         source_agent=research_agent.name,\n",
    "#         target_agent=peer_review_agent.name,\n",
    "#         description=\"Transfer to this agent when you've written the research report and need peer review\"\n",
    "#     )\n",
    "#     .add(\n",
    "#         source_agent=peer_review_agent.name,\n",
    "#         target_agent=research_agent.name,\n",
    "#         description=(\n",
    "#             \"Transfer to this agent if the report you've reviewed, doesn't meet the success criteria and needs revision.\"\n",
    "#         )\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"183pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 182.68\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.790802 0.790802) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 1999.03,-227 1999.03,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1090.29,-8C1090.29,-8 1746.54,-8 1746.54,-8 1752.54,-8 1758.54,-14 1758.54,-20 1758.54,-20 1758.54,-203 1758.54,-203 1758.54,-209 1752.54,-215 1746.54,-215 1746.54,-215 1090.29,-215 1090.29,-215 1084.29,-215 1078.29,-209 1078.29,-203 1078.29,-203 1078.29,-20 1078.29,-20 1078.29,-14 1084.29,-8 1090.29,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"1418.42\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.86,-72.6C133.43,-72.24 159.62,-72.4 216.49,-73.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.32,-76.59 226.37,-73.22 216.41,-69.59 216.32,-76.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.46,-71.88C370.78,-71.43 396.13,-71.62 445.49,-72.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.18,-75.92 455.23,-72.59 445.29,-68.92 445.18,-75.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M926.04,-92.25C926.04,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 926.04,-55.75 926.04,-55.75 932.04,-55.75 938.04,-61.75 938.04,-67.75 938.04,-67.75 938.04,-80.25 938.04,-80.25 938.04,-86.25 932.04,-92.25 926.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;summary -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.28,-69C638.59,-68.14 669.02,-68.56 725.16,-70.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.73,-73.76 734.83,-70.57 724.94,-66.76 724.73,-73.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1188.54,-92.25C1188.54,-92.25 1098.29,-92.25 1098.29,-92.25 1092.29,-92.25 1086.29,-86.25 1086.29,-80.25 1086.29,-80.25 1086.29,-67.75 1086.29,-67.75 1086.29,-61.75 1092.29,-55.75 1098.29,-55.75 1098.29,-55.75 1188.54,-55.75 1188.54,-55.75 1194.54,-55.75 1200.54,-61.75 1200.54,-67.75 1200.54,-67.75 1200.54,-80.25 1200.54,-80.25 1200.54,-86.25 1194.54,-92.25 1188.54,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M881.86,-55.34C964.88,-21.4 990.44,-20.14 1081.1,-51.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.86,-54.82 1090.45,-54.83 1082.17,-48.22 1079.86,-54.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"1012.17\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1416.54,-52.25C1416.54,-52.25 1327.04,-52.25 1327.04,-52.25 1321.04,-52.25 1315.04,-46.25 1315.04,-40.25 1315.04,-40.25 1315.04,-27.75 1315.04,-27.75 1315.04,-21.75 1321.04,-15.75 1327.04,-15.75 1327.04,-15.75 1416.54,-15.75 1416.54,-15.75 1422.54,-15.75 1428.54,-21.75 1428.54,-27.75 1428.54,-27.75 1428.54,-40.25 1428.54,-40.25 1428.54,-46.25 1422.54,-52.25 1416.54,-52.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1200.81,-63.21C1253.32,-53.35 1281.27,-48.19 1303.85,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1304.14,-47.88 1313.43,-42.79 1302.99,-40.97 1304.14,-47.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"1257.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1650.69,-105.94C1650.69,-105.94 1584.14,-78.56 1584.14,-78.56 1578.59,-76.28 1578.59,-71.72 1584.14,-69.44 1584.14,-69.44 1650.69,-42.06 1650.69,-42.06 1656.24,-39.78 1667.34,-39.78 1672.89,-42.06 1672.89,-42.06 1739.44,-69.44 1739.44,-69.44 1744.99,-71.72 1744.99,-76.28 1739.44,-78.56 1739.44,-78.56 1672.89,-105.94 1672.89,-105.94 1667.34,-108.22 1656.24,-108.22 1650.69,-105.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1211.83,-72.2C1443.6,-66.13 1499.16,-65.21 1583.06,-69.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1212.08,-68.69 1202.17,-72.45 1212.26,-75.69 1212.08,-68.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.68,-37.82C1526.04,-44.45 1562.55,-47.76 1598.61,-56.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.31,-59.39 1607.86,-58.37 1598.98,-52.59 1597.31,-59.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"1500.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"1925.91\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1748.73,-72.86C1794.97,-72.28 1822.55,-72.05 1845.08,-72.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1844.92,-75.66 1854.95,-72.24 1844.98,-68.66 1844.92,-75.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"1803.67\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x21c52ff7670>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message from agent ResearchPlanAgent generated\n",
      "\n",
      "thread: thread_5b2S0uVuvZDwD8AKu6sYW67w deleted\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import MessageRole\n",
    "from common.data_models import ResearchPlan\n",
    "from common.utils_ai_agents import (\n",
    "    add_user_message_to_thread,\n",
    "    invoke_agent\n",
    ")\n",
    "import json\n",
    "\n",
    "# create a thread and add the user message\n",
    "thread = project_client.agents.threads.create()\n",
    "add_user_message_to_thread(project_client, thread.id, user_query)\n",
    "\n",
    "# invoke the planner agent to create a research plan\n",
    "planner_agent_output, thread = invoke_agent(\n",
    "    project_client=project_client,\n",
    "    thread=thread,\n",
    "    agent=planner_agent\n",
    ")\n",
    "\n",
    "# parse the output to a ResearchPlan object\n",
    "plan_data = json.loads(planner_agent_output)\n",
    "plan = ResearchPlan(**plan_data)\n",
    "\n",
    "# delete the thread\n",
    "project_client.agents.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['definition of classical machine learning',\n",
       " 'what is deep learning in AI',\n",
       " 'generative AI definition and explanation',\n",
       " 'core principles of classical machine learning vs deep learning',\n",
       " 'how does generative AI differ from traditional AI']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message from agent BingSearchAgent generated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message from agent BingSearchAgent generated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message from agent BingSearchAgent generated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message from agent BingSearchAgent generated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message from agent BingSearchAgent generated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics: 100%|██████████| 1/1 [00:42<00:00, 42.40s/it]██| 5/5 [00:42<00:00,  9.07s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.research_tasks[:1], desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, formatted_query)\n",
    "\n",
    "            bing_search_agent_output, thread = invoke_agent(\n",
    "                project_client=project_client,\n",
    "                thread=thread,\n",
    "                agent=bing_search_agent\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 25\n",
      "\n",
      "Actually total search queries: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 1/1 [00:19<00:00, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message from agent SummaryAgent generated\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    all_agent_responses_for_subtopic, unique_citations_for_subtopic = collect_responses_and_citations(subtopic_result)\n",
    "\n",
    "    # --- Summarize the combined agent responses ONCE per subtopic ---\n",
    "    content_to_summarize = \"\\n\\n---\\n\\n\".join(all_agent_responses_for_subtopic)\n",
    "\n",
    "    subtopic_summary = \"No content found to summarize for this subtopic.\" # Default value\n",
    "    if content_to_summarize:\n",
    "        summary_prompt = f\"Summarize the following information related to the subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content_to_summarize}\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, summary_prompt)\n",
    "            # Invoke the summary agent to summarize the content\n",
    "            summary_agent_output, thread = invoke_agent(\n",
    "                project_client=project_client,\n",
    "                thread=thread,\n",
    "                agent=summary_agent\n",
    "            )\n",
    "\n",
    "            # run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=summary_agent.id)\n",
    "            # subtopic_summary = get_last_message_by_role(project_client, thread.id, MessageRole.AGENT)\n",
    "            subtopic_summary = summary_agent_output.strip()  # Ensure we get the text output\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}': {e}\")\n",
    "            subtopic_summary = f\"Error during summarization for subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}'. Details: {e}\"\n",
    "            # Depending on requirements, you might want to raise the exception, log it, or handle it differently\n",
    "\n",
    "    # --- Convert set of tuples back to list of dictionaries (or Citation objects) ---\n",
    "    citations_list = [\n",
    "        {\"title\": title, \"url\": url}\n",
    "        for title, url in unique_citations_for_subtopic\n",
    "    ]\n",
    "\n",
    "    # --- Append the consolidated result ---\n",
    "    mapped_chunks.append({\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"), # Use .get for safety\n",
    "        \"summary\": subtopic_summary,\n",
    "        \"citations\": citations_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_models import ComprehensiveResearchReport, PeerReviewFeedback\n",
    "from common.utils_ai_agents import add_user_message_to_thread\n",
    "\n",
    "def loop_agents(project_client, agent_a, agent_b, initial_input, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Loop between two agents until agent B produces the target output.\n",
    "    \n",
    "    Args:\n",
    "        agent_a: Function that takes input and returns output\n",
    "        agent_b: Function that takes input and returns output\n",
    "        initial_input: Starting input for agent A\n",
    "        max_iterations: Safety limit to prevent infinite loops\n",
    "    \n",
    "    Returns:\n",
    "        The final output from agent B, or None if max iterations reached\n",
    "    \"\"\"\n",
    "\n",
    "    thread = project_client.agents.threads.create()\n",
    "    add_user_message_to_thread(project_client, thread.id, initial_input)\n",
    "\n",
    "    for it in range(max_iterations):        \n",
    "        # Agent A processes the input\n",
    "        a_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_a\n",
    "        )\n",
    "        \n",
    "        # Agent B processes A's output\n",
    "        b_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_b\n",
    "        )\n",
    "\n",
    "        b_output_json = json.loads(b_output)\n",
    "        review = PeerReviewFeedback(**b_output_json)\n",
    "\n",
    "        # Check if B produced the target output\n",
    "        if review.is_satisfactory is not False:\n",
    "            print(f\"Target output reached after {it+1} iterations!\")\n",
    "            report_json = json.loads(a_output)\n",
    "            final_report = ComprehensiveResearchReport(**report_json)\n",
    "\n",
    "            # delete the thread\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            return final_report\n",
    "        \n",
    "        # Use B's output as input for the next iteration\n",
    "        current_input = b_output\n",
    "\n",
    "    print(f\"Max iterations ({max_iterations}) reached without finding target output\") \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "message from agent ResearchReportAgent generated\n",
      "\n",
      "message from agent PeerReviewAgent generated\n",
      "\n",
      "Target output reached after 1 iterations!\n",
      "thread: thread_akup12RtYsMFGnGnu7RnHfaq deleted\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "research_query = (\n",
    "    \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "    \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "    \"a cohesive, academic-style paper:\\n\\n\"\n",
    "    f\"{research_input_prompt}\\n\\n\"\n",
    "    \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    ")\n",
    "\n",
    "# Run the loop\n",
    "final_report = loop_agents(\n",
    "    project_client=project_client,\n",
    "    agent_a=research_agent,\n",
    "    agent_b=peer_review_agent,\n",
    "    initial_input=research_query,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Defining and Differentiating Classical Machine Learning, Deep Learning, and Generative AI: Principles, Methodologies, Applications, Strengths, and Limitations\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Artificial intelligence (AI) has undergone a remarkable evolution over the past several decades, transitioning from rule-based systems to sophisticated paradigms capable of not only analyzing but also generating content. This progression is marked by three major conceptual and technological milestones: classical machine learning, deep learning, and generative AI. Each paradigm is characterized by distinct core principles, methodologies, and application domains, as well as unique strengths and limitations. Understanding these differences is crucial for practitioners, researchers, and decision-makers seeking to harness the power of AI in diverse contexts. This report provides an in-depth, comparative analysis of these three approaches, exploring their definitions, underlying methodologies, real-world applications, and the broader implications of their adoption. The narrative also traces the historical development of these paradigms, elucidating the relationships and transitions that have shaped the current landscape of AI.\n",
       "\n",
       "## Definitions and Core Principles\n",
       "\n",
       "### Classical Machine Learning\n",
       "\n",
       "Classical machine learning refers to a suite of algorithms rooted in statistical and mathematical modeling, designed to identify patterns and relationships within data. These algorithms, such as linear regression, logistic regression, decision trees, support vector machines (SVMs), and k-nearest neighbors (KNN), are most effective when applied to well-structured, tabular datasets where the problem space is clearly defined. The hallmark of classical machine learning is its reliance on manual feature engineering, where human experts extract and select relevant features from raw data to optimize model performance. This approach emphasizes interpretability, allowing practitioners to understand the influence of individual features on model predictions—a critical attribute in domains requiring transparency and regulatory compliance. Classical machine learning models are typically computationally efficient and require relatively modest amounts of data, making them accessible for a wide range of business intelligence and analytical tasks [3].\n",
       "\n",
       "### Deep Learning\n",
       "\n",
       "Deep learning represents a significant advancement within the broader field of machine learning, distinguished by its use of artificial neural networks composed of multiple hidden layers—hence the term \"deep.\" These architectures are inspired by the structure and function of the human brain, enabling the automatic extraction of hierarchical, high-level features from raw, often unstructured data such as images, audio, and text. Deep learning models, including convolutional neural networks (CNNs) for image processing and recurrent neural networks (RNNs) for sequential data, excel at capturing complex, non-linear relationships that are difficult or impossible to model using classical techniques. The end-to-end learning capability of deep learning systems reduces the need for manual feature engineering, streamlining the development process and enabling breakthroughs in fields like computer vision and natural language processing (NLP). However, this increased complexity comes at the cost of reduced interpretability, as deep neural networks often function as \"black boxes\" whose internal decision-making processes are opaque to users [1].\n",
       "\n",
       "### Generative AI\n",
       "\n",
       "Generative AI constitutes the latest paradigm in artificial intelligence, building upon the foundations of deep learning to create new, original content—ranging from text and images to music and code. Unlike classical and deep learning models, which are primarily designed for classification or prediction, generative AI models are capable of synthesizing outputs that are statistically similar to their training data but are not mere replicas. This is achieved through advanced architectures such as generative adversarial networks (GANs) and large language models (LLMs) like GPT, which leverage vast datasets and sophisticated training regimes to internalize complex statistical relationships. Generative AI is distinguished by its creative potential, enabling automation and augmentation of tasks traditionally reserved for human creativity, such as art, design, content creation, and scientific hypothesis generation [1][2][5].\n",
       "\n",
       "### Traditional (Narrow) AI\n",
       "\n",
       "For completeness, it is important to distinguish traditional or \"narrow\" AI from the aforementioned paradigms. Traditional AI systems are characterized by their deterministic, rule-based approaches, tailored to specific, narrowly defined tasks such as playing chess or spam filtering. These systems rely on explicit rules and logic, lacking the capacity for generative or creative output. While invaluable for certain applications, traditional AI is fundamentally different from the data-driven, adaptive models that define modern machine learning and generative AI [6].\n",
       "\n",
       "### Comparative Overview of Core Principles\n",
       "\n",
       "The following table synthesizes the core principles of each paradigm, highlighting their distinguishing features:\n",
       "\n",
       "| Aspect              | Classical ML                               | Deep Learning                                     | Generative AI                                      | Traditional AI               |\n",
       "|---------------------|--------------------------------------------|---------------------------------------------------|----------------------------------------------------|------------------------------|\n",
       "| Feature Engineering | Manual, essential                          | Automatic, hierarchical                           | Automatic, creative pattern synthesis              | Manual or rules-based        |\n",
       "| Data Requirements   | Smaller, structured                        | Large, often unstructured                         | Vast, diverse, unstructured                        | Typically structured         |\n",
       "| Model Complexity    | Lower, often interpretable                  | High, complex, less interpretable                 | Very high, creative, less interpretable            | Low, deterministic           |\n",
       "| Computation         | Less intensive                             | More intensive (heavy use of GPUs/TPUs)           | Highly intensive                                  | Low to moderate              |\n",
       "| Output              | Predictive, analytical                     | Predictive, analytical/recognitive                | Generative, creative                               | Analytical, non-generative   |\n",
       "| Use Cases           | Business analytics, diagnosis, risk scoring| Image recognition, NLP, speech, recommendation    | Text/image/audio synthesis, creative applications   | Chess, spam filtering, etc.  |\n",
       "\n",
       "This comparative overview underscores the progression from manual, structured approaches in classical machine learning to the automated, scalable, and creative capabilities of generative AI.\n",
       "\n",
       "## Methodologies and Algorithms\n",
       "\n",
       "### Classical Machine Learning Methodologies\n",
       "\n",
       "Classical machine learning methodologies are grounded in well-established statistical techniques and mathematical models. The process typically begins with data preprocessing, followed by manual feature engineering, where domain experts identify and extract relevant features from the raw data. Feature selection is a critical step, as the quality and relevance of features directly influence model performance. Once features are defined, various algorithms can be applied, each with its own assumptions and strengths. For example, linear regression is suitable for modeling linear relationships between variables, while logistic regression is used for binary classification tasks. Decision trees provide a hierarchical approach to decision-making, offering interpretability and the ability to handle both categorical and numerical data. Support vector machines (SVMs) are effective for high-dimensional spaces and can model non-linear relationships through kernel functions. K-nearest neighbors (KNN) is a non-parametric method that classifies data points based on their proximity to labeled examples in the feature space. Model evaluation in classical machine learning often relies on metrics such as accuracy, precision, recall, and F1-score, with cross-validation used to assess generalizability [3].\n",
       "\n",
       "### Deep Learning Methodologies\n",
       "\n",
       "Deep learning methodologies diverge significantly from classical approaches, primarily through their use of artificial neural networks with multiple hidden layers. The architecture of a deep neural network is composed of interconnected nodes (neurons) organized into input, hidden, and output layers. Each layer transforms the data through learned weights and activation functions, enabling the network to capture increasingly abstract representations. Convolutional neural networks (CNNs) are specialized for processing grid-like data, such as images, by applying convolutional filters that detect spatial hierarchies of features. Recurrent neural networks (RNNs), and their variants like long short-term memory (LSTM) networks, are designed for sequential data, capturing temporal dependencies in tasks such as language modeling and speech recognition. Training deep learning models requires large datasets and significant computational resources, often leveraging graphics processing units (GPUs) or tensor processing units (TPUs) to accelerate matrix operations. Optimization is typically performed using stochastic gradient descent (SGD) or its variants, with backpropagation employed to update weights based on the error gradient. Regularization techniques, such as dropout and batch normalization, are used to prevent overfitting and improve generalization [1].\n",
       "\n",
       "### Generative AI Methodologies\n",
       "\n",
       "Generative AI methodologies build upon deep learning architectures to enable the creation of new, original content. Two of the most prominent approaches are generative adversarial networks (GANs) and large language models (LLMs). GANs consist of two neural networks—a generator and a discriminator—that are trained simultaneously in a competitive framework. The generator creates synthetic data samples, while the discriminator evaluates their authenticity relative to real data. Through this adversarial process, the generator learns to produce increasingly realistic outputs. GANs have been instrumental in advancing image synthesis, style transfer, and data augmentation. Large language models, such as GPT, employ transformer architectures trained on massive text corpora to predict and generate coherent, contextually relevant text. These models utilize self-attention mechanisms to capture long-range dependencies and semantic relationships within the data. The training process for generative AI models is resource-intensive, often requiring distributed computing and access to vast datasets. Evaluation metrics for generative models include measures of diversity, coherence, and fidelity to the training distribution, as well as human evaluation for subjective quality [1][2][5].\n",
       "\n",
       "### Traditional AI Methodologies\n",
       "\n",
       "Traditional AI methodologies are characterized by rule-based systems and symbolic reasoning. Expert systems, for example, encode domain knowledge in the form of if-then rules, enabling the automation of decision-making in narrowly defined tasks. These systems are deterministic and lack the capacity for learning from data, limiting their adaptability and scalability. While effective for specific applications, traditional AI is increasingly being supplanted by data-driven approaches that offer greater flexibility and performance [6].\n",
       "\n",
       "## Applications and Use Cases\n",
       "\n",
       "### Classical Machine Learning Applications\n",
       "\n",
       "Classical machine learning remains foundational in a wide array of industries and applications, particularly where data is structured and interpretability is paramount. In finance, classical models are used for credit scoring, fraud detection, and risk assessment, leveraging historical transaction data to identify patterns indicative of creditworthiness or anomalous behavior. In healthcare, logistic regression and decision trees support diagnostic decision-making by modeling relationships between patient attributes and outcomes. Marketing and customer analytics benefit from clustering algorithms and classification models to segment customers, predict churn, and optimize targeting strategies. Manufacturing and supply chain management utilize predictive maintenance models to anticipate equipment failures and optimize inventory levels. The transparency and efficiency of classical machine learning make it well-suited for regulatory environments and scenarios where explainability is a legal or ethical requirement [3].\n",
       "\n",
       "### Deep Learning Applications\n",
       "\n",
       "Deep learning has revolutionized fields characterized by large volumes of unstructured data and complex pattern recognition tasks. In computer vision, CNNs power image classification, object detection, facial recognition, and medical imaging diagnostics, achieving performance levels that rival or surpass human experts. Natural language processing (NLP) applications, such as machine translation, sentiment analysis, and question answering, are driven by deep learning models capable of understanding and generating human language. Speech recognition and synthesis systems, enabled by RNNs and transformer models, have transformed human-computer interaction, facilitating voice assistants and automated transcription services. Recommender systems in e-commerce and entertainment platforms leverage deep learning to personalize content and product suggestions based on user behavior and preferences. Autonomous vehicles rely on deep neural networks for perception, decision-making, and control, integrating data from cameras, lidar, and radar sensors to navigate complex environments [1].\n",
       "\n",
       "### Generative AI Applications\n",
       "\n",
       "Generative AI is at the forefront of a new wave of applications that extend beyond analysis and recognition to content creation and augmentation. In the creative industries, generative models are used to produce original artwork, music, and literature, blurring the line between human and machine creativity. Text-to-image synthesis, powered by GANs and diffusion models, enables the generation of realistic images from textual descriptions, opening new possibilities in design, advertising, and entertainment. Large language models are employed for automated content generation, including news articles, marketing copy, and code, as well as for conversational agents and chatbots that engage users in natural dialogue. In scientific research, generative AI assists in hypothesis generation, drug discovery, and the design of novel materials by exploring vast combinatorial spaces. Data augmentation and synthetic data generation support machine learning workflows by providing additional training examples, improving model robustness and generalization [1][2][5].\n",
       "\n",
       "### Traditional AI Applications\n",
       "\n",
       "Traditional AI continues to play a role in domains where tasks are well-defined and rule-based logic suffices. Classic examples include chess-playing programs, expert systems for medical diagnosis, and rule-based spam filters. These systems are valued for their predictability and reliability in constrained environments but lack the adaptability and creative potential of modern machine learning and generative AI approaches [6].\n",
       "\n",
       "### Industry Impact Assessment\n",
       "\n",
       "The following matrix summarizes the impact of each paradigm across key industries:\n",
       "\n",
       "| Industry         | Classical ML | Deep Learning | Generative AI | Traditional AI |\n",
       "|------------------|--------------|---------------|---------------|---------------|\n",
       "| Finance          | High         | Moderate      | Emerging      | Moderate      |\n",
       "| Healthcare       | High         | High          | Emerging      | Moderate      |\n",
       "| Manufacturing    | High         | Moderate      | Low           | Moderate      |\n",
       "| Creative Arts    | Low          | Moderate      | High          | Low           |\n",
       "| Retail/E-Commerce| High         | High          | Moderate      | Moderate      |\n",
       "| Transportation   | Moderate     | High          | Moderate      | Low           |\n",
       "| Scientific R&D   | Moderate     | High          | High          | Low           |\n",
       "\n",
       "This assessment illustrates the varying degrees of adoption and impact, with generative AI rapidly gaining traction in creative and research-intensive sectors.\n",
       "\n",
       "## Strengths and Limitations\n",
       "\n",
       "### Classical Machine Learning: Strengths and Limitations\n",
       "\n",
       "Classical machine learning offers several notable strengths, chief among them being interpretability and efficiency. The transparency of models like linear and logistic regression allows stakeholders to understand and trust the decision-making process, which is essential in regulated industries such as finance and healthcare. The computational efficiency and modest data requirements of classical algorithms make them accessible for organizations with limited resources or smaller datasets. Furthermore, the well-understood statistical foundations of these models facilitate rigorous validation and hypothesis testing. However, classical machine learning is constrained by its reliance on manual feature engineering, which can be labor-intensive and requires domain expertise. These models often struggle with high-dimensional, unstructured data and may be unable to capture complex, non-linear relationships inherent in many real-world problems. As a result, their performance may plateau in scenarios where deep learning excels [3].\n",
       "\n",
       "### Deep Learning: Strengths and Limitations\n",
       "\n",
       "Deep learning's primary strength lies in its ability to automatically learn hierarchical representations from raw data, enabling the modeling of intricate patterns and relationships that elude classical approaches. This capability has driven breakthroughs in image and speech recognition, NLP, and autonomous systems. Deep learning models are highly scalable, capable of leveraging vast datasets and powerful computational infrastructure to achieve state-of-the-art performance. The end-to-end learning paradigm reduces the need for manual feature engineering, accelerating development cycles and enabling rapid experimentation. However, deep learning models are often criticized for their lack of interpretability, as the internal workings of deep neural networks are difficult to elucidate. The resource-intensive nature of training and deploying deep learning models—requiring specialized hardware and large labeled datasets—can be prohibitive for smaller organizations. Additionally, deep learning models are susceptible to overfitting and adversarial attacks, raising concerns about robustness and security [1].\n",
       "\n",
       "### Generative AI: Strengths and Limitations\n",
       "\n",
       "Generative AI's most distinctive strength is its creative capacity, enabling the synthesis of new content that is indistinguishable from human-generated output in many cases. This opens up transformative possibilities in art, design, content creation, and scientific discovery. Generative models can augment data, enhance privacy through synthetic data generation, and automate labor-intensive creative processes. The flexibility and adaptability of generative AI make it a powerful tool for exploring novel solutions and generating hypotheses in research settings. However, the complexity and opacity of generative models exacerbate challenges related to interpretability and trust. The potential for misuse—such as the creation of deepfakes or disinformation—raises ethical and societal concerns. Training generative models is computationally demanding and requires access to large, high-quality datasets, which may not be available in all domains. Evaluating the quality and authenticity of generated content remains an open challenge, often necessitating human judgment [1][2][5].\n",
       "\n",
       "### Traditional AI: Strengths and Limitations\n",
       "\n",
       "Traditional AI systems excel in environments where rules and logic can be explicitly defined, offering predictability and reliability. Their deterministic nature ensures consistent behavior, making them suitable for safety-critical applications. However, traditional AI lacks the flexibility to adapt to new data or tasks, limiting its applicability in dynamic or unstructured environments. The absence of learning capabilities constrains performance and scalability, particularly as the complexity of tasks increases [6].\n",
       "\n",
       "## Historical Development and Relationships\n",
       "\n",
       "### Early Foundations: Traditional AI and Classical Machine Learning\n",
       "\n",
       "The origins of artificial intelligence can be traced to the development of traditional, rule-based systems in the mid-20th century. Early AI research focused on symbolic reasoning, expert systems, and logic-based approaches, exemplified by programs that played chess or solved algebraic equations. These systems were effective for narrowly defined tasks but struggled with ambiguity, uncertainty, and scalability. The advent of classical machine learning in the latter half of the 20th century marked a shift towards data-driven approaches, leveraging statistical models to identify patterns and make predictions based on empirical evidence. The proliferation of digital data and advances in computing power facilitated the adoption of classical machine learning across diverse industries, laying the groundwork for subsequent innovations [3][6].\n",
       "\n",
       "### The Deep Learning Revolution\n",
       "\n",
       "The emergence of deep learning in the early 21st century represented a paradigm shift in AI research and application. Breakthroughs in neural network architectures, coupled with the availability of large datasets and powerful GPUs, enabled the training of deep networks capable of surpassing human performance in tasks such as image recognition and language understanding. The success of deep learning in competitions like ImageNet catalyzed widespread adoption, with researchers and practitioners embracing the potential of automated feature learning and hierarchical representation. Deep learning's impact extended beyond academia, driving innovation in industry and transforming fields ranging from healthcare to autonomous vehicles [1].\n",
       "\n",
       "### The Rise of Generative AI\n",
       "\n",
       "Building on the foundations of deep learning, generative AI has emerged as the latest frontier in artificial intelligence. The development of GANs in 2014 and the subsequent proliferation of large language models have enabled machines to generate content that is increasingly indistinguishable from human output. Generative AI has expanded the scope of AI applications from analysis and recognition to creation and synthesis, with profound implications for creative industries, scientific research, and society at large. The rapid advancement of generative models has sparked debates around ethics, authenticity, and the future of human creativity, underscoring the need for responsible development and deployment [1][2][5].\n",
       "\n",
       "### Interrelationships and Future Directions\n",
       "\n",
       "The progression from traditional AI to classical machine learning, deep learning, and generative AI reflects an ongoing evolution towards greater adaptability, scalability, and creativity. Each paradigm builds upon the strengths and addresses the limitations of its predecessors, contributing to a rich and dynamic AI ecosystem. The integration of classical and deep learning techniques—such as hybrid models that combine interpretability with expressive power—represents a promising avenue for future research. As generative AI continues to mature, questions around transparency, accountability, and societal impact will become increasingly salient, shaping the trajectory of AI development in the years to come.\n",
       "\n",
       "### Timeline of Major Developments\n",
       "\n",
       "| Year | Milestone                                    | Paradigm                |\n",
       "|------|----------------------------------------------|-------------------------|\n",
       "| 1950 | Turing Test proposed                         | Traditional AI          |\n",
       "| 1956 | Dartmouth Conference (birth of AI)           | Traditional AI          |\n",
       "| 1960s| Development of expert systems                | Traditional AI          |\n",
       "| 1970s| Introduction of decision trees, linear models| Classical ML            |\n",
       "| 1986 | Backpropagation for neural networks          | Deep Learning (early)   |\n",
       "| 1990s| SVMs, ensemble methods                       | Classical ML            |\n",
       "| 2012 | AlexNet wins ImageNet                        | Deep Learning           |\n",
       "| 2014 | Introduction of GANs                         | Generative AI           |\n",
       "| 2018 | GPT-2 released                               | Generative AI           |\n",
       "| 2020s| Proliferation of large language models (LLMs)| Generative AI           |\n",
       "\n",
       "This timeline encapsulates the major milestones that have shaped the evolution of AI, illustrating the interplay between foundational research and technological innovation.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The delineation between classical machine learning, deep learning, and generative AI encapsulates the expanding capability and scope of artificial intelligence. Classical machine learning remains indispensable for structured, interpretable, and resource-efficient applications, while deep learning has unlocked new frontiers in pattern recognition and unstructured data analysis. Generative AI, building on deep learning, has introduced a creative dimension to AI, enabling the synthesis of original content and transforming industries ranging from art to scientific research. Each paradigm is characterized by distinct methodologies, strengths, and limitations, and their interrelationships reflect an ongoing evolution towards more adaptive, scalable, and creative AI systems. As the field continues to advance, balancing interpretability, transparency, and ethical considerations will be paramount in harnessing the full potential of AI for societal benefit.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] What is generative AI? - IBM Research, https://research.ibm.com/blog/what-is-generative-AI\n",
       "\n",
       "[2] Definition of Generative AI - Gartner Information Technology Glossary, https://www.gartner.com/en/information-technology/glossary/generative-ai\n",
       "\n",
       "[3] Chapter 4 Classical machine learning - Quantum algorithms, https://quantumalgorithms.org/chap-machinelearning.html\n",
       "\n",
       "[4] AI Mode in Google Search: Updates from Google I/O 2025 - The Keyword, https://blog.google/products/search/google-search-ai-mode-update/\n",
       "\n",
       "[5] What is Generative AI? | Definition, Examples, & Analysis - Perlego, https://www.perlego.com/knowledge/study-guides/what-is-generative-ai/\n",
       "\n",
       "[6] Classic and Adaptive machines - GeeksforGeeks, https://www.geeksforgeeks.org/classic-and-adaptive-machines/\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(final_report.research_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**semantic kernel handoff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import AzureAIAgent, AzureAIAgentThread\n",
    "\n",
    "# NOT THE SAME PROJECT CLIENT AS THE ONE USED TO CREATE AGENTS\n",
    "project_client_sk = AzureAIAgent.create_client(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "research_agent_sk = AzureAIAgent(client=project_client_sk, definition=research_agent)\n",
    "peer_review_agent_sk = AzureAIAgent(client=project_client_sk, definition=peer_review_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from semantic_kernel.agents import RunPollingOptions   # ← this works\n",
    "\n",
    "long_timeout = RunPollingOptions(\n",
    "    run_polling_interval = timedelta(seconds=2),   # how often to check\n",
    "    run_polling_timeout = timedelta(minutes=15),  # how long before we give up\n",
    ")\n",
    "\n",
    "research_agent_sk.polling_options = long_timeout\n",
    "peer_review_agent_sk.polling_options = long_timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import OrchestrationHandoffs\n",
    "\n",
    "handoffs = (\n",
    "    OrchestrationHandoffs()\n",
    "    .add(\n",
    "        source_agent=research_agent_sk.name,\n",
    "        target_agent=peer_review_agent_sk.name,\n",
    "        description=\"ALWAYS transfer to this agent for peer review of the research report you've written.\"\n",
    "    )\n",
    "    .add(\n",
    "        source_agent=peer_review_agent_sk.name,\n",
    "        target_agent=research_agent_sk.name,\n",
    "        description=(\n",
    "            \"Transfer to this agent if the report you've reviewed, doesn't meet the success criteria and needs revision.\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents import ChatMessageContent\n",
    "import datetime\n",
    "import json\n",
    "from common.data_models import ComprehensiveResearchReport, PeerReviewFeedback\n",
    "\n",
    "transcript = []\n",
    "\n",
    "def capture(msg: ChatMessageContent) -> None:\n",
    "\n",
    "    if msg.name == research_agent_sk.name:\n",
    "        report=json.loads(msg.content)['research_report']\n",
    "        content=ComprehensiveResearchReport(**json.loads(msg.content))\n",
    "\n",
    "    if msg.name == peer_review_agent_sk.name:\n",
    "        report=json.loads(msg.content)['provided_report']\n",
    "        content=PeerReviewFeedback(**json.loads(msg.content))\n",
    "\n",
    "    transcript.append({\n",
    "        \"utc\": datetime.datetime.utcnow().isoformat(timespec=\"seconds\"),\n",
    "        \"agent\": msg.name,\n",
    "        \"content\": content,\n",
    "        \"report\": report,\n",
    "        \"full_response\": msg\n",
    "    })\n",
    "\n",
    "    # print(f\"# {msg.name} ({msg.role})\\n\")\n",
    "\n",
    "from semantic_kernel.agents import HandoffOrchestration\n",
    "\n",
    "orchestration = HandoffOrchestration(\n",
    "    description=(\n",
    "        \"This is a handoff orchestration between a research agent and a peer review agent.\\n\"\n",
    "        \"The research agent will receive the initial input and generate a research report.\\n\"\n",
    "        \"The peer review agent will then review the report and provide feedback.\\n\"\n",
    "        \"If the report does not meet the success criteria, it will be sent back to the research agent for revision.\\n\"\n",
    "        \"This process will continue until the report meets the success criteria.\\n\"\n",
    "        \"This is demonstrated by setting the is_satisfactory: boolean to True in the peer review agent output.\\n\"\n",
    "        \"When the report is satisfactory, the peer review agent will return the final report.\"\n",
    "    ),\n",
    "    members=[research_agent_sk, peer_review_agent_sk],   # order matters: first agent gets the initial task\n",
    "    handoffs=handoffs,\n",
    "    agent_response_callback=capture\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "research_task = (\n",
    "    \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "    \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "    \"a cohesive, academic-style paper:\\n\\n\"\n",
    "    f\"{research_input_prompt}\\n\\n\"\n",
    "    \"Two final reminders:\\n\"\n",
    "    \"   - Fon't forget to include the citation list at the end of the report.\\n\"\n",
    "    \"   - Always make a handoff to the peer review agent after generating the report.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio, asyncio\n",
    "nest_asyncio.apply()                    # lets us re-enter the existing loop\n",
    "\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "async def run_loop(task):\n",
    "    runtime = InProcessRuntime()\n",
    "    runtime.start()\n",
    "\n",
    "    result_handle = await orchestration.invoke(\n",
    "        task=task,\n",
    "        runtime=runtime,\n",
    "    )\n",
    "    await result_handle.get()\n",
    "    await runtime.stop_when_idle()\n",
    "\n",
    "await run_loop(research_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(transcript[0]['report']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson-deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
