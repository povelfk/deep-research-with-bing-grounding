{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Agent Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will **create the Azure AI Agents**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common.create_azure_ai_agents import (\n",
    "#     create_bing_search_agent,\n",
    "#     create_research_plan_agent,\n",
    "#     create_summary_agent,\n",
    "#     create_research_report_agent,\n",
    "#     create_peer_review_agent\n",
    "# )\n",
    "\n",
    "# planner_agent = create_research_plan_agent(project_client=project_client)\n",
    "# bing_search_agent = create_bing_search_agent(project_client=project_client)\n",
    "# summary_agent = create_summary_agent(project_client=project_client)\n",
    "# research_agent = create_research_report_agent(project_client=project_client)\n",
    "# peer_review_agent = create_peer_review_agent(project_client=project_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch agents from your AI Foundry Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PlannerAgentID\"))\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"BingSearchAgentID\"))\n",
    "summary_agent = project_client.agents.get_agent(agent_id=os.getenv(\"SummaryAgentID\"))\n",
    "research_agent = project_client.agents.get_agent(agent_id=os.getenv(\"ResearchAgentID\"))\n",
    "peer_review_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PeerReviewAgentID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update their system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.update_instructions import (\n",
    "    update_planner_instructions,\n",
    "    update_bing_instructions,\n",
    "    update_summary_instructions,\n",
    "    update_research_instructions,\n",
    "    update_peer_review_instructions\n",
    ")\n",
    "\n",
    "planner_agent = update_planner_instructions(agent=planner_agent)\n",
    "bing_search_agent = update_bing_instructions(agent=bing_search_agent)\n",
    "summary_agent = update_summary_instructions(agent=summary_agent)\n",
    "research_agent = update_research_instructions(agent=research_agent)\n",
    "peer_review_agent = update_peer_review_instructions(agent=peer_review_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageRole\n",
    "from common.data_models import ResearchPlan\n",
    "from common.utils_ai_agents import (\n",
    "    add_user_message_to_thread,\n",
    "    invoke_agent\n",
    ")\n",
    "import json\n",
    "\n",
    "# create a thread and add the user message\n",
    "thread = project_client.agents.threads.create()\n",
    "add_user_message_to_thread(project_client, thread.id, user_query)\n",
    "\n",
    "# invoke the planner agent to create a research plan\n",
    "planner_agent_output, thread = invoke_agent(\n",
    "    project_client=project_client,\n",
    "    thread=thread,\n",
    "    agent=planner_agent\n",
    ")\n",
    "\n",
    "# parse the output to a ResearchPlan object\n",
    "plan_data = json.loads(planner_agent_output)\n",
    "plan = ResearchPlan(**plan_data)\n",
    "\n",
    "# delete the thread\n",
    "project_client.agents.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "MAX_WORKERS = 8  # adjust for your rate limits\n",
    "\n",
    "def run_one_query(subtopic_name: str, query: str) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "    Research the following query: {query}\n",
    "    This is related to subtopic: {subtopic_name}\n",
    "    Please provide the information and cite your sources using the available tools.\n",
    "    \"\"\"\n",
    "    thread = None\n",
    "    try:\n",
    "        thread = project_client.agents.threads.create()\n",
    "        add_user_message_to_thread(project_client, thread.id, prompt)\n",
    "\n",
    "        _out, _ = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=bing_search_agent\n",
    "        )\n",
    "\n",
    "        text, urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "        return {\"query\": query, \"agent_response\": text, \"results\": urls}\n",
    "    except Exception as e:\n",
    "        return {\"query\": query, \"results\": [], \"error\": str(e)}\n",
    "    finally:\n",
    "        try:\n",
    "            if thread is not None:\n",
    "                project_client.agents.threads.delete(thread_id=thread.id)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Flatten tasks\n",
    "# si: index of the subtopic\n",
    "# qi: index of the query within that subtopic\n",
    "# st.subtopic: the subtopic name\n",
    "# q: the query text\n",
    "\n",
    "tasks: List[Tuple[int, int, str, str]] = [\n",
    "    (si, qi, st.subtopic, q)\n",
    "    for si, st in enumerate(plan.research_tasks)\n",
    "    for qi, q in enumerate(st.search_queries)\n",
    "]\n",
    "\n",
    "# Run in parallel\n",
    "results = defaultdict(dict)  # results[si][qi] = entry\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    fmap = {ex.submit(run_one_query, subtopic_name, query): (si, qi)\n",
    "            for si, qi, subtopic_name, query in tasks}\n",
    "    for fut in tqdm(as_completed(fmap), total=len(fmap), desc=\"Running research queries in parallel\"):\n",
    "        si, qi = fmap[fut]\n",
    "        try:\n",
    "            results[si][qi] = fut.result()\n",
    "        except Exception as e:\n",
    "            results[si][qi] = {\"query\": tasks[si][3], \"results\": [], \"error\": str(e)}\n",
    "\n",
    "# Rebuild in original shape and order\n",
    "search_results: List[Dict[str, Any]] = []\n",
    "for si, st in enumerate(plan.research_tasks):\n",
    "    queries = [results[si].get(qi, {\"query\": q, \"results\": [], \"error\": \"Missing result\"})\n",
    "               for qi, q in enumerate(st.search_queries)]\n",
    "    search_results.append({\"subtopic\": st.subtopic, \"queries\": queries})\n",
    "\n",
    "# Quick status\n",
    "for block in search_results:\n",
    "    ok = sum(1 for q in block[\"queries\"] if \"error\" not in q)\n",
    "    print(f\"{block['subtopic']}: {ok}/{len(block['queries'])} queries succeeded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "MAX_WORKERS_SUMMARY = 5\n",
    "\n",
    "def summarize_one(subtopic_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    all_responses, unique_citations = collect_responses_and_citations(subtopic_result)\n",
    "    content = \"\\n\\n---\\n\\n\".join(all_responses)\n",
    "\n",
    "    summary = \"No content found to summarize for this subtopic.\"\n",
    "    thread = None\n",
    "    if content:\n",
    "        summary_prompt = (\n",
    "            f\"Summarize the following information related to the subtopic \"\n",
    "            f\"'{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content}\"\n",
    "        )\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, summary_prompt)\n",
    "            out, _ = invoke_agent(project_client=project_client, thread=thread, agent=summary_agent)\n",
    "            summary = out.strip()\n",
    "        except Exception as e:\n",
    "            sub = subtopic_result.get('subtopic', 'Unknown Subtopic')\n",
    "            summary = f\"Error during summarization for subtopic '{sub}'. Details: {e}\"\n",
    "        finally:\n",
    "            try:\n",
    "                if thread is not None:\n",
    "                    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    citations_list = [{\"title\": t, \"url\": u} for (t, u) in unique_citations]\n",
    "    return {\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"),\n",
    "        \"summary\": summary,\n",
    "        \"citations\": citations_list,\n",
    "    }\n",
    "\n",
    "# Run all subtopics in parallel and preserve order\n",
    "mapped_chunks: List[Dict[str, Any]] = [None] * len(search_results)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS_SUMMARY) as ex:\n",
    "    fmap = {ex.submit(summarize_one, subtopic_result): i\n",
    "            for i, subtopic_result in enumerate(search_results)}\n",
    "    for fut in tqdm(as_completed(fmap), total=len(fmap), desc=\"Summarizing subtopics in parallel\"):\n",
    "        i = fmap[fut]\n",
    "        try:\n",
    "            mapped_chunks[i] = fut.result()\n",
    "        except Exception as e:\n",
    "            sub = search_results[i].get(\"subtopic\", \"Unknown Subtopic\")\n",
    "            mapped_chunks[i] = {\n",
    "                \"subtopic\": sub,\n",
    "                \"summary\": f\"Error during summarization for subtopic '{sub}'. Details: {e}\",\n",
    "                \"citations\": [],\n",
    "            }\n",
    "\n",
    "# Optional: quick status\n",
    "ok = sum(1 for m in mapped_chunks if m and not m[\"summary\"].startswith(\"Error during summarization\"))\n",
    "print(f\"Summaries completed: {ok}/{len(mapped_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_thread_messages(thread):\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for m in messages:\n",
    "        print(f\"roll: {m.role}\")\n",
    "        print(f\"agent_id: {m.agent_id}\")\n",
    "        print(f\"content: {m.content[0]['text']['value']}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_models import ComprehensiveResearchReport, PeerReviewFeedback\n",
    "from common.utils_ai_agents import add_user_message_to_thread\n",
    "\n",
    "def loop_agents(project_client, agent_a, agent_b, initial_input, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Loop between two agents until agent B produces the target output.\n",
    "    \n",
    "    Args:\n",
    "        agent_a: Function that takes input and returns output\n",
    "        agent_b: Function that takes input and returns output\n",
    "        initial_input: Starting input for agent A\n",
    "        max_iterations: Safety limit to prevent infinite loops\n",
    "    \n",
    "    Returns:\n",
    "        The final output from agent B, or None if max iterations reached\n",
    "    \"\"\"\n",
    "    current_input = initial_input\n",
    "    thread = project_client.agents.threads.create()\n",
    "    add_user_message_to_thread(project_client, thread.id, current_input)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # Agent A processes the input and produces output\n",
    "        a_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_a\n",
    "        )\n",
    "\n",
    "        handover_message = f\"A research agent has produced a research report. Please review it.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "        \n",
    "        # Agent B reviews the output\n",
    "        b_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_b\n",
    "        )\n",
    "\n",
    "        b_output_json = json.loads(b_output)\n",
    "        review = PeerReviewFeedback(**b_output_json)\n",
    "\n",
    "        # Check if B produced the target output\n",
    "        if review.is_satisfactory is not False:\n",
    "            print(f\"Target output reached after {i+1} iterations!\")\n",
    "            report_json = json.loads(a_output)\n",
    "            final_report = ComprehensiveResearchReport(**report_json)\n",
    "\n",
    "            # delete the thread\n",
    "            # print_thread_messages(thread)\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            return final_report\n",
    "        \n",
    "        # Use B's output as input for the next iteration\n",
    "        current_input = b_output\n",
    "        \n",
    "        handover_message = f\"Peer review agent has provided feedback. Please revise the research report based on the feedback.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "\n",
    "    # delete the thread\n",
    "    # print_thread_messages(thread)\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"Max iterations ({max_iterations}) reached without finding target output\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "research_query = (\n",
    "    \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "    \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "    \"a cohesive, academic-style paper:\\n\\n\"\n",
    "    f\"{research_input_prompt}\\n\\n\"\n",
    "    \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    ")\n",
    "\n",
    "# Run the loop\n",
    "final_report = loop_agents(\n",
    "    project_client=project_client,\n",
    "    agent_a=research_agent,\n",
    "    agent_b=peer_review_agent,\n",
    "    initial_input=research_query,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(final_report.research_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
