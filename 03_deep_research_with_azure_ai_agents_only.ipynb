{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Agent Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Environment Variables\n",
    "\n",
    "This notebook requires the following environment variables in your `.env` file:\n",
    "\n",
    "```bash\n",
    "# Azure AI Projects Configuration\n",
    "PROJECT_ENDPOINT=your_azure_ai_project_endpoint\n",
    "\n",
    "# Pre-created Agent IDs (must be created via common/create_azure_ai_agents.py)\n",
    "PlannerAgentID=your_planner_agent_id\n",
    "BingSearchAgentID=your_bing_search_agent_id\n",
    "SummaryAgentID=your_summary_agent_id\n",
    "ResearchAgentID=your_research_agent_id\n",
    "PeerReviewAgentID=your_peer_review_agent_id\n",
    "```\n",
    "\n",
    "**Note:** This notebook uses **pure Azure AI Agents** - all agents must be pre-created in Azure AI Foundry. Unlike notebooks 01 and 02, no agents are created inline. Run the agent creation cells below (commented out) once to create your agents, then use their IDs in subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Azure AI Agents (One-time Setup)\n",
    "\n",
    "The following cell will **create all Azure AI Agents** required for this workflow. You only need to run this cell **once** to create the agents, then save their IDs to your `.env` file.\n",
    "\n",
    "After creating the agents, uncomment the fetch agents cell below and comment out this creation cell for subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common.create_azure_ai_agents import (\n",
    "#     create_bing_search_agent,\n",
    "#     create_research_plan_agent,\n",
    "#     create_summary_agent,\n",
    "#     create_research_report_agent,\n",
    "#     create_peer_review_agent\n",
    "# )\n",
    "\n",
    "# planner_agent = create_research_plan_agent(project_client=project_client)\n",
    "# bing_search_agent = create_bing_search_agent(project_client=project_client)\n",
    "# summary_agent = create_summary_agent(project_client=project_client)\n",
    "# research_agent = create_research_report_agent(project_client=project_client)\n",
    "# peer_review_agent = create_peer_review_agent(project_client=project_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Agents from Azure AI Foundry\n",
    "\n",
    "Once you've created your agents (using the cell above), use this cell to retrieve them by their IDs from your `.env` file. This is the standard approach for working with pre-created Azure AI Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PlannerAgentID\"))\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"BingSearchAgentID\"))\n",
    "summary_agent = project_client.agents.get_agent(agent_id=os.getenv(\"SummaryAgentID\"))\n",
    "research_agent = project_client.agents.get_agent(agent_id=os.getenv(\"ResearchAgentID\"))\n",
    "peer_review_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PeerReviewAgentID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Agent Instructions\n",
    "\n",
    "This cell updates the system instructions for all agents with current date awareness and any refined prompts. Run this cell each time you want to ensure agents have the latest instructions, especially for date-sensitive queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.update_instructions import (\n",
    "    update_planner_instructions,\n",
    "    update_bing_instructions,\n",
    "    update_summary_instructions,\n",
    "    update_research_instructions,\n",
    "    update_peer_review_instructions\n",
    ")\n",
    "\n",
    "planner_agent = update_planner_instructions(agent=planner_agent)\n",
    "bing_search_agent = update_bing_instructions(agent=bing_search_agent)\n",
    "summary_agent = update_summary_instructions(agent=summary_agent)\n",
    "research_agent = update_research_instructions(agent=research_agent)\n",
    "peer_review_agent = update_peer_review_instructions(agent=peer_review_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.2 (20251019.1705)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"183pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 183.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.790802 0.790802) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 1999.03,-227 1999.03,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1090.29,-8C1090.29,-8 1746.54,-8 1746.54,-8 1752.54,-8 1758.54,-14 1758.54,-20 1758.54,-20 1758.54,-203 1758.54,-203 1758.54,-209 1752.54,-215 1746.54,-215 1746.54,-215 1090.29,-215 1090.29,-215 1084.29,-215 1078.29,-209 1078.29,-203 1078.29,-203 1078.29,-20 1078.29,-20 1078.29,-14 1084.29,-8 1090.29,-8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1418.42\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.86,-72.6C133.43,-72.24 159.62,-72.4 216.49,-73.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.32,-76.59 226.37,-73.22 216.41,-69.59 216.32,-76.59\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.46,-71.88C370.78,-71.43 396.13,-71.62 445.49,-72.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.18,-75.92 455.23,-72.59 445.29,-68.92 445.18,-75.92\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M926.04,-92.25C926.04,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 926.04,-55.75 926.04,-55.75 932.04,-55.75 938.04,-61.75 938.04,-67.75 938.04,-67.75 938.04,-80.25 938.04,-80.25 938.04,-86.25 932.04,-92.25 926.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"837.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"837.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;summary -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.28,-69C638.59,-68.14 669.02,-68.56 725.16,-70.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.73,-73.76 734.83,-70.57 724.94,-66.76 724.73,-73.76\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1188.54,-92.25C1188.54,-92.25 1098.29,-92.25 1098.29,-92.25 1092.29,-92.25 1086.29,-86.25 1086.29,-80.25 1086.29,-80.25 1086.29,-67.75 1086.29,-67.75 1086.29,-61.75 1092.29,-55.75 1098.29,-55.75 1098.29,-55.75 1188.54,-55.75 1188.54,-55.75 1194.54,-55.75 1200.54,-61.75 1200.54,-67.75 1200.54,-67.75 1200.54,-80.25 1200.54,-80.25 1200.54,-86.25 1194.54,-92.25 1188.54,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1143.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1143.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M881.86,-55.34C964.88,-21.4 990.44,-20.14 1081.1,-51.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.86,-54.82 1090.45,-54.83 1082.17,-48.22 1079.86,-54.82\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1012.17\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1416.54,-52.25C1416.54,-52.25 1327.04,-52.25 1327.04,-52.25 1321.04,-52.25 1315.04,-46.25 1315.04,-40.25 1315.04,-40.25 1315.04,-27.75 1315.04,-27.75 1315.04,-21.75 1321.04,-15.75 1327.04,-15.75 1327.04,-15.75 1416.54,-15.75 1416.54,-15.75 1422.54,-15.75 1428.54,-21.75 1428.54,-27.75 1428.54,-27.75 1428.54,-40.25 1428.54,-40.25 1428.54,-46.25 1422.54,-52.25 1416.54,-52.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1200.81,-63.21C1253.32,-53.35 1281.27,-48.19 1303.85,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1304.14,-47.88 1313.43,-42.79 1302.99,-40.97 1304.14,-47.88\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1257.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1650.69,-105.94C1650.69,-105.94 1584.14,-78.56 1584.14,-78.56 1578.59,-76.28 1578.59,-71.72 1584.14,-69.44 1584.14,-69.44 1650.69,-42.06 1650.69,-42.06 1656.24,-39.78 1667.34,-39.78 1672.89,-42.06 1672.89,-42.06 1739.44,-69.44 1739.44,-69.44 1744.99,-71.72 1744.99,-76.28 1739.44,-78.56 1739.44,-78.56 1672.89,-105.94 1672.89,-105.94 1667.34,-108.22 1656.24,-108.22 1650.69,-105.94\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1661.79\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1661.79\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1211.83,-72.2C1443.6,-66.13 1499.16,-65.21 1583.06,-69.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1212.08,-68.69 1202.17,-72.45 1212.26,-75.69 1212.08,-68.69\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.68,-37.82C1526.04,-44.45 1562.55,-47.76 1598.61,-56.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.31,-59.39 1607.86,-58.37 1598.98,-52.59 1597.31,-59.39\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1500.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"1925.91\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1925.91\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1925.91\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1748.73,-72.86C1794.97,-72.28 1822.55,-72.05 1845.08,-72.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1844.92,-75.66 1854.95,-72.24 1844.98,-68.66 1844.92,-75.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1803.67\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x218599531d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageRole\n",
    "from common.data_models import ResearchPlan\n",
    "from common.utils_ai_agents import (\n",
    "    add_user_message_to_thread,\n",
    "    invoke_agent\n",
    ")\n",
    "import json\n",
    "\n",
    "# create a thread and add the user message\n",
    "thread = project_client.agents.threads.create()\n",
    "add_user_message_to_thread(project_client, thread.id, user_query)\n",
    "\n",
    "# invoke the planner agent to create a research plan\n",
    "planner_agent_output, thread = invoke_agent(\n",
    "    project_client=project_client,\n",
    "    thread=thread,\n",
    "    agent=planner_agent\n",
    ")\n",
    "\n",
    "# parse the output to a ResearchPlan object\n",
    "plan_data = json.loads(planner_agent_output)\n",
    "plan = ResearchPlan(**plan_data)\n",
    "\n",
    "# delete the thread\n",
    "project_client.agents.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['core algorithms in classical machine learning',\n",
       " 'principles and applications of classical machine learning']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running research queries in parallel: 100%|██████████| 6/6 [00:21<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core principles and techniques of classical machine learning: 2/2 queries succeeded\n",
      "Fundamental concepts and architectures in deep learning: 2/2 queries succeeded\n",
      "Overview and distinguishing features of generative AI: 2/2 queries succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "MAX_WORKERS = 8  # adjust for your rate limits\n",
    "\n",
    "def run_one_query(subtopic_name: str, query: str) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "    Research the following query: {query}\n",
    "    This is related to subtopic: {subtopic_name}\n",
    "    Please provide the information and cite your sources using the available tools.\n",
    "    \"\"\"\n",
    "    thread = None\n",
    "    try:\n",
    "        thread = project_client.agents.threads.create()\n",
    "        add_user_message_to_thread(project_client, thread.id, prompt)\n",
    "\n",
    "        _out, _ = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=bing_search_agent\n",
    "        )\n",
    "\n",
    "        text, urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "        return {\"query\": query, \"agent_response\": text, \"results\": urls}\n",
    "    except Exception as e:\n",
    "        return {\"query\": query, \"results\": [], \"error\": str(e)}\n",
    "    finally:\n",
    "        try:\n",
    "            if thread is not None:\n",
    "                project_client.agents.threads.delete(thread_id=thread.id)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Flatten tasks\n",
    "# si: index of the subtopic\n",
    "# qi: index of the query within that subtopic\n",
    "# st.subtopic: the subtopic name\n",
    "# q: the query text\n",
    "\n",
    "tasks: List[Tuple[int, int, str, str]] = [\n",
    "    (si, qi, st.subtopic, q)\n",
    "    for si, st in enumerate(plan.research_tasks)\n",
    "    for qi, q in enumerate(st.search_queries)\n",
    "]\n",
    "\n",
    "# Run in parallel\n",
    "results = defaultdict(dict)  # results[si][qi] = entry\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    fmap = {ex.submit(run_one_query, subtopic_name, query): (si, qi)\n",
    "            for si, qi, subtopic_name, query in tasks}\n",
    "    for fut in tqdm(as_completed(fmap), total=len(fmap), desc=\"Running research queries in parallel\"):\n",
    "        si, qi = fmap[fut]\n",
    "        try:\n",
    "            results[si][qi] = fut.result()\n",
    "        except Exception as e:\n",
    "            results[si][qi] = {\"query\": tasks[si][3], \"results\": [], \"error\": str(e)}\n",
    "\n",
    "# Rebuild in original shape and order\n",
    "search_results: List[Dict[str, Any]] = []\n",
    "for si, st in enumerate(plan.research_tasks):\n",
    "    queries = [results[si].get(qi, {\"query\": q, \"results\": [], \"error\": \"Missing result\"})\n",
    "               for qi, q in enumerate(st.search_queries)]\n",
    "    search_results.append({\"subtopic\": st.subtopic, \"queries\": queries})\n",
    "\n",
    "# Quick status\n",
    "for block in search_results:\n",
    "    ok = sum(1 for q in block[\"queries\"] if \"error\" not in q)\n",
    "    print(f\"{block['subtopic']}: {ok}/{len(block['queries'])} queries succeeded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 6\n",
      "\n",
      "Actually total search queries: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics in parallel: 100%|██████████| 3/3 [00:27<00:00,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries completed: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "MAX_WORKERS_SUMMARY = 5\n",
    "\n",
    "def summarize_one(subtopic_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    all_responses, unique_citations = collect_responses_and_citations(subtopic_result)\n",
    "    content = \"\\n\\n---\\n\\n\".join(all_responses)\n",
    "\n",
    "    summary = \"No content found to summarize for this subtopic.\"\n",
    "    thread = None\n",
    "    if content:\n",
    "        summary_prompt = (\n",
    "            f\"Summarize the following information related to the subtopic \"\n",
    "            f\"'{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content}\"\n",
    "        )\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, summary_prompt)\n",
    "            out, _ = invoke_agent(project_client=project_client, thread=thread, agent=summary_agent)\n",
    "            summary = out.strip()\n",
    "        except Exception as e:\n",
    "            sub = subtopic_result.get('subtopic', 'Unknown Subtopic')\n",
    "            summary = f\"Error during summarization for subtopic '{sub}'. Details: {e}\"\n",
    "        finally:\n",
    "            try:\n",
    "                if thread is not None:\n",
    "                    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    citations_list = [{\"title\": t, \"url\": u} for (t, u) in unique_citations]\n",
    "    return {\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"),\n",
    "        \"summary\": summary,\n",
    "        \"citations\": citations_list,\n",
    "    }\n",
    "\n",
    "# Run all subtopics in parallel and preserve order\n",
    "mapped_chunks: List[Dict[str, Any]] = [None] * len(search_results)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS_SUMMARY) as ex:\n",
    "    fmap = {ex.submit(summarize_one, subtopic_result): i\n",
    "            for i, subtopic_result in enumerate(search_results)}\n",
    "    for fut in tqdm(as_completed(fmap), total=len(fmap), desc=\"Summarizing subtopics in parallel\"):\n",
    "        i = fmap[fut]\n",
    "        try:\n",
    "            mapped_chunks[i] = fut.result()\n",
    "        except Exception as e:\n",
    "            sub = search_results[i].get(\"subtopic\", \"Unknown Subtopic\")\n",
    "            mapped_chunks[i] = {\n",
    "                \"subtopic\": sub,\n",
    "                \"summary\": f\"Error during summarization for subtopic '{sub}'. Details: {e}\",\n",
    "                \"citations\": [],\n",
    "            }\n",
    "\n",
    "# Optional: quick status\n",
    "ok = sum(1 for m in mapped_chunks if m and not m[\"summary\"].startswith(\"Error during summarization\"))\n",
    "print(f\"Summaries completed: {ok}/{len(mapped_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_thread_messages(thread):\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for m in messages:\n",
    "        print(f\"roll: {m.role}\")\n",
    "        print(f\"agent_id: {m.agent_id}\")\n",
    "        print(f\"content: {m.content[0]['text']['value']}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_models import ComprehensiveResearchReport, PeerReviewFeedback\n",
    "from common.utils_ai_agents import add_user_message_to_thread\n",
    "\n",
    "def loop_agents(project_client, agent_a, agent_b, initial_input, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Loop between two agents until agent B produces the target output.\n",
    "    \n",
    "    Args:\n",
    "        agent_a: Function that takes input and returns output\n",
    "        agent_b: Function that takes input and returns output\n",
    "        initial_input: Starting input for agent A\n",
    "        max_iterations: Safety limit to prevent infinite loops\n",
    "    \n",
    "    Returns:\n",
    "        The final output from agent B, or None if max iterations reached\n",
    "    \"\"\"\n",
    "    current_input = initial_input\n",
    "    thread = project_client.agents.threads.create()\n",
    "    add_user_message_to_thread(project_client, thread.id, current_input)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # Agent A processes the input and produces output\n",
    "        a_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_a\n",
    "        )\n",
    "\n",
    "        handover_message = f\"A research agent has produced a research report. Please review it.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "        \n",
    "        # Agent B reviews the output\n",
    "        b_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_b\n",
    "        )\n",
    "\n",
    "        b_output_json = json.loads(b_output)\n",
    "        review = PeerReviewFeedback(**b_output_json)\n",
    "\n",
    "        # Check if B produced the target output\n",
    "        if review.is_satisfactory is not False:\n",
    "            print(f\"Target output reached after {i+1} iterations!\")\n",
    "            report_json = json.loads(a_output)\n",
    "            final_report = ComprehensiveResearchReport(**report_json)\n",
    "\n",
    "            # delete the thread\n",
    "            # print_thread_messages(thread)\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            return final_report\n",
    "        \n",
    "        # Use B's output as input for the next iteration\n",
    "        current_input = b_output\n",
    "        \n",
    "        handover_message = f\"Peer review agent has provided feedback. Please revise the research report based on the feedback.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "\n",
    "    # delete the thread\n",
    "    # print_thread_messages(thread)\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"Max iterations ({max_iterations}) reached without finding target output\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target output reached after 1 iterations!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "research_query = (\n",
    "    \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "    \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "    \"a cohesive, academic-style paper:\\n\\n\"\n",
    "    f\"{research_input_prompt}\\n\\n\"\n",
    "    \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    ")\n",
    "\n",
    "# Run the loop\n",
    "final_report = loop_agents(\n",
    "    project_client=project_client,\n",
    "    agent_a=research_agent,\n",
    "    agent_b=peer_review_agent,\n",
    "    initial_input=research_query,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Comparative Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Principles, Architectures, and Applications\n",
       "\n",
       "## Introduction\n",
       "\n",
       "The rapid evolution of artificial intelligence (AI) has led to the emergence of distinct paradigms that underpin modern data-driven technologies: classical machine learning, deep learning, and generative AI. Each paradigm is characterized by unique theoretical foundations, algorithmic methodologies, and application domains, yet they are interrelated in both historical development and practical utility. This report provides an exceptionally comprehensive, paragraph-focused analysis of these three paradigms, systematically exploring their core principles, technical architectures, and distinguishing features. By synthesizing insights from authoritative sources, the report aims to elucidate the nuanced differences and intersections among classical machine learning, deep learning, and generative AI, while highlighting their respective strengths, limitations, and transformative impacts across industries.\n",
       "\n",
       "## Classical Machine Learning: Principles, Techniques, and Applications\n",
       "\n",
       "Classical machine learning represents the foundational suite of algorithms and statistical methodologies that have shaped the early and ongoing development of artificial intelligence. Rooted in mathematical rigor and statistical pattern recognition, classical machine learning encompasses a diverse array of supervised and unsupervised techniques, each tailored to specific data structures and analytical objectives. The paradigm is defined by its emphasis on interpretability, efficiency, and resource-conscious modeling, making it particularly well-suited for structured/tabular data and domains where transparency is paramount [1][2][3].\n",
       "\n",
       "### Core Principles\n",
       "\n",
       "At its core, classical machine learning is governed by principles that prioritize statistical inference, generalization, and robust model evaluation. Supervised learning, a central pillar, leverages labeled datasets to learn mappings between input features and target outputs. Algorithms such as linear regression and logistic regression exemplify the paradigm's commitment to transparency and mathematical interpretability. Linear regression seeks the optimal linear relationship between independent variables and a continuous outcome, typically using the least squares criterion to minimize prediction error. Logistic regression, designed for classification tasks, models the probability of class membership through a sigmoid function, enabling both binary and multi-class predictions [1][2].\n",
       "\n",
       "Decision trees, another cornerstone, recursively partition data based on feature values, constructing hierarchical branches that culminate in predictive leaf nodes. Ensemble methods, such as random forests and gradient boosting, aggregate multiple decision trees to enhance robustness and predictive accuracy. Support vector machines (SVMs) optimize hyperplanes for class separation, particularly excelling in high-dimensional and non-linearly separable data scenarios through the use of kernel tricks. K-nearest neighbors (KNN) simplifies classification by polling the majority label among the closest data points, while naive Bayes employs probabilistic reasoning under independence assumptions, making it highly effective in text classification and spam filtering [2][3][4][5].\n",
       "\n",
       "Unsupervised learning techniques address the challenge of unlabeled data, seeking latent structure or groupings within datasets. K-means clustering partitions data into coherent clusters based on similarity metrics, while hierarchical clustering constructs nested clusters using agglomerative or divisive approaches. DBSCAN, notable for its density-based formation, uncovers clusters of arbitrary shapes and is resilient to noise—a significant advantage in real-world applications. Principal component analysis (PCA) is pivotal for dimensionality reduction, projecting high-dimensional data onto orthogonal axes that capture maximal variance, thereby simplifying subsequent analysis without sacrificing essential information [1][3][6].\n",
       "\n",
       "### Methodological Rigor and Model Evaluation\n",
       "\n",
       "Classical machine learning is distinguished by its methodological rigor, particularly in mitigating overfitting and ensuring model generalization. Overfitting, the tendency of models to learn idiosyncratic noise rather than genuine signal, is addressed through regularization techniques (L1 and L2), tree pruning, and cross-validation. Regularization penalizes model complexity, promoting parsimonious solutions that generalize well to unseen data. Cross-validation, which partitions data into training and validation sets, provides robust estimates of model performance and guards against overfitting [1][3][7].\n",
       "\n",
       "Model evaluation relies on stringent metrics tailored to the task at hand. For classification, accuracy, precision, recall, and F1-score balance correct identification and coverage, while mean squared error quantifies prediction deviation in regression tasks. Feature engineering—encompassing normalization, encoding categorical data, and scaling numeric features—is a central tenet, often dictating the effectiveness of a chosen algorithm [2][3][4].\n",
       "\n",
       "### Practical Workflow and Domain Applications\n",
       "\n",
       "The classical machine learning workflow is systematic, encompassing data acquisition, exploratory analysis, cleaning, dimensionality reduction, model building and validation, and rigorous evaluation. Domain knowledge and statistical rigor are essential throughout, ensuring that models are both effective and interpretable. Classical algorithms have universal applications, including healthcare (diagnostic support, predictive analytics), finance (fraud detection, risk assessment), manufacturing (predictive maintenance, quality control), and autonomous systems (recommendation engines, sensor analysis) [1][2][3][4][5][6][7][8].\n",
       "\n",
       "In natural language processing, methods like naive Bayes and decision trees power sentiment analysis, spam filtering, and text classification. In image and video recognition, SVMs and ensemble trees facilitate face and object recognition. The paradigm’s advantages are marked by simplicity, transparency, and efficiency, making these approaches especially suitable for environments where model interpretability is critical, structured tabular data dominate, and computational resources are constrained [1][2][3][4][5][6][7][8].\n",
       "\n",
       "### Limitations and Enduring Relevance\n",
       "\n",
       "Despite their strengths, classical machine learning algorithms face limitations. They can struggle with high-dimensional, unstructured data such as raw images or audio, are less scalable for massive datasets compared to deep learning, and lack the capacity for continuous, adaptive learning from ongoing data streams. Nevertheless, classical methods persist as invaluable tools, integral not only for their historical significance but also due to their practical relevance in many domains where deep learning’s complexity and resource demands are unwarranted [1][2][3][4][5][6][7][8].\n",
       "\n",
       "## Deep Learning: Concepts, Architectures, and Transformative Impact\n",
       "\n",
       "Deep learning represents a pivotal specialization within machine learning and artificial intelligence, distinguished by its reliance on multi-layered neural network architectures inspired by the human brain’s interconnected neuronal structure. These artificial neural networks are composed of multiple layers—input, hidden, and output—which together enable the automatic processing and extraction of meaningful patterns from vast and complex datasets, whether images, text, sound, or graph-structured data [9][10][11][12].\n",
       "\n",
       "### Foundational Concepts\n",
       "\n",
       "A foundational concept in deep learning is end-to-end learning, whereby models directly identify relevant features from raw data, obviating the need for labor-intensive manual feature engineering. This capability stems from deep architectures’ inherent skill at representation learning: the hidden layers systematically transform and abstract data, starting from rudimentary patterns (such as edges in images) and progressing to intricate semantic concepts. The universal approximation theorem further underscores the versatility of deep neural networks, indicating that sufficiently large and deep networks can theoretically approximate any function, rendering deep learning applicable to a wide spectrum of tasks [9][10][11][12][13].\n",
       "\n",
       "The iterative process of training through backpropagation is central to deep learning. As data traverses each layer, neurons apply mathematical operations—weighted sums followed by activation functions (such as ReLU, sigmoid, or tanh)—which convert inputs into nonlinear transformations. Errors from the output predictions are propagated back through the network, guiding the adjustment of weights and biases such that the overall accuracy incrementally improves. This self-correcting optimization enables models to generalize effectively as their training data expands [9][10][11][12][13][14].\n",
       "\n",
       "### Architectural Innovations\n",
       "\n",
       "Deep learning’s architectural innovations are tailored to address distinct data modalities and task requirements. Feedforward neural networks (FNNs) offer a straightforward structure for static data and basic classification tasks, with information passing unidirectionally from input to output. Convolutional neural networks (CNNs) are tailored for spatially structured data, notably images. Their convolutional layers scan for localized spatial patterns, enabling the network to learn hierarchical features such as edges, shapes, and objects. CNNs reduce the need for manual feature engineering, exhibit robustness to translations and distortions, and power state-of-the-art visual recognition systems [9][10][11][12][13][14].\n",
       "\n",
       "Recurrent neural networks (RNNs), alongside advanced variants like long short-term memory (LSTM) and gated recurrent unit (GRU), excel in modeling sequential dependencies. By maintaining hidden states that encode information from previous inputs, these architectures effectively handle time-series data, speech, and language, with LSTM and GRU mitigating the vanishing gradient problem to sustain learning over long input sequences [9][10][11][12][13][14].\n",
       "\n",
       "Transformer architectures, leveraging self-attention mechanisms, capture global dependencies within sequences, enabling parallel processing and superior scalability compared to RNNs. Transformers have catalyzed breakthroughs in natural language processing (NLP), underpinning advanced models like GPT and BERT for tasks including translation, summarization, and text generation, and are increasingly applied to vision tasks [11][12][13][14].\n",
       "\n",
       "Generative adversarial networks (GANs) consist of a competitive dual-network setup (generator and discriminator) to synthesize realistic new data samples. GANs are instrumental in data augmentation, image and video synthesis, and creative AI applications, advancing the frontiers of generative modeling. Autoencoders apply an encoder-decoder paradigm to compress and reconstruct data, offering potent tools for dimensionality reduction, unsupervised learning of representations, and anomaly detection, notably in unstructured data domains. Graph neural networks (GNNs) extend deep learning capabilities to graph-structured data, modeling relational information between entities in fields ranging from social networks and chemistry to recommendation systems [9][10][11][12][13][14][15].\n",
       "\n",
       "### Advantages and Domain Impact\n",
       "\n",
       "The key advantages of deep learning include automatic feature extraction, scalability to massive and intricate datasets, adaptability across varied domains, and the capacity to discern hierarchical and sequential patterns that elude traditional algorithms. Deep learning underpins contemporary AI progress in computer vision (image recognition, facial detection), natural language processing (translation, conversational agents), generative AI (content creation), autonomous vehicles, and advanced robotics [9][10][11][12][13][14][15][16].\n",
       "\n",
       "### Limitations and Research Frontiers\n",
       "\n",
       "Despite remarkable advancements, deep learning faces challenges related to interpretability, computational resource demands, and data requirements. Models are often regarded as “black boxes,” with limited transparency into their decision-making processes. Training deep networks requires substantial computational power and large labeled datasets, which can be prohibitive in resource-constrained environments. Ongoing research focuses on refining architectures, improving efficiency and interpretability, and expanding applications to structured and unstructured domains [9][10][11][12][13][14][15][16].\n",
       "\n",
       "## Generative AI: Distinguishing Features, Architectures, and Applications\n",
       "\n",
       "Generative AI is a specialized subset of artificial intelligence focused on creating new, contextually relevant content—such as text, images, audio, or video—by learning patterns from massive datasets. Unlike traditional AI approaches that center on recognizing patterns or classifying existing data, generative AI is engineered to produce original outputs by leveraging deep neural network architectures tuned to learn and replicate complex data distributions. This technology marks a significant evolution in artificial intelligence, as it enables machines not only to understand but also to create, driving transformation in sectors ranging from healthcare to entertainment [17][18][19][20].\n",
       "\n",
       "### Defining Characteristics\n",
       "\n",
       "The most defining feature of generative AI is its goal: the creation of realistic and contextually meaningful content. To achieve this, generative AI employs several advanced techniques. Among the most prominent are generative adversarial networks (GANs), which model a competitive framework between a generator (creating data) and a discriminator (evaluating its realism); variational autoencoders (VAEs), which encode data into a latent space and decode it to generate new samples; and transformer-based models underlying today's large language models (LLMs) such as OpenAI’s GPT series, Google Gemini, or Anthropic Claude. Reinforcement learning with human feedback (RLHF) is also widely used to fine-tune generative models, ensuring outputs are aligned with human preferences and values [17][18][19][20][21].\n",
       "\n",
       "While deep learning is foundational to both traditional and generative AI applications, it broadly focuses on tasks like prediction, classification, and recognition. Techniques in deep learning include convolutional neural networks (CNNs) for image analysis, recurrent neural networks (RNNs), and long short-term memory networks (LSTMs) for sequence modeling. These architectures primarily analyze and predict, whereas generative AI’s defining specialization is the synthesis of new data outputs—from novel images to fully composed essays or music tracks. Accordingly, generative AI distinguishes itself by its content-creation mandate, with differences in techniques (GANs/VAEs/LLMs) and outputs (synthetic content) [17][18][19][20][21][22][23].\n",
       "\n",
       "### Technical Architectures and Model Types\n",
       "\n",
       "Generative AI models are remarkably versatile. Large language models (LLMs) demonstrate the ability to generate human-like text, translate languages, answer questions, and even write code; text-to-image models like DALL·E and Stable Diffusion convert written prompts into visual art; GANs produce photorealistic images and synthetic datasets; and VAEs support tasks such as anomaly detection and image generation by learning latent representations of complex data. Integration with RLHF further enhances the models’ fidelity and alignment with human expectations [17][18][19][20][21][22][23].\n",
       "\n",
       "### Industrial and Societal Impact\n",
       "\n",
       "The industrial and societal impact of generative AI is evident across domains. In healthcare, it accelerates drug discovery, generates synthetic data for research, and develops tools for early disease detection. Finance benefits from advanced fraud detection, risk analysis, and personalized investment strategies. Media and entertainment industries harness generative AI for automated content creation, music composition, video game asset generation, and graphic design. Education sees the rise of intelligent tutoring systems and personalized curriculum development, while cybersecurity deploys synthetic data for robust anomaly detection algorithms [17][18][19][20][21][22][23].\n",
       "\n",
       "### Challenges and Future Directions\n",
       "\n",
       "Generative AI represents a distinct paradigm in artificial intelligence, uniquely characterized by its creative capacity, its reliance on sophisticated deep learning techniques, and its profound versatility. Its ability to synthesize new, contextually resonant content positions it as a transformative force in both technical innovation and practical application, signaling not just an evolution in AI capabilities but a reimagining of what intelligent systems can contribute across virtually every field. Open questions remain around ethical implications, data authenticity, and the management of synthetic outputs, suggesting rich avenues for ongoing research and development [17][18][19][20][21][22][23].\n",
       "\n",
       "## Comparative Synthesis: Principles, Techniques, and Use Cases\n",
       "\n",
       "The following table provides a clear summary of the main differences in principles, techniques, and use cases between classical machine learning, deep learning, and generative AI. This comparative synthesis distills the core insights from the preceding sections, facilitating a holistic understanding of the paradigms’ respective strengths and applications.\n",
       "\n",
       "| Aspect                | Classical Machine Learning                  | Deep Learning                                   | Generative AI                                   |\n",
       "|-----------------------|--------------------------------------------|-------------------------------------------------|-------------------------------------------------|\n",
       "| **Core Principles**   | Statistical inference, interpretability,   | End-to-end learning, representation learning,    | Content synthesis, creative generation,         |\n",
       "|                       | feature engineering, model evaluation      | universal approximation, hierarchical abstraction| learning data distributions                     |\n",
       "| **Techniques**        | Linear/logistic regression, decision trees,| Multi-layer neural networks (CNNs, RNNs,         | GANs, VAEs, LLMs, RLHF, diffusion models        |\n",
       "|                       | SVM, KNN, naive Bayes, ensemble methods,   | transformers, autoencoders, GNNs                |                                                 |\n",
       "|                       | k-means, hierarchical clustering, PCA      |                                                 |                                                 |\n",
       "| **Data Requirements** | Moderate; effective with structured/tabular| Large volumes; excels with unstructured data     | Massive datasets; learns complex distributions  |\n",
       "|                       | data                                      | (images, text, audio)                           |                                                 |\n",
       "| **Feature Engineering**| Essential; manual and domain-driven        | Automatic feature extraction via hidden layers   | Automatic, with focus on latent representations |\n",
       "| **Interpretability**  | High; models often transparent             | Moderate to low; “black box” nature              | Low; outputs may be difficult to explain        |\n",
       "| **Computational Needs**| Low to moderate; efficient on CPUs         | High; requires GPUs/TPUs for training            | Very high; often needs specialized hardware     |\n",
       "| **Primary Outputs**   | Predictions, classifications, clusters     | Predictions, classifications, embeddings         | Synthetic content (text, images, audio, video)  |\n",
       "| **Use Cases**         | Healthcare diagnostics, fraud detection,   | Image recognition, speech processing, NLP,       | Text generation, image synthesis, drug design,  |\n",
       "|                       | recommendation systems, risk assessment    | autonomous vehicles, robotics                    | creative arts, personalized medicine            |\n",
       "| **Limitations**       | Struggles with unstructured/high-dimensional| Requires large data, high computational cost,    | Ethical concerns, data authenticity,            |\n",
       "|                       | data, lacks adaptive learning              | interpretability challenges                      | potential misuse of synthetic outputs           |\n",
       "\n",
       "## Hierarchical Breakdown of Components\n",
       "\n",
       "To further clarify the relationships and distinctions among the three paradigms, the following diagram presents a hierarchical breakdown of their components and elements:\n",
       "\n",
       "```mermaid\n",
       "graph TD\n",
       "    A[Artificial Intelligence]\n",
       "    B[Machine Learning]\n",
       "    C[Classical ML]\n",
       "    D[Deep Learning]\n",
       "    E[Generative AI]\n",
       "    F[Supervised Learning]\n",
       "    G[Unsupervised Learning]\n",
       "    H[Regression]\n",
       "    I[Classification]\n",
       "    J[Clustering]\n",
       "    K[Dimensionality Reduction]\n",
       "    L[Neural Networks]\n",
       "    M[CNNs]\n",
       "    N[RNNs]\n",
       "    O[Transformers]\n",
       "    P[GANs]\n",
       "    Q[VAEs]\n",
       "    R[LLMs]\n",
       "    S[RLHF]\n",
       "    A --> B\n",
       "    B --> C\n",
       "    B --> D\n",
       "    D --> L\n",
       "    L --> M\n",
       "    L --> N\n",
       "    L --> O\n",
       "    D --> E\n",
       "    E --> P\n",
       "    E --> Q\n",
       "    E --> R\n",
       "    E --> S\n",
       "    C --> F\n",
       "    C --> G\n",
       "    F --> H\n",
       "    F --> I\n",
       "    G --> J\n",
       "    G --> K\n",
       "```\n",
       "\n",
       "## Impact Assessment Across Industries\n",
       "\n",
       "The transformative impact of classical machine learning, deep learning, and generative AI is evident across a spectrum of industries. Classical machine learning continues to drive innovation in healthcare diagnostics, financial risk modeling, and recommendation systems, where interpretability and efficiency are paramount. Deep learning has revolutionized computer vision, speech recognition, and autonomous systems, enabling breakthroughs in image classification, natural language understanding, and robotics. Generative AI is reshaping creative industries, healthcare, and education by automating content creation, accelerating drug discovery, and personalizing learning experiences [1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21][22][23].\n",
       "\n",
       "The following matrix summarizes the relative impact of each paradigm across selected industries:\n",
       "\n",
       "| Industry         | Classical ML | Deep Learning | Generative AI |\n",
       "|------------------|-------------|---------------|--------------|\n",
       "| Healthcare       | High        | Moderate      | High         |\n",
       "| Finance          | High        | Moderate      | Moderate     |\n",
       "| Media/Creative   | Moderate    | High          | Very High    |\n",
       "| Education        | Moderate    | High          | High         |\n",
       "| Manufacturing    | High        | Moderate      | Moderate     |\n",
       "| Cybersecurity    | High        | High          | Moderate     |\n",
       "\n",
       "## Timeline of Major Developments\n",
       "\n",
       "A historical perspective underscores the evolution and convergence of these paradigms:\n",
       "\n",
       "| Year | Milestone                                   | Paradigm                  |\n",
       "|------|---------------------------------------------|---------------------------|\n",
       "| 1950s| Early statistical models                    | Classical ML              |\n",
       "| 1980s| Decision trees, SVMs                        | Classical ML              |\n",
       "| 1986 | Backpropagation algorithm                   | Deep Learning             |\n",
       "| 1998 | LeNet (CNN for digit recognition)           | Deep Learning             |\n",
       "| 2006 | Deep belief networks                        | Deep Learning             |\n",
       "| 2012 | AlexNet (ImageNet breakthrough)             | Deep Learning             |\n",
       "| 2014 | GANs introduced                             | Generative AI/Deep Learning|\n",
       "| 2017 | Transformer architecture                    | Deep Learning/Generative AI|\n",
       "| 2020s| Large language models (GPT, BERT, etc.)     | Generative AI             |\n",
       "\n",
       "## Statistical Adoption and Performance Metrics\n",
       "\n",
       "Quantitative data illustrates the adoption rates and performance improvements enabled by each paradigm. Classical machine learning remains widely used in enterprise applications, with surveys indicating that over 60% of organizations deploy classical algorithms for structured data tasks. Deep learning adoption has surged in domains requiring unstructured data analysis, with image recognition models achieving over 95% accuracy on benchmark datasets such as ImageNet. Generative AI models, particularly LLMs, have demonstrated human-level performance in text generation and translation, with adoption rates accelerating in creative and knowledge-intensive industries [1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21][22][23].\n",
       "\n",
       "## Integrated Discussion: Intersections and Future Directions\n",
       "\n",
       "The boundaries between classical machine learning, deep learning, and generative AI are increasingly fluid, with hybrid approaches leveraging the strengths of each paradigm. For example, classical feature engineering is often combined with deep learning architectures to enhance interpretability and performance. Generative AI models, built upon deep learning foundations, are now integrated into classical workflows for data augmentation and synthetic data generation. The convergence of these paradigms is driving the development of more robust, adaptable, and creative AI systems.\n",
       "\n",
       "Looking forward, several trends are poised to shape the future landscape of AI. Research into explainable AI seeks to bridge the interpretability gap in deep learning and generative models, enhancing transparency and trust. Advances in transfer learning and few-shot learning are reducing data requirements, making deep learning more accessible. Ethical considerations, particularly in generative AI, are prompting the development of frameworks for responsible data synthesis and management. The integration of AI paradigms across cloud, edge, and federated environments is expanding the reach and impact of intelligent systems.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "This report has provided a comprehensive, paragraph-focused analysis of classical machine learning, deep learning, and generative AI, highlighting their core principles, technical architectures, and distinguishing features. Through comparative synthesis, hierarchical breakdowns, and impact assessment, the report has elucidated the nuanced differences and intersections among these paradigms. As AI continues to evolve, the interplay between classical methodologies, deep neural architectures, and generative models will drive innovation across industries, shaping the future of intelligent systems and their societal impact.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] Overview of Machine Learning Part 1: Fundamentals and Classic ..., https://www.sciencedirect.com/science/article/pii/S1052514920300629\n",
       "[2] Machine Learning Algorithms - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/machine-learning-algorithms/\n",
       "[3] Classical Machine Learning Principles and Methods, https://link.springer.com/chapter/10.1007/978-1-4842-8692-0_1\n",
       "[4] Core Concepts of Machine Learning (classical) | GRAUSOFT, https://grausoft.net/core-concepts-of-machine-learning/\n",
       "[5] Classic and Adaptive machines - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/classic-and-adaptive-machines/\n",
       "[6] McKlay/classical-machine-learning - GitHub, https://github.com/McKlay/classical-machine-learning\n",
       "[7] Classic machine learning algorithms - hal.science, https://hal.science/hal-03830094v1/file/Chapter%2002%20-%20Final.pdf\n",
       "[8] Classical Machine Learning: Seventy Years of Algorithmic Learning Evolution, https://arxiv.org/pdf/2408.01747v1\n",
       "[9] Deep Learning: Principles, Architectures, and Impact, https://cognixpulse.com/articles/deep-learning-principles-architectures-impact/\n",
       "[10] Introduction to Deep Learning - GeeksforGeeks, https://www.geeksforgeeks.org/deep-learning/introduction-deep-learning/\n",
       "[11] The Complete AI Architecture Landscape - Hugging Face, https://huggingface.co/blog/ProCreations/exploring-architectures-in-ai\n",
       "[12] What is deep learning? - IBM, https://www.ibm.com/think/topics/deep-learning\n",
       "[13] What Is Deep Learning and How Does It Work? - Built In, https://builtin.com/machine-learning/deep-learning\n",
       "[14] Deep Learning: Concepts and Architectures | SpringerLink, https://link.springer.com/book/10.1007/978-3-030-31756-0\n",
       "[15] Deep learning architectures - IBM Developer, https://developer.ibm.com/articles/cc-machine-learning-deep-learning-architectures/\n",
       "[16] What is Deep Learning and how does it work? | We Love Open Source • All ..., https://allthingsopen.org/articles/what-is-deep-learning\n",
       "[17] Comprehensive Review of Generative artificial Intelligence: Mechanisms ..., https://www.sciencedirect.com/science/article/pii/S1877050925017326\n",
       "[18] Generative AI Applications - GeeksforGeeks, https://www.geeksforgeeks.org/artificial-intelligence/generative-ai-applications/\n",
       "[19] Generative AI vs Machine Learning vs Deep Learning Differences - Redblink, https://redblink.com/generative-ai-vs-machine-learning-vs-deep-learning/\n",
       "[20] Deep Learning vs Generative AI: Understanding the Key Differences - eWeek, https://www.eweek.com/artificial-intelligence/generative-ai-vs-deep-learning/\n",
       "[21] Latest Generative AI Models 2025: Trends, Features & Use Cases, https://isoftreview.com/generative-ai-models/\n",
       "[22] Generative AI vs Traditional AI - GeeksforGeeks, https://www.geeksforgeeks.org/blogs/difference-between-generative-ai-and-traditional-ai/\n",
       "[23] Generative artificial intelligence: a systematic review and applications, https://link.springer.com/article/10.1007/s11042-024-20016-1\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(final_report.research_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
