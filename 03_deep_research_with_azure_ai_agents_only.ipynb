{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Agent Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will **create the Azure AI Agents**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common.create_azure_ai_agents import (\n",
    "#     create_bing_search_agent,\n",
    "#     create_research_plan_agent,\n",
    "#     create_summary_agent,\n",
    "#     create_research_report_agent,\n",
    "#     create_peer_review_agent\n",
    "# )\n",
    "\n",
    "# planner_agent = create_research_plan_agent(project_client=project_client)\n",
    "# bing_search_agent = create_bing_search_agent(project_client=project_client)\n",
    "# summary_agent = create_summary_agent(project_client=project_client)\n",
    "# research_agent = create_research_report_agent(project_client=project_client)\n",
    "# peer_review_agent = create_peer_review_agent(project_client=project_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch agents from your AI Foundry Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PlannerAgentID\"))\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"BingSearchAgentID\"))\n",
    "summary_agent = project_client.agents.get_agent(agent_id=os.getenv(\"SummaryAgentID\"))\n",
    "research_agent = project_client.agents.get_agent(agent_id=os.getenv(\"ResearchAgentID\"))\n",
    "peer_review_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PeerReviewAgentID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update their system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.update_instructions import (\n",
    "    update_planner_instructions,\n",
    "    update_bing_instructions,\n",
    "    update_summary_instructions,\n",
    "    update_research_instructions,\n",
    "    update_peer_review_instructions\n",
    ")\n",
    "\n",
    "planner_agent = update_planner_instructions(agent=planner_agent)\n",
    "bing_search_agent = update_bing_instructions(agent=bing_search_agent)\n",
    "summary_agent = update_summary_instructions(agent=summary_agent)\n",
    "research_agent = update_research_instructions(agent=research_agent)\n",
    "peer_review_agent = update_peer_review_instructions(agent=peer_review_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.2 (20251019.1705)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"183pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 183.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.790802 0.790802) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 1999.03,-227 1999.03,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1090.29,-8C1090.29,-8 1746.54,-8 1746.54,-8 1752.54,-8 1758.54,-14 1758.54,-20 1758.54,-20 1758.54,-203 1758.54,-203 1758.54,-209 1752.54,-215 1746.54,-215 1746.54,-215 1090.29,-215 1090.29,-215 1084.29,-215 1078.29,-209 1078.29,-203 1078.29,-203 1078.29,-20 1078.29,-20 1078.29,-14 1084.29,-8 1090.29,-8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1418.42\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.86,-72.6C133.43,-72.24 159.62,-72.4 216.49,-73.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.32,-76.59 226.37,-73.22 216.41,-69.59 216.32,-76.59\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.46,-71.88C370.78,-71.43 396.13,-71.62 445.49,-72.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.18,-75.92 455.23,-72.59 445.29,-68.92 445.18,-75.92\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M926.04,-92.25C926.04,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 926.04,-55.75 926.04,-55.75 932.04,-55.75 938.04,-61.75 938.04,-67.75 938.04,-67.75 938.04,-80.25 938.04,-80.25 938.04,-86.25 932.04,-92.25 926.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"837.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"837.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;summary -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.28,-69C638.59,-68.14 669.02,-68.56 725.16,-70.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.73,-73.76 734.83,-70.57 724.94,-66.76 724.73,-73.76\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1188.54,-92.25C1188.54,-92.25 1098.29,-92.25 1098.29,-92.25 1092.29,-92.25 1086.29,-86.25 1086.29,-80.25 1086.29,-80.25 1086.29,-67.75 1086.29,-67.75 1086.29,-61.75 1092.29,-55.75 1098.29,-55.75 1098.29,-55.75 1188.54,-55.75 1188.54,-55.75 1194.54,-55.75 1200.54,-61.75 1200.54,-67.75 1200.54,-67.75 1200.54,-80.25 1200.54,-80.25 1200.54,-86.25 1194.54,-92.25 1188.54,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1143.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1143.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M881.86,-55.34C964.88,-21.4 990.44,-20.14 1081.1,-51.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.86,-54.82 1090.45,-54.83 1082.17,-48.22 1079.86,-54.82\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1012.17\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1416.54,-52.25C1416.54,-52.25 1327.04,-52.25 1327.04,-52.25 1321.04,-52.25 1315.04,-46.25 1315.04,-40.25 1315.04,-40.25 1315.04,-27.75 1315.04,-27.75 1315.04,-21.75 1321.04,-15.75 1327.04,-15.75 1327.04,-15.75 1416.54,-15.75 1416.54,-15.75 1422.54,-15.75 1428.54,-21.75 1428.54,-27.75 1428.54,-27.75 1428.54,-40.25 1428.54,-40.25 1428.54,-46.25 1422.54,-52.25 1416.54,-52.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1200.81,-63.21C1253.32,-53.35 1281.27,-48.19 1303.85,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1304.14,-47.88 1313.43,-42.79 1302.99,-40.97 1304.14,-47.88\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1257.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1650.69,-105.94C1650.69,-105.94 1584.14,-78.56 1584.14,-78.56 1578.59,-76.28 1578.59,-71.72 1584.14,-69.44 1584.14,-69.44 1650.69,-42.06 1650.69,-42.06 1656.24,-39.78 1667.34,-39.78 1672.89,-42.06 1672.89,-42.06 1739.44,-69.44 1739.44,-69.44 1744.99,-71.72 1744.99,-76.28 1739.44,-78.56 1739.44,-78.56 1672.89,-105.94 1672.89,-105.94 1667.34,-108.22 1656.24,-108.22 1650.69,-105.94\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1661.79\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1661.79\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1211.83,-72.2C1443.6,-66.13 1499.16,-65.21 1583.06,-69.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1212.08,-68.69 1202.17,-72.45 1212.26,-75.69 1212.08,-68.69\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.68,-37.82C1526.04,-44.45 1562.55,-47.76 1598.61,-56.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.31,-59.39 1607.86,-58.37 1598.98,-52.59 1597.31,-59.39\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1500.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"1925.91\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1925.91\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1925.91\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1748.73,-72.86C1794.97,-72.28 1822.55,-72.05 1845.08,-72.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1844.92,-75.66 1854.95,-72.24 1844.98,-68.66 1844.92,-75.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1803.67\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1aa6c501bd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageRole\n",
    "from common.data_models import ResearchPlan\n",
    "from common.utils_ai_agents import (\n",
    "    add_user_message_to_thread,\n",
    "    invoke_agent\n",
    ")\n",
    "import json\n",
    "\n",
    "# create a thread and add the user message\n",
    "thread = project_client.agents.threads.create()\n",
    "add_user_message_to_thread(project_client, thread.id, user_query)\n",
    "\n",
    "# invoke the planner agent to create a research plan\n",
    "planner_agent_output, thread = invoke_agent(\n",
    "    project_client=project_client,\n",
    "    thread=thread,\n",
    "    agent=planner_agent\n",
    ")\n",
    "\n",
    "# parse the output to a ResearchPlan object\n",
    "plan_data = json.loads(planner_agent_output)\n",
    "plan = ResearchPlan(**plan_data)\n",
    "\n",
    "# delete the thread\n",
    "project_client.agents.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classical machine learning vs deep learning vs generative AI methodologies',\n",
       " 'Technical comparison of classical ML, deep learning, and generative AI']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running research queries in parallel: 100%|██████████| 6/6 [00:38<00:00,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methodological and technical distinctions: 2/2 queries succeeded\n",
      "Typical use cases and applications: 2/2 queries succeeded\n",
      "Advantages and limitations of each approach: 2/2 queries succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "MAX_WORKERS = 8  # adjust for your rate limits\n",
    "\n",
    "def run_one_query(subtopic_name: str, query: str) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "    Research the following query: {query}\n",
    "    This is related to subtopic: {subtopic_name}\n",
    "    Please provide the information and cite your sources using the available tools.\n",
    "    \"\"\"\n",
    "    thread = None\n",
    "    try:\n",
    "        thread = project_client.agents.threads.create()\n",
    "        add_user_message_to_thread(project_client, thread.id, prompt)\n",
    "\n",
    "        _out, _ = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=bing_search_agent\n",
    "        )\n",
    "\n",
    "        text, urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "        return {\"query\": query, \"agent_response\": text, \"results\": urls}\n",
    "    except Exception as e:\n",
    "        return {\"query\": query, \"results\": [], \"error\": str(e)}\n",
    "    finally:\n",
    "        try:\n",
    "            if thread is not None:\n",
    "                project_client.agents.threads.delete(thread_id=thread.id)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Flatten tasks\n",
    "# si: index of the subtopic\n",
    "# qi: index of the query within that subtopic\n",
    "# st.subtopic: the subtopic name\n",
    "# q: the query text\n",
    "\n",
    "tasks: List[Tuple[int, int, str, str]] = [\n",
    "    (si, qi, st.subtopic, q)\n",
    "    for si, st in enumerate(plan.research_tasks)\n",
    "    for qi, q in enumerate(st.search_queries)\n",
    "]\n",
    "\n",
    "# Run in parallel\n",
    "results = defaultdict(dict)  # results[si][qi] = entry\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    fmap = {ex.submit(run_one_query, subtopic_name, query): (si, qi)\n",
    "            for si, qi, subtopic_name, query in tasks}\n",
    "    for fut in tqdm(as_completed(fmap), total=len(fmap), desc=\"Running research queries in parallel\"):\n",
    "        si, qi = fmap[fut]\n",
    "        try:\n",
    "            results[si][qi] = fut.result()\n",
    "        except Exception as e:\n",
    "            results[si][qi] = {\"query\": tasks[si][3], \"results\": [], \"error\": str(e)}\n",
    "\n",
    "# Rebuild in original shape and order\n",
    "search_results: List[Dict[str, Any]] = []\n",
    "for si, st in enumerate(plan.research_tasks):\n",
    "    queries = [results[si].get(qi, {\"query\": q, \"results\": [], \"error\": \"Missing result\"})\n",
    "               for qi, q in enumerate(st.search_queries)]\n",
    "    search_results.append({\"subtopic\": st.subtopic, \"queries\": queries})\n",
    "\n",
    "# Quick status\n",
    "for block in search_results:\n",
    "    ok = sum(1 for q in block[\"queries\"] if \"error\" not in q)\n",
    "    print(f\"{block['subtopic']}: {ok}/{len(block['queries'])} queries succeeded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 6\n",
      "\n",
      "Actually total search queries: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics in parallel: 100%|██████████| 3/3 [00:34<00:00, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries completed: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "MAX_WORKERS_SUMMARY = 5\n",
    "\n",
    "def summarize_one(subtopic_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    all_responses, unique_citations = collect_responses_and_citations(subtopic_result)\n",
    "    content = \"\\n\\n---\\n\\n\".join(all_responses)\n",
    "\n",
    "    summary = \"No content found to summarize for this subtopic.\"\n",
    "    thread = None\n",
    "    if content:\n",
    "        summary_prompt = (\n",
    "            f\"Summarize the following information related to the subtopic \"\n",
    "            f\"'{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content}\"\n",
    "        )\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, summary_prompt)\n",
    "            out, _ = invoke_agent(project_client=project_client, thread=thread, agent=summary_agent)\n",
    "            summary = out.strip()\n",
    "        except Exception as e:\n",
    "            sub = subtopic_result.get('subtopic', 'Unknown Subtopic')\n",
    "            summary = f\"Error during summarization for subtopic '{sub}'. Details: {e}\"\n",
    "        finally:\n",
    "            try:\n",
    "                if thread is not None:\n",
    "                    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    citations_list = [{\"title\": t, \"url\": u} for (t, u) in unique_citations]\n",
    "    return {\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"),\n",
    "        \"summary\": summary,\n",
    "        \"citations\": citations_list,\n",
    "    }\n",
    "\n",
    "# Run all subtopics in parallel and preserve order\n",
    "mapped_chunks: List[Dict[str, Any]] = [None] * len(search_results)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS_SUMMARY) as ex:\n",
    "    fmap = {ex.submit(summarize_one, subtopic_result): i\n",
    "            for i, subtopic_result in enumerate(search_results)}\n",
    "    for fut in tqdm(as_completed(fmap), total=len(fmap), desc=\"Summarizing subtopics in parallel\"):\n",
    "        i = fmap[fut]\n",
    "        try:\n",
    "            mapped_chunks[i] = fut.result()\n",
    "        except Exception as e:\n",
    "            sub = search_results[i].get(\"subtopic\", \"Unknown Subtopic\")\n",
    "            mapped_chunks[i] = {\n",
    "                \"subtopic\": sub,\n",
    "                \"summary\": f\"Error during summarization for subtopic '{sub}'. Details: {e}\",\n",
    "                \"citations\": [],\n",
    "            }\n",
    "\n",
    "# Optional: quick status\n",
    "ok = sum(1 for m in mapped_chunks if m and not m[\"summary\"].startswith(\"Error during summarization\"))\n",
    "print(f\"Summaries completed: {ok}/{len(mapped_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_thread_messages(thread):\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for m in messages:\n",
    "        print(f\"roll: {m.role}\")\n",
    "        print(f\"agent_id: {m.agent_id}\")\n",
    "        print(f\"content: {m.content[0]['text']['value']}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_models import ComprehensiveResearchReport, PeerReviewFeedback\n",
    "from common.utils_ai_agents import add_user_message_to_thread\n",
    "\n",
    "def loop_agents(project_client, agent_a, agent_b, initial_input, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Loop between two agents until agent B produces the target output.\n",
    "    \n",
    "    Args:\n",
    "        agent_a: Function that takes input and returns output\n",
    "        agent_b: Function that takes input and returns output\n",
    "        initial_input: Starting input for agent A\n",
    "        max_iterations: Safety limit to prevent infinite loops\n",
    "    \n",
    "    Returns:\n",
    "        The final output from agent B, or None if max iterations reached\n",
    "    \"\"\"\n",
    "    current_input = initial_input\n",
    "    thread = project_client.agents.threads.create()\n",
    "    add_user_message_to_thread(project_client, thread.id, current_input)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # Agent A processes the input and produces output\n",
    "        a_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_a\n",
    "        )\n",
    "\n",
    "        handover_message = f\"A research agent has produced a research report. Please review it.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "        \n",
    "        # Agent B reviews the output\n",
    "        b_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_b\n",
    "        )\n",
    "\n",
    "        b_output_json = json.loads(b_output)\n",
    "        review = PeerReviewFeedback(**b_output_json)\n",
    "\n",
    "        # Check if B produced the target output\n",
    "        if review.is_satisfactory is not False:\n",
    "            print(f\"Target output reached after {i+1} iterations!\")\n",
    "            report_json = json.loads(a_output)\n",
    "            final_report = ComprehensiveResearchReport(**report_json)\n",
    "\n",
    "            # delete the thread\n",
    "            # print_thread_messages(thread)\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            return final_report\n",
    "        \n",
    "        # Use B's output as input for the next iteration\n",
    "        current_input = b_output\n",
    "        \n",
    "        handover_message = f\"Peer review agent has provided feedback. Please revise the research report based on the feedback.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "\n",
    "    # delete the thread\n",
    "    # print_thread_messages(thread)\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"Max iterations ({max_iterations}) reached without finding target output\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target output reached after 1 iterations!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "research_query = (\n",
    "    \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "    \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "    \"a cohesive, academic-style paper:\\n\\n\"\n",
    "    f\"{research_input_prompt}\\n\\n\"\n",
    "    \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    ")\n",
    "\n",
    "# Run the loop\n",
    "final_report = loop_agents(\n",
    "    project_client=project_client,\n",
    "    agent_a=research_agent,\n",
    "    agent_b=peer_review_agent,\n",
    "    initial_input=research_query,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Classical Machine Learning, Deep Learning, and Generative AI: Methodologies, Applications, and Comparative Analysis\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Artificial intelligence (AI) has evolved into a diverse landscape of methodologies, each offering distinct capabilities, strengths, and limitations. Among the most prominent paradigms are classical machine learning (ML), deep learning (DL), and generative AI. These approaches, while interconnected, are differentiated by their underlying technical frameworks, data requirements, and practical applications. Understanding the distinctions between them is essential for practitioners, researchers, and organizations seeking to leverage AI for strategic advantage. This report provides a comprehensive analysis of the methodological and technical differences, typical use cases, and the comparative advantages and limitations of classical ML, deep learning, and generative AI. The discussion is supported by quantitative data, real-world examples, and authoritative sources, culminating in a synthesized perspective on the current and future landscape of intelligent systems.\n",
       "\n",
       "## Methodological and Technical Distinctions\n",
       "\n",
       "The methodological and technical differences between classical machine learning, deep learning, and generative AI are foundational to their respective roles in the AI ecosystem. These paradigms diverge in their approaches to feature engineering, model architecture, data requirements, interpretability, and computational demands.\n",
       "\n",
       "### Classical Machine Learning\n",
       "\n",
       "Classical machine learning is rooted in statistical learning theory and relies on algorithms such as decision trees, support vector machines (SVMs), logistic regression, and k-nearest neighbors. These models are typically applied to structured data—tabular datasets where each feature is well-defined and often numeric or categorical. The hallmark of classical ML is manual feature engineering: domain experts must select, transform, and construct features that capture relevant information from the raw data. This process, while labor-intensive, ensures a high degree of model interpretability, allowing stakeholders to understand how predictions are made and which features are most influential.\n",
       "\n",
       "Model architectures in classical ML are generally simple to moderately complex, with a focus on transparency and computational efficiency. Training and inference are feasible on standard hardware, and models perform well even with limited data. For example, logistic regression can provide interpretable coefficients for binary classification tasks, while decision trees can visually represent decision boundaries and feature importance. The trade-off for this simplicity is a limited capacity to capture highly nonlinear or hierarchical patterns, especially in high-dimensional or unstructured data.\n",
       "\n",
       "### Deep Learning\n",
       "\n",
       "Deep learning represents a paradigm shift in AI, characterized by the use of multi-layered artificial neural networks. These architectures, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), long short-term memory (LSTM) networks, and transformers, are designed to automatically extract features from raw, often unstructured data. Deep learning excels in domains such as computer vision, speech recognition, and natural language processing, where data is abundant and complex.\n",
       "\n",
       "The technical sophistication of deep learning models is reflected in their scalability and capacity to learn hierarchical representations. For instance, CNNs can identify spatial patterns in images, while transformers enable contextual understanding in language tasks. Training deep networks requires vast amounts of labeled data and specialized hardware, such as graphics processing units (GPUs) or tensor processing units (TPUs). The computational demands are significant, with state-of-the-art models comprising millions to billions of parameters.\n",
       "\n",
       "Interpretability is a persistent challenge in deep learning. The internal workings of neural networks are often opaque, making it difficult to trace the rationale behind specific predictions. This \"black box\" nature has implications for trust, accountability, and regulatory compliance, particularly in sensitive domains.\n",
       "\n",
       "### Generative AI\n",
       "\n",
       "Generative AI builds upon deep learning foundations to create models capable of generating novel data and content. Key architectures include generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer-based models such as GPT (Generative Pre-trained Transformer), DALL-E, and Stable Diffusion. These models learn to approximate the distribution of training data, enabling the synthesis of realistic text, images, audio, and other modalities.\n",
       "\n",
       "The scale and complexity of generative AI models are unprecedented. Training requires vast, diverse datasets and distributed computing infrastructure, often spanning multiple data centers. Model sizes have grown exponentially, with recent large language models (LLMs) containing hundreds of billions of parameters. Feature extraction is fully automated, leveraging deep neural networks to capture nuanced representations for creative synthesis.\n",
       "\n",
       "Interpretability is even more challenging in generative AI, as the models not only make predictions but also produce new content. Ensuring transparency, quality control, and ethical use is an ongoing concern. The technical demands—both in terms of data and computation—are among the highest in the AI field, limiting accessibility to organizations with substantial resources.\n",
       "\n",
       "### Comparative Summary Table\n",
       "\n",
       "| Aspect                | Classical ML          | Deep Learning         | Generative AI         |\n",
       "|----------------------|----------------------|----------------------|----------------------|\n",
       "| Feature Engineering  | Manual               | Automated            | Automated            |\n",
       "| Data Requirements    | Low to Moderate      | High                 | Very High            |\n",
       "| Model Complexity     | Simple to Moderate   | Complex              | Highly Complex       |\n",
       "| Interpretability     | High                 | Low                  | Very Low             |\n",
       "| Computational Needs  | Low                  | High                 | Very High            |\n",
       "| Output Type          | Predictions          | Recognition/Analysis | Content Generation   |\n",
       "\n",
       "This table encapsulates the progression from classical ML to generative AI: as models become more capable and versatile, their requirements for data and computation increase, while interpretability diminishes.\n",
       "\n",
       "### Timeline of Major Developments\n",
       "\n",
       "To contextualize these distinctions, a brief timeline highlights key milestones:\n",
       "\n",
       "| Year | Development                                  |\n",
       "|------|----------------------------------------------|\n",
       "| 1957 | Perceptron (early neural network)            |\n",
       "| 1967 | Nearest Neighbor algorithm                   |\n",
       "| 1986 | Backpropagation for neural networks          |\n",
       "| 1995 | Support Vector Machines (SVMs)               |\n",
       "| 1998 | LeNet (CNN for digit recognition)            |\n",
       "| 2006 | Deep Belief Networks (unsupervised DL)       |\n",
       "| 2012 | AlexNet (CNN breakthrough in ImageNet)       |\n",
       "| 2014 | GANs (Generative Adversarial Networks)       |\n",
       "| 2017 | Transformer architecture (NLP revolution)    |\n",
       "| 2020 | GPT-3 (large-scale generative language model)|\n",
       "| 2022 | Stable Diffusion, DALL-E (image generation)  |\n",
       "\n",
       "This progression illustrates the rapid evolution from interpretable, structured models to highly complex, generative systems capable of creative synthesis.\n",
       "\n",
       "### Hierarchical Breakdown of Components\n",
       "\n",
       "A hierarchical view further clarifies the relationships:\n",
       "\n",
       "- **Classical ML**\n",
       "  - Algorithms: Decision Trees, SVMs, Logistic Regression, KNN\n",
       "  - Data: Structured/tabular\n",
       "  - Feature Engineering: Manual\n",
       "  - Output: Predictive analytics, classification, regression\n",
       "- **Deep Learning**\n",
       "  - Architectures: CNNs, RNNs, LSTMs, Transformers\n",
       "  - Data: Unstructured (images, text, audio)\n",
       "  - Feature Engineering: Automated\n",
       "  - Output: Recognition, pattern analysis\n",
       "- **Generative AI**\n",
       "  - Architectures: GANs, VAEs, Transformers (LLMs)\n",
       "  - Data: Large, diverse, often unstructured\n",
       "  - Feature Engineering: Automated\n",
       "  - Output: New content/data generation\n",
       "\n",
       "### Synthesis and Integration\n",
       "\n",
       "The methodological and technical distinctions among classical ML, deep learning, and generative AI are not merely academic—they shape the practical deployment, scalability, and impact of AI solutions. Classical ML remains indispensable for tasks requiring transparency and efficiency, especially in regulated industries. Deep learning unlocks the potential of unstructured data, driving advances in perception and language understanding. Generative AI, built atop deep learning innovations, introduces capabilities for simulation, augmentation, and creative automation, albeit with heightened challenges in interpretability and resource management. The field is dynamic, with ongoing research into hybrid models and interpretability-enhancing techniques aiming to bridge gaps and extend the reach of intelligent systems.\n",
       "\n",
       "## Typical Use Cases and Applications\n",
       "\n",
       "The practical applications of classical machine learning, deep learning, and generative AI are diverse, reflecting their methodological strengths and limitations. Each paradigm is suited to specific data types, problem complexities, and industry requirements.\n",
       "\n",
       "### Classical Machine Learning Applications\n",
       "\n",
       "Classical ML algorithms excel in predictive analytics, classification, anomaly detection, recommendation systems, and segmentation tasks, particularly when working with structured or tabular data. In finance, classical ML models are used for credit scoring, fraud detection, and risk assessment, leveraging interpretable features such as transaction history and demographic data. Healthcare applications include diagnostic support, patient risk stratification, and resource allocation, where model transparency is crucial for clinical decision-making.\n",
       "\n",
       "Retail and marketing sectors utilize classical ML for customer segmentation, demand forecasting, and targeted advertising. For example, logistic regression and decision trees power recommendation engines that suggest products based on user behavior. Telecommunications companies deploy classical ML for churn prediction and network optimization, benefiting from the efficiency and explainability of these models.\n",
       "\n",
       "Anomaly detection is another prominent use case, with classical ML identifying outliers in network traffic, manufacturing processes, or financial transactions. The ability to rapidly train and deploy models on limited data makes classical ML attractive for small and medium-sized enterprises (SMEs) and scenarios where data labeling is costly or impractical.\n",
       "\n",
       "### Deep Learning Applications\n",
       "\n",
       "Deep learning has revolutionized the processing of unstructured data, enabling breakthroughs in image and video analysis, speech recognition, and natural language processing (NLP). In computer vision, CNNs power facial recognition systems, medical imaging diagnostics, and autonomous vehicle perception. For instance, deep learning models have achieved human-level accuracy in detecting diseases from radiological images, supporting early intervention and improved patient outcomes.\n",
       "\n",
       "Speech recognition and audio processing are driven by deep learning architectures such as RNNs and LSTMs. Virtual assistants like Siri and Alexa rely on these models for real-time transcription, translation, and command understanding. In entertainment, deep learning enhances recommendation engines by analyzing user preferences across multimedia content.\n",
       "\n",
       "NLP applications have matured with the advent of transformers, enabling sentiment analysis, machine translation, question answering, and text summarization. Large language models (LLMs) like GPT-3 and BERT have set new benchmarks in contextual understanding and generation. Time-series forecasting, another domain where deep learning excels, supports stock price prediction, weather modeling, and sensor analytics in IoT environments.\n",
       "\n",
       "Industries benefiting from deep learning include healthcare (disease detection, drug discovery), automotive (autonomous driving), security (threat detection), and telecommunications (network optimization). The capacity to handle massive, high-dimensional datasets and learn complex patterns makes deep learning indispensable for tasks where classical ML falls short.\n",
       "\n",
       "### Generative AI Applications\n",
       "\n",
       "Generative AI marks a paradigm shift by enabling the creation of entirely new data—text, code, images, video, music, and synthetic datasets. Models such as GANs, transformers (GPT-4), and diffusion-based architectures (DALL-E) are at the forefront of this revolution. Automated writing, media generation, advanced conversational AI, and personalization engines are among the most impactful use cases.\n",
       "\n",
       "In creative industries, generative AI powers content creation for writing, design, and video production. Marketing and customer service leverage generative models for personalized engagement, product descriptions, and adaptive educational content. Software development benefits from automated code generation, accelerating prototyping and reducing manual effort.\n",
       "\n",
       "Synthetic data generation is transformative for privacy-sensitive sectors and scenarios with limited real data. In healthcare, generative AI models produce synthetic medical images for training diagnostic algorithms, while drug discovery applications generate novel proteins and chemical compounds in silico. The ability to create realistic, diverse data supports research, innovation, and regulatory compliance.\n",
       "\n",
       "Education is another domain where generative AI is making inroads, enabling customized learning materials and interactive tutoring systems. The automation of cognitive tasks—historically considered uniquely human—is reshaping the boundaries of creativity, productivity, and personalization.\n",
       "\n",
       "### Hybrid and Integrated Applications\n",
       "\n",
       "Organizations increasingly combine classical ML, deep learning, and generative AI tools to match technology strengths with specific data types and business requirements. A hybrid pipeline might use classical ML for quick, interpretable predictions on tabular data, deep learning for extracting patterns from image or text components, and generative AI for producing new content or simulating data when needed.\n",
       "\n",
       "This versatility ensures optimal matching of technology to data modality, business urgency, and interpretability requirements. For example, a financial institution may use classical ML for credit scoring, deep learning for fraud detection in transaction logs, and generative AI for synthetic data generation to enhance model robustness. In healthcare, classical ML supports risk stratification, deep learning enables diagnostic imaging, and generative AI augments training datasets.\n",
       "\n",
       "### Impact Assessment Matrix Across Industries\n",
       "\n",
       "| Industry         | Classical ML        | Deep Learning        | Generative AI         |\n",
       "|------------------|--------------------|----------------------|-----------------------|\n",
       "| Finance          | Credit scoring, fraud detection | Algorithmic trading, risk modeling | Synthetic data, personalized reports |\n",
       "| Healthcare       | Diagnostic support, risk stratification | Medical imaging, genomics | Drug discovery, synthetic medical images |\n",
       "| Retail/Marketing | Customer segmentation, demand forecasting | Multimedia recommendations | Automated content, personalized marketing |\n",
       "| Automotive       | Predictive maintenance | Autonomous driving, sensor fusion | Simulation, synthetic environments |\n",
       "| Education        | Student performance prediction | Adaptive learning systems | Custom materials, interactive tutors |\n",
       "| Creative Media   | Audience analytics | Image/video analysis | Automated writing, design, music |\n",
       "\n",
       "This matrix highlights the complementary roles of each paradigm, with generative AI introducing new dimensions of automation and creativity.\n",
       "\n",
       "### Statistical Charts: Adoption Rates and Performance Metrics\n",
       "\n",
       "Recent surveys indicate that over 60% of large enterprises have deployed deep learning models in production, primarily for image and text analysis tasks. Classical ML remains prevalent, with 80% of organizations using it for structured data analytics and decision support. Generative AI adoption is accelerating, with 40% of companies experimenting with content generation and synthetic data, and projections suggest this figure will surpass 60% by 2025 as models become more accessible and versatile [1][2][3].\n",
       "\n",
       "Performance metrics further illustrate the distinctions:\n",
       "\n",
       "- Classical ML models achieve 90-95% accuracy in structured classification tasks with moderate data volumes.\n",
       "- Deep learning models routinely surpass 98% accuracy in image recognition benchmarks (e.g., ImageNet), but require orders of magnitude more data and computational power.\n",
       "- Generative AI models are evaluated on metrics such as perplexity (for text), Fréchet Inception Distance (FID) for images, and human judgment for content quality, with top models producing outputs indistinguishable from human-generated content in blind tests.\n",
       "\n",
       "## Advantages and Limitations of Each Approach\n",
       "\n",
       "A nuanced understanding of the strengths and weaknesses of classical ML, deep learning, and generative AI is essential for informed technology selection and deployment.\n",
       "\n",
       "### Classical Machine Learning: Strengths and Weaknesses\n",
       "\n",
       "Classical ML algorithms are valued for their interpretability, efficiency, and performance on small, structured datasets. Their simplicity facilitates rapid training, deployment, and maintenance, making them suitable for resource-constrained environments and applications where labeled data is scarce. The transparency of classical ML models supports regulatory compliance and stakeholder trust, particularly in industries such as healthcare, finance, and law.\n",
       "\n",
       "However, classical ML is limited by its reliance on manual feature engineering. The process of selecting and transforming features is time-intensive and may overlook subtle patterns or interactions within complex datasets. As data volume and dimensionality increase, classical algorithms struggle to scale, with performance plateauing and robustness diminishing. Unstructured data—images, audio, free text—remains challenging for classical ML, as these models are designed for tabular, structured information.\n",
       "\n",
       "### Deep Learning: Strengths and Weaknesses\n",
       "\n",
       "Deep learning architectures excel at handling unstructured data and automating feature extraction, achieving state-of-the-art results in domains such as computer vision, NLP, and speech recognition. Their scalability allows for improved performance with increased data and computational resources, supporting large-scale, data-rich environments.\n",
       "\n",
       "The power of deep learning comes at a cost. Models are extremely data-intensive, often requiring millions of labeled examples for effective training. Specialized hardware (GPUs, TPUs) and significant energy consumption translate into high financial and environmental costs. The opacity of deep networks undermines trust and accountability, especially in critical applications where explanations are required. Technical pitfalls include susceptibility to overfitting with limited or non-representative data, potential failures in generalization to new scenarios, and vulnerabilities to adversarial inputs that can mislead predictions.\n",
       "\n",
       "### Generative AI: Strengths and Weaknesses\n",
       "\n",
       "Generative AI empowers the creation of novel content—text, images, music—with models such as GPT, DALL-E, and GANs. These algorithms are highly versatile, fueling rapid innovation in creative arts, drug discovery, intelligent chatbots, and automated coding. Generative AI has become increasingly accessible, enabling organizations of various sizes to leverage these capabilities for automation and rapid prototyping.\n",
       "\n",
       "Despite their potential, generative AI models face significant limitations. They can reproduce and amplify biases present in training data, resulting in outputs that are inappropriate, misleading, or harmful. Evaluating generated content is often subjective, posing challenges for authenticity and quality assessment. Resource demands are as high as deep learning, with vast computational power and hardware infrastructure required for training and inference. Ethical and legal concerns—copyright infringement, misinformation, privacy breaches, and deepfakes—are actively debated and subject to emerging regulatory scrutiny. Technical risks include mode collapse in GANs, where the generator fails to produce diverse outputs.\n",
       "\n",
       "### Comparative Analysis\n",
       "\n",
       "No single approach is universally superior; the choice depends on problem context, data characteristics, performance requirements, regulatory constraints, and available resources. Classical ML remains foundational for transparent, structured, and smaller-scale problems. Deep learning is indispensable for tackling complex, unstructured, and large-scale challenges. Generative AI opens frontiers for content automation and creative augmentation but must be managed with attention to ethical integrity and operational feasibility.\n",
       "\n",
       "### Synthesis and Future Directions\n",
       "\n",
       "The field continues to evolve, with ongoing research into interpretable deep learning methods, transfer learning to reduce data requirements, and safeguards for responsible generative AI use. Hybrid models that integrate classical ML, deep learning, and generative AI are increasingly common, enabling organizations to harness the strengths of each paradigm while mitigating their respective limitations. The future of AI lies in the seamless integration of these approaches, supported by advances in hardware, algorithmic transparency, and ethical governance.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The distinctions between classical machine learning, deep learning, and generative AI are foundational to the development and deployment of intelligent systems. Classical ML offers transparency, efficiency, and reliability for structured data analytics, while deep learning unlocks the potential of unstructured data through automated feature extraction and hierarchical modeling. Generative AI builds upon these advances to enable creative synthesis, automation, and personalization, albeit with heightened challenges in interpretability, resource management, and ethical oversight.\n",
       "\n",
       "Organizations and practitioners must carefully consider the methodological and technical requirements, typical use cases, and comparative advantages and limitations of each paradigm. The optimal deployment of AI technologies depends on aligning model capabilities with data characteristics, business objectives, and regulatory constraints. As the field advances, the integration of classical ML, deep learning, and generative AI will drive innovation, productivity, and transformative impact across industries.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] AI vs ML vs DL vs GenAI: Key Differences Explained - FS.com, https://www.fs.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-vs-generative-ai-key-differences-explained-24134.html\n",
       "[2] Comparison Analysis of Traditional Machine Learning and Deep Learning ..., https://arxiv.org/abs/2204.05983\n",
       "[3] Difference Between Machine Learning and Deep Learning, https://www.geeksforgeeks.org/artificial-intelligence/difference-between-machine-learning-and-deep-learning/\n",
       "[4] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks | IBM, https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
       "[5] Machine Learning vs Deep Learning vs Generative AI - What are the ..., https://www.freecodecamp.org/news/machine-learning-vs-deep-learning-vs-generative-ai/\n",
       "[6] AI vs ML vs DL vs Generative AI: A Comparison | Synoptek, https://synoptek.com/insights/it-blogs/data-insights/ai-ml-dl-and-generative-ai-face-off-a-comparative-analysis/\n",
       "[7] Difference between AI, ML, LLM, and generative AI - Toloka, https://toloka.ai/blog/difference-between-ai-ml-llm-and-generative-ai/\n",
       "[8] Deep Learning Examples: Practical Applications in Real Life, https://www.geeksforgeeks.org/deep-learning/deep-learning-examples/\n",
       "[9] Integrating LLMs with Traditional ML: How, Why & Use Cases - Iguazio, https://www.iguazio.com/blog/integrating-llms-with-traditional-ml-how-why-use-cases/\n",
       "[10] 5 Reasons Why Traditional Machine Learning is Alive and Well in the Age ..., https://machinelearningmastery.com/5-reasons-why-traditional-machine-learning-is-alive-and-well-in-the-age-of-llms/\n",
       "[11] Machine Learning Examples, Applications & Use Cases | IBM, https://www.ibm.com/think/topics/machine-learning-use-cases\n",
       "[12] Machine learning and generative AI: What are they good for in 2025?, https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-and-generative-ai-what-are-they-good-for\n",
       "[13] Machine Learning and Deep Learning Applications-A Vision, https://www.sciencedirect.com/science/article/pii/S2666285X21000042\n",
       "[14] 100+ AI Use Cases with Real Life Examples - AIMultiple, https://research.aimultiple.com/ai-usecases/\n",
       "[15] A Comprehensive Analysis of Classical Machine Learning and Modern Deep ..., https://www.ijert.org/research/a-comprehensive-analysis-of-classical-machine-learning-and-modern-deep-learning-methodologies-IJERTV13IS050275.pdf\n",
       "[16] Deep Learning vs. Traditional Machine Learning: Which is Better?, https://www.alliancetek.com/blog/post/2025/03/11/deep-learning-vs-traditional-ml.aspx\n",
       "[17] Classical ML vs Deep Learning 2023 | by Anirban Bose | Medium, https://medium.com/@bosea949/classical-ml-vs-deep-learning-2023-3ade040dfddb\n",
       "[18] A Comprehensive Analysis of Classical Machine Learning and Modern Deep ..., https://www.ijert.org/a-comprehensive-analysis-of-classical-machine-learning-and-modern-deep-learning-methodologies\n",
       "[19] The Computational Limits of Deep Learning, https://cbmm.mit.edu/sites/default/files/documents/2020-07-10%20Thompson-Greenewald-Lee-Manso%20-%20Deep_Learning_Limitations%20-%20Neil%20Thompson.pdf\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(final_report.research_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
