{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Agent Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Environment Variables\n",
    "\n",
    "This notebook requires the following environment variables in your `.env` file:\n",
    "\n",
    "```bash\n",
    "# Azure AI Projects Configuration\n",
    "PROJECT_ENDPOINT=your_azure_ai_project_endpoint\n",
    "\n",
    "# Pre-created Agent IDs (must be created via common/create_azure_ai_agents.py)\n",
    "PlannerAgentID=your_planner_agent_id\n",
    "BingSearchAgentID=your_bing_search_agent_id\n",
    "SummaryAgentID=your_summary_agent_id\n",
    "ResearchAgentID=your_research_agent_id\n",
    "PeerReviewAgentID=your_peer_review_agent_id\n",
    "```\n",
    "\n",
    "**Note:** This notebook uses **pure Azure AI Agents** - all agents must be pre-created in Azure AI Foundry. Unlike notebooks 01 and 02, no agents are created inline. Run the agent creation cells below (commented out) once to create your agents, then use their IDs in subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Azure AI Agents (One-time Setup)\n",
    "\n",
    "The following cell will **create all Azure AI Agents** required for this workflow. You only need to run this cell **once** to create the agents, then save their IDs to your `.env` file.\n",
    "\n",
    "After creating the agents, uncomment the fetch agents cell below and comment out this creation cell for subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common.create_azure_ai_agents import (\n",
    "#     create_bing_search_agent,\n",
    "#     create_research_plan_agent,\n",
    "#     create_summary_agent,\n",
    "#     create_research_report_agent,\n",
    "#     create_peer_review_agent\n",
    "# )\n",
    "\n",
    "# planner_agent = create_research_plan_agent(project_client=project_client)\n",
    "# bing_search_agent = create_bing_search_agent(project_client=project_client)\n",
    "# summary_agent = create_summary_agent(project_client=project_client)\n",
    "# research_agent = create_research_report_agent(project_client=project_client)\n",
    "# peer_review_agent = create_peer_review_agent(project_client=project_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Agents from Azure AI Foundry\n",
    "\n",
    "Once you've created your agents (using the cell above), use this cell to retrieve them by their IDs from your `.env` file. This is the standard approach for working with pre-created Azure AI Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PlannerAgentID\"))\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"BingSearchAgentID\"))\n",
    "summary_agent = project_client.agents.get_agent(agent_id=os.getenv(\"SummaryAgentID\"))\n",
    "research_agent = project_client.agents.get_agent(agent_id=os.getenv(\"ResearchAgentID\"))\n",
    "peer_review_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PeerReviewAgentID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Agent Instructions\n",
    "\n",
    "This cell updates the system instructions for all agents with current date awareness and any refined prompts. Run this cell each time you want to ensure agents have the latest instructions, especially for date-sensitive queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.update_instructions import (\n",
    "    update_planner_instructions,\n",
    "    update_bing_instructions,\n",
    "    update_summary_instructions,\n",
    "    update_research_instructions,\n",
    "    update_peer_review_instructions\n",
    ")\n",
    "\n",
    "planner_agent = update_planner_instructions(agent=planner_agent)\n",
    "bing_search_agent = update_bing_instructions(agent=bing_search_agent)\n",
    "summary_agent = update_summary_instructions(agent=summary_agent)\n",
    "research_agent = update_research_instructions(agent=research_agent)\n",
    "peer_review_agent = update_peer_review_instructions(agent=peer_review_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.4 (20251115.1723)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"183pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 183.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.790802 0.790802) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 1999.03,-227 1999.03,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1090.29,-8C1090.29,-8 1746.54,-8 1746.54,-8 1752.54,-8 1758.54,-14 1758.54,-20 1758.54,-20 1758.54,-203 1758.54,-203 1758.54,-209 1752.54,-215 1746.54,-215 1746.54,-215 1090.29,-215 1090.29,-215 1084.29,-215 1078.29,-209 1078.29,-203 1078.29,-203 1078.29,-20 1078.29,-20 1078.29,-14 1084.29,-8 1090.29,-8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1418.42\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.86,-72.6C133.43,-72.24 159.62,-72.4 216.49,-73.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.32,-76.59 226.37,-73.22 216.41,-69.59 216.32,-76.59\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.46,-71.88C370.78,-71.43 396.13,-71.62 445.49,-72.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.18,-75.92 455.23,-72.59 445.29,-68.92 445.18,-75.92\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M926.04,-92.25C926.04,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 926.04,-55.75 926.04,-55.75 932.04,-55.75 938.04,-61.75 938.04,-67.75 938.04,-67.75 938.04,-80.25 938.04,-80.25 938.04,-86.25 932.04,-92.25 926.04,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"837.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"837.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;summary -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.28,-69C638.59,-68.14 669.02,-68.56 725.16,-70.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.73,-73.76 734.83,-70.57 724.94,-66.76 724.73,-73.76\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1188.54,-92.25C1188.54,-92.25 1098.29,-92.25 1098.29,-92.25 1092.29,-92.25 1086.29,-86.25 1086.29,-80.25 1086.29,-80.25 1086.29,-67.75 1086.29,-67.75 1086.29,-61.75 1092.29,-55.75 1098.29,-55.75 1098.29,-55.75 1188.54,-55.75 1188.54,-55.75 1194.54,-55.75 1200.54,-61.75 1200.54,-67.75 1200.54,-67.75 1200.54,-80.25 1200.54,-80.25 1200.54,-86.25 1194.54,-92.25 1188.54,-92.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1143.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1143.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M881.86,-55.34C964.88,-21.4 990.44,-20.14 1081.1,-51.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.86,-54.82 1090.45,-54.83 1082.17,-48.22 1079.86,-54.82\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1012.17\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1416.54,-52.25C1416.54,-52.25 1327.04,-52.25 1327.04,-52.25 1321.04,-52.25 1315.04,-46.25 1315.04,-40.25 1315.04,-40.25 1315.04,-27.75 1315.04,-27.75 1315.04,-21.75 1321.04,-15.75 1327.04,-15.75 1327.04,-15.75 1416.54,-15.75 1416.54,-15.75 1422.54,-15.75 1428.54,-21.75 1428.54,-27.75 1428.54,-27.75 1428.54,-40.25 1428.54,-40.25 1428.54,-46.25 1422.54,-52.25 1416.54,-52.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1200.81,-63.21C1253.32,-53.35 1281.27,-48.19 1303.85,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1304.14,-47.88 1313.43,-42.79 1302.99,-40.97 1304.14,-47.88\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1257.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1650.69,-105.94C1650.69,-105.94 1584.14,-78.56 1584.14,-78.56 1578.59,-76.28 1578.59,-71.72 1584.14,-69.44 1584.14,-69.44 1650.69,-42.06 1650.69,-42.06 1656.24,-39.78 1667.34,-39.78 1672.89,-42.06 1672.89,-42.06 1739.44,-69.44 1739.44,-69.44 1744.99,-71.72 1744.99,-76.28 1739.44,-78.56 1739.44,-78.56 1672.89,-105.94 1672.89,-105.94 1667.34,-108.22 1656.24,-108.22 1650.69,-105.94\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1661.79\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1661.79\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1211.83,-72.2C1443.6,-66.13 1499.16,-65.21 1583.06,-69.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1212.08,-68.69 1202.17,-72.45 1212.26,-75.69 1212.08,-68.69\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1371.79\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.68,-37.82C1526.04,-44.45 1562.55,-47.76 1598.61,-56.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.31,-59.39 1607.86,-58.37 1598.98,-52.59 1597.31,-59.39\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1500.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"1925.91\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1925.91\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1925.91\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1748.73,-72.86C1794.97,-72.28 1822.55,-72.05 1845.08,-72.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1844.92,-75.66 1854.95,-72.24 1844.98,-68.66 1844.92,-75.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1803.67\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2a4eb249910>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageRole\n",
    "from common.data_models import ResearchPlan\n",
    "from common.utils_ai_agents import (\n",
    "    add_user_message_to_thread,\n",
    "    invoke_agent\n",
    ")\n",
    "import json\n",
    "\n",
    "# create a thread and add the user message\n",
    "thread = project_client.agents.threads.create()\n",
    "add_user_message_to_thread(project_client, thread.id, user_query)\n",
    "\n",
    "# invoke the planner agent to create a research plan\n",
    "planner_agent_output, thread = invoke_agent(\n",
    "    project_client=project_client,\n",
    "    thread=thread,\n",
    "    agent=planner_agent\n",
    ")\n",
    "\n",
    "# parse the output to a ResearchPlan object\n",
    "plan_data = json.loads(planner_agent_output)\n",
    "plan = ResearchPlan(**plan_data)\n",
    "\n",
    "# delete the thread\n",
    "project_client.agents.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classical machine learning vs deep learning vs generative AI methodologies',\n",
       " 'Comparison of foundational algorithms in classical ML, deep learning, and generative AI']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running research queries in parallel: 100%|██████████| 6/6 [00:28<00:00,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core principles and methodologies: 2/2 queries succeeded\n",
      "Typical applications and use cases: 2/2 queries succeeded\n",
      "Technological requirements and limitations: 2/2 queries succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "MAX_WORKERS = 8  # adjust for your rate limits\n",
    "\n",
    "def run_one_query(subtopic_name: str, query: str) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "    Research the following query: {query}\n",
    "    This is related to subtopic: {subtopic_name}\n",
    "    Please provide the information and cite your sources using the available tools.\n",
    "    \"\"\"\n",
    "    thread = None\n",
    "    try:\n",
    "        thread = project_client.agents.threads.create()\n",
    "        add_user_message_to_thread(project_client, thread.id, prompt)\n",
    "\n",
    "        _out, _ = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=bing_search_agent\n",
    "        )\n",
    "\n",
    "        text, urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "        return {\"query\": query, \"agent_response\": text, \"results\": urls}\n",
    "    except Exception as e:\n",
    "        return {\"query\": query, \"results\": [], \"error\": str(e)}\n",
    "    finally:\n",
    "        try:\n",
    "            if thread is not None:\n",
    "                project_client.agents.threads.delete(thread_id=thread.id)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Flatten tasks\n",
    "# si: index of the subtopic\n",
    "# qi: index of the query within that subtopic\n",
    "# st.subtopic: the subtopic name\n",
    "# q: the query text\n",
    "\n",
    "tasks: List[Tuple[int, int, str, str]] = [\n",
    "    (si, qi, st.subtopic, q)\n",
    "    for si, st in enumerate(plan.research_tasks)\n",
    "    for qi, q in enumerate(st.search_queries)\n",
    "]\n",
    "\n",
    "# Run in parallel\n",
    "results = defaultdict(dict)  # results[si][qi] = entry\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    fmap = {ex.submit(run_one_query, subtopic_name, query): (si, qi)\n",
    "            for si, qi, subtopic_name, query in tasks}\n",
    "    for fut in tqdm(as_completed(fmap), total=len(fmap), desc=\"Running research queries in parallel\"):\n",
    "        si, qi = fmap[fut]\n",
    "        try:\n",
    "            results[si][qi] = fut.result()\n",
    "        except Exception as e:\n",
    "            results[si][qi] = {\"query\": tasks[si][3], \"results\": [], \"error\": str(e)}\n",
    "\n",
    "# Rebuild in original shape and order\n",
    "search_results: List[Dict[str, Any]] = []\n",
    "for si, st in enumerate(plan.research_tasks):\n",
    "    queries = [results[si].get(qi, {\"query\": q, \"results\": [], \"error\": \"Missing result\"})\n",
    "               for qi, q in enumerate(st.search_queries)]\n",
    "    search_results.append({\"subtopic\": st.subtopic, \"queries\": queries})\n",
    "\n",
    "# Quick status\n",
    "for block in search_results:\n",
    "    ok = sum(1 for q in block[\"queries\"] if \"error\" not in q)\n",
    "    print(f\"{block['subtopic']}: {ok}/{len(block['queries'])} queries succeeded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 6\n",
      "\n",
      "Actually total search queries: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics in parallel: 100%|██████████| 3/3 [00:29<00:00,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries completed: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from tqdm import tqdm\n",
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "MAX_WORKERS_SUMMARY = 5\n",
    "\n",
    "def summarize_one(subtopic_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    all_responses, unique_citations = collect_responses_and_citations(subtopic_result)\n",
    "    content = \"\\n\\n---\\n\\n\".join(all_responses)\n",
    "\n",
    "    summary = \"No content found to summarize for this subtopic.\"\n",
    "    thread = None\n",
    "    if content:\n",
    "        summary_prompt = (\n",
    "            f\"Summarize the following information related to the subtopic \"\n",
    "            f\"'{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content}\"\n",
    "        )\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, summary_prompt)\n",
    "            out, _ = invoke_agent(project_client=project_client, thread=thread, agent=summary_agent)\n",
    "            summary = out.strip()\n",
    "        except Exception as e:\n",
    "            sub = subtopic_result.get('subtopic', 'Unknown Subtopic')\n",
    "            summary = f\"Error during summarization for subtopic '{sub}'. Details: {e}\"\n",
    "        finally:\n",
    "            try:\n",
    "                if thread is not None:\n",
    "                    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    citations_list = [{\"title\": t, \"url\": u} for (t, u) in unique_citations]\n",
    "    return {\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"),\n",
    "        \"summary\": summary,\n",
    "        \"citations\": citations_list,\n",
    "    }\n",
    "\n",
    "# Run all subtopics in parallel and preserve order\n",
    "mapped_chunks: List[Dict[str, Any]] = [None] * len(search_results)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS_SUMMARY) as ex:\n",
    "    fmap = {ex.submit(summarize_one, subtopic_result): i\n",
    "            for i, subtopic_result in enumerate(search_results)}\n",
    "    for fut in tqdm(as_completed(fmap), total=len(fmap), desc=\"Summarizing subtopics in parallel\"):\n",
    "        i = fmap[fut]\n",
    "        try:\n",
    "            mapped_chunks[i] = fut.result()\n",
    "        except Exception as e:\n",
    "            sub = search_results[i].get(\"subtopic\", \"Unknown Subtopic\")\n",
    "            mapped_chunks[i] = {\n",
    "                \"subtopic\": sub,\n",
    "                \"summary\": f\"Error during summarization for subtopic '{sub}'. Details: {e}\",\n",
    "                \"citations\": [],\n",
    "            }\n",
    "\n",
    "# Optional: quick status\n",
    "ok = sum(1 for m in mapped_chunks if m and not m[\"summary\"].startswith(\"Error during summarization\"))\n",
    "print(f\"Summaries completed: {ok}/{len(mapped_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_thread_messages(thread):\n",
    "    messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "    for m in messages:\n",
    "        print(f\"roll: {m.role}\")\n",
    "        print(f\"agent_id: {m.agent_id}\")\n",
    "        print(f\"content: {m.content[0]['text']['value']}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_models import ComprehensiveResearchReport, PeerReviewFeedback\n",
    "from common.utils_ai_agents import add_user_message_to_thread\n",
    "\n",
    "def loop_agents(project_client, agent_a, agent_b, initial_input, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Loop between two agents until agent B produces the target output.\n",
    "    \n",
    "    Args:\n",
    "        agent_a: Function that takes input and returns output\n",
    "        agent_b: Function that takes input and returns output\n",
    "        initial_input: Starting input for agent A\n",
    "        max_iterations: Safety limit to prevent infinite loops\n",
    "    \n",
    "    Returns:\n",
    "        The final output from agent B, or None if max iterations reached\n",
    "    \"\"\"\n",
    "    current_input = initial_input\n",
    "    thread = project_client.agents.threads.create()\n",
    "    add_user_message_to_thread(project_client, thread.id, current_input)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # Agent A processes the input and produces output\n",
    "        a_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_a\n",
    "        )\n",
    "\n",
    "        handover_message = f\"A research agent has produced a research report. Please review it.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "        \n",
    "        # Agent B reviews the output\n",
    "        b_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_b\n",
    "        )\n",
    "\n",
    "        b_output_json = json.loads(b_output)\n",
    "        review = PeerReviewFeedback(**b_output_json)\n",
    "\n",
    "        # Check if B produced the target output\n",
    "        if review.is_satisfactory is not False:\n",
    "            print(f\"Target output reached after {i+1} iterations!\")\n",
    "            report_json = json.loads(a_output)\n",
    "            final_report = ComprehensiveResearchReport(**report_json)\n",
    "\n",
    "            # delete the thread\n",
    "            # print_thread_messages(thread)\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            return final_report\n",
    "        \n",
    "        # Use B's output as input for the next iteration\n",
    "        current_input = b_output\n",
    "        \n",
    "        handover_message = f\"Peer review agent has provided feedback. Please revise the research report based on the feedback.\"\n",
    "        add_user_message_to_thread(project_client, thread.id, handover_message)\n",
    "\n",
    "    # delete the thread\n",
    "    # print_thread_messages(thread)\n",
    "    project_client.agents.threads.delete(thread_id=thread.id)\n",
    "    print(f\"Max iterations ({max_iterations}) reached without finding target output\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target output reached after 1 iterations!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "research_query = (\n",
    "    \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "    \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "    \"a cohesive, academic-style paper:\\n\\n\"\n",
    "    f\"{research_input_prompt}\\n\\n\"\n",
    "    \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    ")\n",
    "\n",
    "# Run the loop\n",
    "final_report = loop_agents(\n",
    "    project_client=project_client,\n",
    "    agent_a=research_agent,\n",
    "    agent_b=peer_review_agent,\n",
    "    initial_input=research_query,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Comparative Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Methodologies, Applications, and Technological Foundations\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Artificial intelligence (AI) has undergone a dramatic evolution over the past several decades, giving rise to a diverse spectrum of methodologies that span classical machine learning, deep learning, and the most recent frontier—generative AI. Each of these paradigms is distinguished by unique philosophical foundations, algorithmic approaches, and technological requirements, which in turn shape their respective applications and impact across industries. This report provides an exceptionally comprehensive, paragraph-focused analysis of these three pillars of modern AI, synthesizing their core principles, typical use cases, and technological underpinnings. The goal is to offer a nuanced, authoritative comparison that informs both practitioners and decision-makers about the strengths, limitations, and future trajectories of these transformative technologies.\n",
       "\n",
       "## Core Principles and Methodologies\n",
       "\n",
       "### Classical Machine Learning: Foundations and Approaches\n",
       "\n",
       "Classical machine learning (ML) is fundamentally rooted in statistical theory and algorithmic pattern recognition, relying on the explicit representation of data through manual feature engineering. The practitioner’s expertise is central to this paradigm, as the selection and crafting of features—those measurable properties or characteristics of the data—directly influence model performance and interpretability. Classical ML encompasses three primary learning modalities: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves training models on labeled datasets to perform tasks such as classification (e.g., spam detection) or regression (e.g., price prediction). Unsupervised learning, by contrast, seeks to uncover hidden structures in unlabeled data, as seen in clustering algorithms for customer segmentation. Reinforcement learning, though less common in traditional ML, enables models to optimize behaviors through iterative feedback from their environment, often applied in control systems and robotics.\n",
       "\n",
       "The canonical algorithms of classical ML include linear regression, logistic regression, support vector machines (SVM), decision trees, and Naive Bayes classifiers. These algorithms are typically implemented in a stepwise workflow: data collection, preprocessing, feature selection, algorithm choice, iterative model training, evaluation, and deployment. The interpretability of classical ML models is a defining strength, allowing practitioners to trace predictions back to specific features and understand the rationale behind decisions. This transparency is especially valued in regulated sectors such as finance and healthcare, where accountability is paramount. However, classical ML’s reliance on structured, tabular data and manual feature engineering imposes limitations on scalability and adaptability, particularly when confronted with high-dimensional or unstructured datasets such as images or natural language text [1][2][3][4][5][6][7][8].\n",
       "\n",
       "### Deep Learning: Automated Feature Extraction and Hierarchical Representation\n",
       "\n",
       "Deep learning (DL) represents a methodological leap from classical ML by automating the process of feature extraction through multi-layered artificial neural networks. Inspired by the structure of biological neural networks, deep learning models consist of interconnected neurons organized into input, hidden, and output layers. The depth of these networks—often comprising dozens or even hundreds of layers—enables the learning of hierarchical representations, from low-level edges in images to high-level semantic concepts in text. Foundational architectures include multilayer perceptrons (MLP), convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers. CNNs excel at spatial data processing, making them the backbone of image and video recognition systems. RNNs and their variants (such as LSTM and GRU) are tailored for sequential data, powering applications in natural language processing (NLP) and time series analysis. Transformers, leveraging self-attention mechanisms, have revolutionized NLP by enabling models to capture long-range dependencies and context within text sequences.\n",
       "\n",
       "The training of deep learning models is computationally intensive, requiring extensive labeled datasets and high-performance hardware—often GPU acceleration—to perform backpropagation and optimize network weights. Unlike classical ML, deep learning minimizes manual intervention in feature creation, instead learning complex, non-linear mappings directly from raw data. This capability makes DL highly scalable and versatile, excelling in domains characterized by unstructured inputs such as images, speech, and text. However, the complexity and opacity of deep learning models—often described as “black boxes”—pose significant challenges for interpretability and transparency, particularly in critical decision-making contexts. Additionally, the resource demands of deep learning, both in terms of data and computation, can be prohibitive for organizations lacking specialized infrastructure [1][2][3][4][5][7][8].\n",
       "\n",
       "### Generative AI: Creation and Simulation through Advanced Architectures\n",
       "\n",
       "Generative AI marks the latest and most advanced evolution in the AI landscape, building upon deep learning to shift the focus from prediction and classification to the creation of novel data. The core principle of generative AI is the modeling of the underlying probability distribution of observed data, enabling the generation of new, plausible samples that mimic the characteristics of the training set. This paradigm is realized through several sophisticated architectures, including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), diffusion models, autoregressive models, and transformers.\n",
       "\n",
       "GANs, introduced by Goodfellow et al., consist of two neural networks—the generator and the discriminator—engaged in a competitive, game-theoretic loop that iteratively refines the quality of generated outputs. VAEs encode input data into a latent representation and decode it to reconstruct and generate new samples, optimizing for probabilistic consistency. Diffusion models, which have recently achieved state-of-the-art results in high-fidelity image synthesis, iteratively add and remove noise to generate realistic imagery. Autoregressive models, exemplified by the GPT family, sequentially generate content by predicting each subsequent token based on preceding context. Transformers underpin large language models (LLMs), handling vast sequences for tasks such as text generation, question answering, and code synthesis.\n",
       "\n",
       "Generative AI models are trained on massive, diverse datasets and demand enormous computational power, often necessitating distributed cloud infrastructure and specialized hardware. Their automatic feature learning supports advanced applications in content creation (art, text, video, music), conversational agents, code generation, and scientific discovery (e.g., drug design and molecular simulation). The complexity and resource intensity of generative AI surpass those of classical ML and deep learning, while interpretability remains a significant challenge. The exponential growth in synthetic media, automation, and discovery driven by generative AI raises important questions about model fairness, ethical deployment, and resource sustainability [1][2][3][4][5][7][8].\n",
       "\n",
       "### Comparative Summary of Methodologies\n",
       "\n",
       "The progression from classical ML to deep learning and generative AI is marked by increasing complexity, data requirements, and application breadth. Classical ML relies on manual feature engineering, moderate data, and structured inputs, offering interpretability and moderate scalability. Deep learning automates feature extraction, requires large-scale labeled data, and excels with unstructured inputs, but sacrifices transparency for scalability and versatility. Generative AI, at the frontier, leverages automatic feature learning and massive datasets to create new content, demanding the highest computational resources and presenting the lowest interpretability. This stratification is critical for organizations seeking to balance transparency, scalability, data availability, and innovation in their AI strategies [1][2][3][4][5][6][7][8].\n",
       "\n",
       "## Typical Applications and Use Cases\n",
       "\n",
       "### Classical Machine Learning: Structured Data and Predictive Analytics\n",
       "\n",
       "Classical machine learning algorithms are most effective when applied to structured, tabular data—datasets organized into rows and columns, such as financial transactions, health records, or retail databases. These models underpin a wide array of business-critical functions, including predictive analytics, classification, regression, clustering, and recommendation systems. In finance, classical ML is foundational for fraud detection, leveraging historical transaction data to flag suspicious activity. Retailers employ these models for sales forecasting and inventory management, while healthcare organizations use them for disease risk prediction based on patient records. Telecommunications companies rely on classical ML for churn prediction, identifying customers likely to switch providers.\n",
       "\n",
       "The interpretability and computational efficiency of classical ML make it the preferred choice for credit scoring in finance, targeted marketing through customer segmentation, and predictive diagnostics in healthcare. Recommendation systems, which suggest products or content based on user behavior, are another prominent application, particularly in e-commerce and streaming platforms. Clustering algorithms facilitate market segmentation, while anomaly detection is critical for cybersecurity and fraud prevention. Time series analysis supports sensor monitoring in IoT and financial forecasting. The reliance on structured data and transparent decision-making processes ensures that classical ML remains indispensable in domains where accountability and regulatory compliance are paramount [1][5][6][7][8][9].\n",
       "\n",
       "### Deep Learning: Unstructured Data and Complex Pattern Mining\n",
       "\n",
       "Deep learning’s core strength lies in its ability to process vast, complex, and unstructured datasets—such as images, text, and audio—where traditional approaches falter. This paradigm powers image and video recognition applications, including facial identification for security systems and medical image analysis for tumor detection in X-rays and MRIs. Autonomous vehicle navigation critically depends on deep neural networks’ ability to interpret sensor data, identify obstacles, and make real-time decisions, enhancing safety and reliability.\n",
       "\n",
       "Natural language processing (NLP) through deep learning underpins virtual assistants (e.g., Siri, Alexa), chatbots, sentiment analysis, and automated text summarization. DL models such as CNNs, RNNs, and transformers are pivotal in speech recognition, transforming voice recordings into text and enabling voice-controlled devices and automated customer service. In healthcare, deep learning accelerates drug discovery by modeling complex biological interactions and predicting molecular efficacy. Cybersecurity benefits from DL-driven pattern recognition for detecting malware and network intrusions. The flexibility and capability of deep learning to handle unstructured information have led to its widespread adoption in healthcare (radiology imaging), automotive (self-driving systems), entertainment (content recommendation), and security (facial recognition technology) [1][2][3][4][6][7][8].\n",
       "\n",
       "### Generative AI: Content Creation, Simulation, and Interactive Systems\n",
       "\n",
       "Generative AI is fundamentally transforming creative and data-driven industries by enabling machines to generate text, images, audio, and code. Advanced architectures such as GANs and large language models (LLMs, e.g., GPT family) underpin these capabilities. Applications include generating realistic images and videos for art, entertainment, and marketing; synthesizing music; automating the writing of reports and social media posts; and facilitating natural conversation through advanced chatbots and virtual assistants.\n",
       "\n",
       "Generative AI is particularly impactful in areas where producing new, original material is valuable. Companies use it to augment datasets with synthetic data when real data is limited, improving the robustness of classical ML or DL models. In software development, generative models assist programmers by generating code snippets or translating natural language queries into SQL statements. Pharmaceutical firms utilize generative AI for drug discovery and molecular design, simulating new chemical compounds with desired properties. In design-centric fields—such as fashion, architecture, and industrial prototyping—generative AI can propose new concepts rapidly, expanding creative capacity.\n",
       "\n",
       "Increasingly, organizations integrate these approaches in hybrid solutions: for example, using classical ML for structured predictions, deep learning for feature extraction from complex data, and generative AI for augmenting datasets or content creation. This integration maximizes business value and enables sophisticated solutions in healthcare, finance, transportation, manufacturing, entertainment, and more [1][2][3][4][5][6][7][8][9].\n",
       "\n",
       "### Comparative Summary of Applications\n",
       "\n",
       "Classical ML dominates structured, well-understood, and explainable tasks; deep learning leads in complex, unstructured data environments and pattern mining; generative AI pushes boundaries in creative, synthetic, and highly interactive domains. The breadth of applications across these three categories highlights both their current value and future potential. As technology advances, understanding when and how to deploy classical ML, DL, or generative AI—or combinations thereof—is critical for optimizing innovation and operational efficiency. Emerging challenges include interpretability (especially for DL and generative AI), data privacy, and regulatory compliance, spotlighting the need for continued evolution in methodologies and governance frameworks [1][2][3][4][5][6][7][8][9].\n",
       "\n",
       "## Technological Requirements and Limitations\n",
       "\n",
       "### Classical Machine Learning: Modest Hardware and Manual Feature Engineering\n",
       "\n",
       "Classical machine learning is characterized by relatively modest hardware demands. Most algorithms, including regression, decision trees, and SVMs, are CPU-bound, with a modern multi-core processor (e.g., Intel i7/i9 or AMD Ryzen 7/9) sufficing for most workloads. RAM requirements range from 8–16 GB for typical datasets, extending up to 32 GB or more for larger datasets. Storage needs are moderate, with SSDs (512 GB+) recommended for efficient data access; GPUs are generally optional unless using parallelizable methods. From a software perspective, classical ML operates efficiently using common operating systems (Windows, Linux, macOS) and lightweight libraries such as Scikit-learn (Python), R, or MATLAB.\n",
       "\n",
       "Technological limitations arise primarily in scaling up: large datasets or real-time requirements can quickly exceed available CPU/RAM, necessitating distributed computing or cloud resources. Additionally, classical ML relies heavily on manual feature selection and engineering, which is labor-intensive and depends on domain expertise. Datasets with high dimensionality challenge scalability and often require dimensionality reduction techniques. Though relatively interpretable, ensemble methods may become opaque. Overfitting on small datasets and poor generalization to non-linear or complex relationships are frequent issues [10][11][12][13][14][15][16][17][18].\n",
       "\n",
       "### Deep Learning: High-Performance Computing and Data Demands\n",
       "\n",
       "Deep learning significantly raises the bar for technological requirements. While powerful CPUs are essential for data preparation, the critical hardware is the GPU. Modern NVIDIA GPUs (RTX 3080/3090, A100, H100) with CUDA support, offering 8–16 GB or more VRAM, are almost mandatory for training neural networks. RAM requirements increase to 16–32 GB or higher, especially for large datasets and parallelized training, and storage needs (SSD, 1 TB+) reflect massive data read-write operations. When scaling across nodes, high-speed networking (1 Gbps Ethernet, InfiniBand) becomes vital.\n",
       "\n",
       "Software environments favor Linux (e.g., Ubuntu, CentOS) for compatibility and performance, but Windows can be used. Critical frameworks include TensorFlow, PyTorch, Keras, and MXNet, all of which demand CUDA/cuDNN libraries and up-to-date NVIDIA drivers for optimal acceleration.\n",
       "\n",
       "Limitations for deep learning center on high computational resource and data demands: extensive labeled datasets, significant VRAM, and RAM are essential. Scaling up often involves multiple GPUs or specialized hardware like TPUs, usually found only in cloud or dedicated HPC environments. Deep learning models are typically “black boxes,” raising concerns over interpretability—particularly in sensitive areas like healthcare or finance. Overfitting, vulnerability to adversarial attacks, and optimization barriers such as vanishing gradients or local minima complicate development. Many architectures are domain-specific, requiring extensive retraining to shift to different data types, and the sheer volume of data creates storage and I/O bottlenecks [10][11][12][13][14][15][16][17][18].\n",
       "\n",
       "### Generative AI: Extreme Resource Intensity and Ethical Challenges\n",
       "\n",
       "Generative AI systems, including large language models, GANs, and diffusion models, impose the highest technological requirements. Hardware demands peak with server-grade CPUs (e.g., Intel Xeon, AMD EPYC/Threadripper PRO), cutting-edge GPUs (NVIDIA A100, H100, RTX 40 series) equipped with 40–80 GB VRAM and Tensor Cores for accelerated matrix operations, TPUs, and occasionally FPGAs for specialized tasks. RAM requirements soar to 64 GB or more, and storage moves to NVMe SSDs at 2 TB+ for rapid data throughput. Networking must support distributed training and inference at high speeds (advanced Ethernet/InfiniBand). In practice, training state-of-the-art generative models often exceeds the capabilities of local hardware, necessitating cloud-based platforms (AWS, GCP, Azure) with clusters of top-tier GPUs/TPUs and corresponding data pipeline infrastructure.\n",
       "\n",
       "From a software standpoint, Linux is the preferred OS for enterprise and research deployments. Key frameworks and libraries include Hugging Face Transformers, TensorFlow, PyTorch, and JAX, alongside CUDA/cuDNN and specialized solutions (e.g., Diffusers for diffusion models).\n",
       "\n",
       "Generative AI’s key limitations are multidimensional. The computational cost—both hardware and power consumption—is immense and often unattainable outside cloud or enterprise settings. Quality control is a major challenge: large generative models can output plausible but inaccurate or biased results, complicating trustworthy deployment. Risks around ethics and society (e.g., misinformation, bias, deepfakes) are elevated, and models trained on sensitive data can potentially leak private information. As with deep learning, explainability is poor, making regulatory compliance difficult. Maintenance and updating is costly: keeping generative models current requires retraining, significant compute investment, and sophisticated infrastructure [10][11][12][13][14][15][16][17][18].\n",
       "\n",
       "### Comparative Overview of Technological Requirements\n",
       "\n",
       "Classical ML, deep learning, and generative AI differ sharply in technology requirements, scalability, interpretability, and robustness. Classical ML performs well with moderate resources but cannot scale or automate feature engineering like deep learning, which, in turn, is bottlenecked by data/computation needs and interpretability hurdles. Generative AI surpasses both in demand for computational power and data infrastructure, while introducing new risks in quality, ethics, privacy, and maintenance. For the largest models, technological limitations are tightly coupled to available infrastructure—making cloud and distributed systems indispensable. The rapid evolution of AI models continually raises the technological threshold for meaningful participation, especially in research or enterprise settings. Each technology layer has its own set of scaling bottlenecks, interpretability trade-offs, and domain-specific requirements, making thoughtful infrastructure investment crucial for organizations. As models reach new levels of capability (e.g., GPT-4 scale), technical limitations become a key determinant of feasibility and innovation pace—sparking ongoing development in hardware, cloud capacity, and software optimization [10][11][12][13][14][15][16][17][18].\n",
       "\n",
       "## Integrated Comparative Analysis\n",
       "\n",
       "### Methodological Hierarchy and Evolution\n",
       "\n",
       "The evolution from classical machine learning to deep learning and generative AI reflects a hierarchical progression in both technical sophistication and application breadth. Classical ML’s reliance on manual feature engineering and structured data makes it highly interpretable but limited in scalability and adaptability. Deep learning automates feature extraction and excels with unstructured data, enabling breakthroughs in image, speech, and text processing, albeit at the cost of transparency and resource intensity. Generative AI, building on deep learning, shifts the paradigm toward creation and simulation, opening new frontiers in content generation, scientific discovery, and interactive systems. This hierarchy is illustrated in the table below:\n",
       "\n",
       "| Dimension            | Classical ML      | Deep Learning      | Generative AI      |\n",
       "|---------------------|------------------|--------------------|-------------------|\n",
       "| Feature Engineering | Manual           | Automated          | Automated         |\n",
       "| Data Requirements   | Moderate         | Large, labeled     | Massive, diverse  |\n",
       "| Input Type          | Structured       | Unstructured       | Unstructured      |\n",
       "| Model Complexity    | Low–Moderate     | High               | Very High         |\n",
       "| Interpretability    | High             | Low                | Very Low          |\n",
       "| Scalability         | Moderate         | High               | Highest           |\n",
       "| Computational Need  | Modest           | Significant        | Extreme           |\n",
       "| Typical Use Cases   | Predictive,      | Pattern mining,    | Content creation, |\n",
       "|                     | analytics,       | recognition, NLP   | simulation,       |\n",
       "|                     | classification   |                    | discovery         |\n",
       "\n",
       "### Application Domains and Industry Impact\n",
       "\n",
       "The impact of these AI paradigms is felt across a diverse array of industries. Classical ML remains the backbone of structured analytics in finance, healthcare, and retail, supporting critical functions that demand transparency and regulatory compliance. Deep learning has unlocked new capabilities in healthcare (radiology imaging, drug discovery), automotive (autonomous navigation), entertainment (content recommendation), and security (facial recognition). Generative AI is reshaping creative industries, software development, customer service, and pharmaceuticals, enabling automated content generation, synthetic data creation, and rapid prototyping.\n",
       "\n",
       "Organizations increasingly deploy hybrid solutions that blend these approaches, leveraging the strengths of each paradigm to address complex, multifaceted problems. For example, a healthcare analytics platform might use classical ML for risk prediction, deep learning for image analysis, and generative AI to augment training datasets or automate report generation. This integration maximizes business value and fosters innovation, while also introducing new challenges in governance, interpretability, and resource management.\n",
       "\n",
       "### Technological Trajectories and Future Challenges\n",
       "\n",
       "The technological requirements of AI systems have escalated dramatically, with generative AI models setting new benchmarks for computational intensity and infrastructure demands. The shift toward cloud-based and distributed computing is driven by the need to support large-scale training and inference, particularly for generative models. As AI systems become more capable, concerns about interpretability, fairness, privacy, and ethical deployment are magnified, necessitating ongoing research and the development of robust governance frameworks.\n",
       "\n",
       "The future trajectory of AI will be shaped by advances in hardware (e.g., next-generation GPUs, TPUs), software optimization, and data pipeline engineering. Addressing the challenges of explainability, bias mitigation, and resource sustainability will be critical for ensuring the responsible and effective deployment of AI technologies. The integration of classical ML, deep learning, and generative AI into cohesive, hybrid solutions represents the cutting edge of AI innovation, offering unparalleled opportunities for impact across industries and society at large.\n",
       "\n",
       "## Data Visualizations and Comparative Tables\n",
       "\n",
       "### Timeline of Major Developments\n",
       "\n",
       "| Year | Milestone                                    | Paradigm           |\n",
       "|------|----------------------------------------------|--------------------|\n",
       "| 1950s–1970s | Statistical pattern recognition, regression | Classical ML       |\n",
       "| 1980s–1990s | Decision trees, SVMs, ensemble methods     | Classical ML       |\n",
       "| 2006        | Deep belief networks, resurgence of DL     | Deep Learning      |\n",
       "| 2012        | AlexNet, breakthrough in image recognition | Deep Learning      |\n",
       "| 2017        | Transformer architecture                   | Deep Learning      |\n",
       "| 2014        | GANs introduced                            | Generative AI      |\n",
       "| 2018–2020   | GPT, BERT, large-scale LLMs                | Generative AI      |\n",
       "| 2022–2024   | Diffusion models, multimodal generative AI | Generative AI      |\n",
       "\n",
       "### Impact Assessment Matrix Across Industries\n",
       "\n",
       "| Industry      | Classical ML | Deep Learning | Generative AI |\n",
       "|---------------|-------------|---------------|---------------|\n",
       "| Finance       | High        | Moderate      | Emerging      |\n",
       "| Healthcare    | High        | High          | Moderate      |\n",
       "| Retail        | High        | Moderate      | Moderate      |\n",
       "| Automotive    | Moderate    | High          | Moderate      |\n",
       "| Entertainment | Moderate    | High          | High          |\n",
       "| Security      | High        | High          | Moderate      |\n",
       "| Pharma        | Moderate    | High          | High          |\n",
       "| Software Dev  | Moderate    | Moderate      | High          |\n",
       "\n",
       "### Hierarchical Breakdown of Components\n",
       "\n",
       "- **Classical ML:**\n",
       "  - Algorithms: Linear/Logistic Regression, SVM, Decision Trees, Naive Bayes\n",
       "  - Feature Engineering: Manual, domain-driven\n",
       "  - Data: Structured/tabular\n",
       "- **Deep Learning:**\n",
       "  - Architectures: MLP, CNN, RNN, Transformer\n",
       "  - Feature Extraction: Automated, hierarchical\n",
       "  - Data: Unstructured (images, text, audio)\n",
       "- **Generative AI:**\n",
       "  - Architectures: GAN, VAE, Diffusion, Transformer\n",
       "  - Output: Synthetic data, novel content\n",
       "  - Data: Massive, diverse, multimodal\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The comparative analysis of classical machine learning, deep learning, and generative AI reveals a landscape of increasing complexity, capability, and resource intensity. Classical ML offers interpretability and efficiency for structured data tasks, deep learning unlocks powerful pattern recognition in unstructured domains, and generative AI pushes the boundaries of creation and simulation. The technological requirements escalate from modest hardware for classical ML to extreme infrastructure demands for generative AI, while interpretability and ethical considerations become more pronounced. The integration of these paradigms into hybrid solutions is driving innovation across industries, but also necessitates careful attention to governance, resource sustainability, and responsible deployment. As AI continues to evolve, understanding the distinctions and complementarities among these methodologies will be essential for harnessing their full potential in research, industry, and society.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] Machine Learning vs Deep Learning vs Generative AI - What are the ..., https://www.freecodecamp.org/news/machine-learning-vs-deep-learning-vs-generative-ai/\n",
       "[2] Machine Learning vs. Deep Learning vs. Generative AI, https://tellix.ai/machine-learning-vs-deep-learning-vs-generative-ai/\n",
       "[3] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks, https://www.geeksforgeeks.org/machine-learning/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks/\n",
       "[4] Comparing Deep Learning and Traditional Machine Learning, https://theceoviews.com/comparing-deep-learning-and-traditional-machine-learning/\n",
       "[5] A Comprehensive Overview and Comparative Analysis on Deep, https://arxiv.org/pdf/2305.17473\n",
       "[6] Classic and Adaptive machines - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/classic-and-adaptive-machines/\n",
       "[7] Classical Machine Learning vs. Generative AI: Key Differences, https://clarkstonconsulting.com/insights/machine-learning-vs-generative-ai/\n",
       "[8] Machine Learning and Deep Learning: A Comparative Review, https://link.springer.com/chapter/10.1007/978-981-33-6307-6_15\n",
       "[9] Machine Learning Theory and Applications: Hands-on Use Cases with ..., https://ieeexplore.ieee.org/book/10444091\n",
       "[10] A Comprehensive Analysis of Classical Machine Learning and Modern Deep ..., https://www.ijert.org/research/a-comprehensive-analysis-of-classical-machine-learning-and-modern-deep-learning-methodologies-IJERTV13IS050275.pdf\n",
       "[11] Hardware Requirements for Machine Learning - GeeksforGeeks, https://www.geeksforgeeks.org/machine-learning/hardware-requirements-for-machine-learning/\n",
       "[12] Hardware Recommendations for Machine Learning / AI | Puget Systems, https://www.pugetsystems.com/solutions/ai-and-hpc-workstations/machine-learning-ai/hardware-recommendations/\n",
       "[13] Hardware Requirements for Artificial Intelligence - SabrePC, https://www.sabrepc.com/blog/Deep-Learning-and-AI/hardware-requirements-for-artificial-intelligence\n",
       "[14] Advantages and Disadvantages of Deep Learning - GeeksforGeeks, https://www.geeksforgeeks.org/deep-learning/advantages-and-disadvantages-of-deep-learning/\n",
       "[15] The Challenges of Machine Learning: A Critical Review - MDPI, https://www.mdpi.com/2079-9292/13/2/416\n",
       "[16] AI Hardware Requirements: A Comprehensive Guide - Cherry Servers, https://www.cherryservers.com/blog/ai-hardware-requirements\n",
       "[17] System Requirements for Deep Learning in 2025, https://www.proxpc.com/blogs/system-requirements-for-deep-learning-in-2025\n",
       "[18] Deep learning modelling techniques: current progress, applications ..., https://link.springer.com/article/10.1007/s10462-023-10466-8\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(final_report.research_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ban3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
