{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Research with Bing Search**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow that leverages Azure AI services to conduct comprehensive web-based research on any topic. The workflow includes:\n",
    "\n",
    "1. **Research Planning** - Breaking down complex queries into structured subtopics and targeted search queries\n",
    "2. **Information Retrieval** - Using Bing Search API through Azure AI Services to gather relevant web content\n",
    "3. **Content Analysis** - Summarizing search results and extracting key insights \n",
    "4. **Report Generation** - Creating detailed research reports with proper citations\n",
    "5. **Peer Review** - Evaluating report quality and suggesting improvements until quality standards are met\n",
    "\n",
    "The notebook orchestrates multiple specialized AI agents working together:\n",
    "- PlannerAgent - Creates comprehensive research plans with subtopics and queries\n",
    "- BingSearchAgent - Retrieves relevant search results from the web\n",
    "- SummaryAgent - Extracts key insights from retrieved content\n",
    "- ResearchAgent - Compiles findings into structured research reports\n",
    "- PeerReviewAgent - Provides quality feedback in a continuous improvement loop\n",
    "\n",
    "Built with Azure OpenAI, Azure AI Projects, and the OpenAI Agents SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we'll set up our environment by importing necessary libraries and loading environment variables from a .env file. These environment variables contain configuration details such as API keys and endpoints for the Azure OpenAI and Bing Search services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "The research workflow is powered by Azure AI Agents, with Semantic Kernel serving as the orchestration framework to coordinate between different specialized agents.\n",
    "\n",
    "All agents are created using Azure AI Projects and are orchestrated through Semantic Kernel to handle various research tasks including web search capabilities and specialized analysis.\n",
    "\n",
    "Let's configure each agent with their specific instructions and capabilities using the Semantic Kernel framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Foundry Connections\n",
    "\n",
    "First, we'll establish connections to Azure AI Projects, which provides the infrastructure for our Bing Search agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.getenv(\"PROJECT_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will **create the Azure AI Agents**, so you only need to run this cell **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common.create_azure_ai_agents import (\n",
    "#     create_bing_search_agent,\n",
    "#     create_research_plan_agent,\n",
    "#     create_summary_agent,\n",
    "#     create_research_report_agent,\n",
    "#     create_peer_review_agent\n",
    "# )\n",
    "\n",
    "# planner_agent = create_research_plan_agent(project_client=project_client)\n",
    "# bing_search_agent = create_bing_search_agent(project_client=project_client)\n",
    "# summary_agent = create_summary_agent(project_client=project_client)\n",
    "# research_agent = create_research_report_agent(project_client=project_client)\n",
    "# peer_review_agent = create_peer_review_agent(project_client=project_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch agents from Ai Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PlannerAgentID\"))\n",
    "bing_search_agent = project_client.agents.get_agent(agent_id=os.getenv(\"BingSearchAgentID\"))\n",
    "summary_agent = project_client.agents.get_agent(agent_id=os.getenv(\"SummaryAgentID\"))\n",
    "research_agent = project_client.agents.get_agent(agent_id=os.getenv(\"ResearchAgentID\"))\n",
    "peer_review_agent = project_client.agents.get_agent(agent_id=os.getenv(\"PeerReviewAgentID\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update their system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.update_instructions import (\n",
    "    update_planner_instructions,\n",
    "    update_bing_instructions,\n",
    "    update_summary_instructions,\n",
    "    update_research_instructions,\n",
    "    update_peer_review_instructions\n",
    ")\n",
    "\n",
    "planner_agent = update_planner_instructions(agent=planner_agent)\n",
    "bing_search_agent = update_bing_instructions(agent=bing_search_agent)\n",
    "summary_agent = update_summary_instructions(agent=summary_agent)\n",
    "research_agent = update_research_instructions(agent=research_agent)\n",
    "peer_review_agent = update_peer_review_instructions(agent=peer_review_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow\n",
    "\n",
    "Our system uses specialized AI agents to transform a user query into a comprehensive research report through these steps:\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "1. **User Query** → User submits research topic or question\n",
    "2. **Planning** → PlannerAgent develops structured research plan with objectives and subtopics\n",
    "3. **Information Retrieval** → BingSearchAgent executes targeted web searches for each area\n",
    "4. **Analysis** → SummaryAgent processes results, extracting key insights while preserving technical details\n",
    "5. **Synthesis** → ResearchAgent creates well-structured report with proper citations\n",
    "6. **Quality Control** → PeerReviewAgent evaluates report for completeness, clarity, and evidence\n",
    "7. **Revision** → If needed, research report undergoes improvement cycles based on feedback\n",
    "8. **Delivery** → Final comprehensive, high-quality report delivered to user\n",
    "\n",
    "This collaborative approach combines the strengths of different specialized agents to produce thorough, evidence-based research that meets predefined quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: edge labels with splines=curved not supported in dot - use xlabels\n",
      "Warning: gvrender_set_style: unsupported style curved - ignoring\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1584pt\" height=\"183pt\"\n",
       " viewBox=\"0.00 0.00 1584.00 182.68\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.790802 0.790802) rotate(0) translate(4 227)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-227 1999.03,-227 1999.03,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<path fill=\"white\" stroke=\"#ff9999\" stroke-width=\"1.5\" stroke-dasharray=\"5,2\" d=\"M1090.29,-8C1090.29,-8 1746.54,-8 1746.54,-8 1752.54,-8 1758.54,-14 1758.54,-20 1758.54,-20 1758.54,-203 1758.54,-203 1758.54,-209 1752.54,-215 1746.54,-215 1746.54,-215 1090.29,-215 1090.29,-215 1084.29,-215 1078.29,-209 1078.29,-203 1078.29,-203 1078.29,-20 1078.29,-20 1078.29,-14 1084.29,-8 1090.29,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"1418.42\" y=\"-199.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#666666\">Iterative Improvement Loop</text>\n",
       "</g>\n",
       "<!-- user -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>user</title>\n",
       "<ellipse fill=\"#d6e9f8\" stroke=\"#4472c4\" cx=\"54.27\" cy=\"-74\" rx=\"54.27\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">User Query</text>\n",
       "<text text-anchor=\"middle\" x=\"54.27\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Input</text>\n",
       "</g>\n",
       "<!-- planner -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>planner</title>\n",
       "<path fill=\"#cce5ff\" stroke=\"#4472c4\" d=\"M335.04,-92.25C335.04,-92.25 240.29,-92.25 240.29,-92.25 234.29,-92.25 228.29,-86.25 228.29,-80.25 228.29,-80.25 228.29,-67.75 228.29,-67.75 228.29,-61.75 234.29,-55.75 240.29,-55.75 240.29,-55.75 335.04,-55.75 335.04,-55.75 341.04,-55.75 347.04,-61.75 347.04,-67.75 347.04,-67.75 347.04,-80.25 347.04,-80.25 347.04,-86.25 341.04,-92.25 335.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PlannerAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"287.67\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Research Planning</text>\n",
       "</g>\n",
       "<!-- user&#45;&gt;planner -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>user&#45;&gt;planner</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.86,-72.6C133.43,-72.24 159.62,-72.4 216.49,-73.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.32,-76.59 226.37,-73.22 216.41,-69.59 216.32,-76.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.42\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query</text>\n",
       "</g>\n",
       "<!-- search -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>search</title>\n",
       "<path fill=\"#ffeecc\" stroke=\"#4472c4\" d=\"M599.04,-92.25C599.04,-92.25 469.04,-92.25 469.04,-92.25 463.04,-92.25 457.04,-86.25 457.04,-80.25 457.04,-80.25 457.04,-67.75 457.04,-67.75 457.04,-61.75 463.04,-55.75 469.04,-55.75 469.04,-55.75 599.04,-55.75 599.04,-55.75 605.04,-55.75 611.04,-61.75 611.04,-67.75 611.04,-67.75 611.04,-80.25 611.04,-80.25 611.04,-86.25 605.04,-92.25 599.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">BingSearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"534.04\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Web Information Retrieval</text>\n",
       "</g>\n",
       "<!-- planner&#45;&gt;search -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>planner&#45;&gt;search</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.46,-71.88C370.78,-71.43 396.13,-71.62 445.49,-72.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"445.18,-75.92 455.23,-72.59 445.29,-68.92 445.18,-75.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"402.04\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Plan</text>\n",
       "</g>\n",
       "<!-- summary -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>summary</title>\n",
       "<path fill=\"#e6ffe6\" stroke=\"#4472c4\" d=\"M926.04,-92.25C926.04,-92.25 748.79,-92.25 748.79,-92.25 742.79,-92.25 736.79,-86.25 736.79,-80.25 736.79,-80.25 736.79,-67.75 736.79,-67.75 736.79,-61.75 742.79,-55.75 748.79,-55.75 748.79,-55.75 926.04,-55.75 926.04,-55.75 932.04,-55.75 938.04,-61.75 938.04,-67.75 938.04,-67.75 938.04,-80.25 938.04,-80.25 938.04,-86.25 932.04,-92.25 926.04,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">SummaryAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"837.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Content Analysis &amp; Summarization</text>\n",
       "</g>\n",
       "<!-- search&#45;&gt;summary -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>search&#45;&gt;summary</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M611.28,-69C638.59,-68.14 669.02,-68.56 725.16,-70.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.73,-73.76 734.83,-70.57 724.94,-66.76 724.73,-73.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"673.92\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Results</text>\n",
       "</g>\n",
       "<!-- research -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>research</title>\n",
       "<path fill=\"#e0eaff\" stroke=\"#4472c4\" d=\"M1188.54,-92.25C1188.54,-92.25 1098.29,-92.25 1098.29,-92.25 1092.29,-92.25 1086.29,-86.25 1086.29,-80.25 1086.29,-80.25 1086.29,-67.75 1086.29,-67.75 1086.29,-61.75 1092.29,-55.75 1098.29,-55.75 1098.29,-55.75 1188.54,-55.75 1188.54,-55.75 1194.54,-55.75 1200.54,-61.75 1200.54,-67.75 1200.54,-67.75 1200.54,-80.25 1200.54,-80.25 1200.54,-86.25 1194.54,-92.25 1188.54,-92.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">ResearchAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1143.42\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report Generation</text>\n",
       "</g>\n",
       "<!-- summary&#45;&gt;research -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>summary&#45;&gt;research</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M881.86,-55.34C964.88,-21.4 990.44,-20.14 1081.1,-51.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.86,-54.82 1090.45,-54.83 1082.17,-48.22 1079.86,-54.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"1012.17\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Summaries</text>\n",
       "</g>\n",
       "<!-- review -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>review</title>\n",
       "<path fill=\"#ffe6e6\" stroke=\"#4472c4\" d=\"M1416.54,-52.25C1416.54,-52.25 1327.04,-52.25 1327.04,-52.25 1321.04,-52.25 1315.04,-46.25 1315.04,-40.25 1315.04,-40.25 1315.04,-27.75 1315.04,-27.75 1315.04,-21.75 1321.04,-15.75 1327.04,-15.75 1327.04,-15.75 1416.54,-15.75 1416.54,-15.75 1422.54,-15.75 1428.54,-21.75 1428.54,-27.75 1428.54,-27.75 1428.54,-40.25 1428.54,-40.25 1428.54,-46.25 1422.54,-52.25 1416.54,-52.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-36.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">PeerReviewAgent</text>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-22.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Quality Evaluation</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;review -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>research&#45;&gt;review</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1200.81,-63.21C1253.32,-53.35 1281.27,-48.19 1303.85,-44.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1304.14,-47.88 1313.43,-42.79 1302.99,-40.97 1304.14,-47.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"1257.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Draft</text>\n",
       "</g>\n",
       "<!-- decision -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>decision</title>\n",
       "<path fill=\"#fff2cc\" stroke=\"#4472c4\" d=\"M1650.69,-105.94C1650.69,-105.94 1584.14,-78.56 1584.14,-78.56 1578.59,-76.28 1578.59,-71.72 1584.14,-69.44 1584.14,-69.44 1650.69,-42.06 1650.69,-42.06 1656.24,-39.78 1667.34,-39.78 1672.89,-42.06 1672.89,-42.06 1739.44,-69.44 1739.44,-69.44 1744.99,-71.72 1744.99,-76.28 1739.44,-78.56 1739.44,-78.56 1672.89,-105.94 1672.89,-105.94 1667.34,-108.22 1656.24,-108.22 1650.69,-105.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Meets Quality</text>\n",
       "<text text-anchor=\"middle\" x=\"1661.79\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Standards?</text>\n",
       "</g>\n",
       "<!-- research&#45;&gt;decision -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>research&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"#ff9999\" d=\"M1211.83,-72.2C1443.6,-66.13 1499.16,-65.21 1583.06,-69.43\"/>\n",
       "<polygon fill=\"#ff9999\" stroke=\"#ff9999\" points=\"1212.08,-68.69 1202.17,-72.45 1212.26,-75.69 1212.08,-68.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"1371.79\" y=\"-171.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">No</text>\n",
       "</g>\n",
       "<!-- review&#45;&gt;decision -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>review&#45;&gt;decision</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.68,-37.82C1526.04,-44.45 1562.55,-47.76 1598.61,-56.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1597.31,-59.39 1607.86,-58.37 1598.98,-52.59 1597.31,-59.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"1500.79\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Evaluation</text>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>report</title>\n",
       "<ellipse fill=\"#d5f5d5\" stroke=\"#4472c4\" cx=\"1925.91\" cy=\"-74\" rx=\"69.12\" ry=\"25.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-76.85\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Final Research</text>\n",
       "<text text-anchor=\"middle\" x=\"1925.91\" y=\"-62.6\" font-family=\"Helvetica,sans-Serif\" font-size=\"12.00\" fill=\"#333333\">Report</text>\n",
       "</g>\n",
       "<!-- decision&#45;&gt;report -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>decision&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1748.73,-72.86C1794.97,-72.28 1822.55,-72.05 1845.08,-72.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1844.92,-75.66 1854.95,-72.24 1844.98,-68.66 1844.92,-75.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"1803.67\" y=\"-77.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Yes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x220528f71f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.helper import create_research_workflow_diagram\n",
    "\n",
    "# This will generate research_workflow_diagram.png and return the Digraph object\n",
    "workflow_diagram = create_research_workflow_diagram()\n",
    "workflow_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a sample research query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_query=\"What big industries will AI have the most affected on?\"\n",
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Research Planning\n",
    "\n",
    "The PlannerAgent analyzes the research query and creates a structured plan with:\n",
    "\n",
    "- Research objective - A clear statement of what the research aims to accomplish\n",
    "- Subtopics - Key areas to explore for comprehensive coverage\n",
    "- Search queries - Specific queries for each subtopic to gather relevant information\n",
    "- Success criteria - Metrics to determine research completeness\n",
    "- Related topics - Additional areas that may provide valuable context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.agents.models import MessageRole\n",
    "from common.data_models import ResearchPlan\n",
    "from common.utils_ai_agents import (\n",
    "    add_user_message_to_thread,\n",
    "    invoke_agent\n",
    ")\n",
    "import json\n",
    "\n",
    "# create a thread and add the user message\n",
    "thread = project_client.agents.threads.create()\n",
    "add_user_message_to_thread(project_client, thread.id, user_query)\n",
    "\n",
    "# invoke the planner agent to create a research plan\n",
    "planner_agent_output, thread = invoke_agent(\n",
    "    project_client=project_client,\n",
    "    thread=thread,\n",
    "    agent=planner_agent\n",
    ")\n",
    "\n",
    "# parse the output to a ResearchPlan object\n",
    "plan_data = json.loads(planner_agent_output)\n",
    "plan = ResearchPlan(**plan_data)\n",
    "\n",
    "# delete the thread\n",
    "project_client.agents.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['definition of classical machine learning',\n",
       " 'what is deep learning in AI',\n",
       " 'generative AI definition and explanation',\n",
       " 'core concepts of classical machine learning vs deep learning vs generative AI',\n",
       " 'overview of machine learning paradigms']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.research_tasks[0].search_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Information Retrieval\n",
    "\n",
    "The BingSearchAgent executes web searches for each query in our research plan. For each subtopic:\n",
    "\n",
    "1. We send multiple search queries to gather diverse perspectives\n",
    "2. The agent returns structured search results with titles, full_text, and URLs\n",
    "3. Results are organized by subtopic for further processing\n",
    "\n",
    "This step leverages Azure AI Projects with Bing Search integration to ensure up-to-date information from across the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subtopics: 100%|██████████| 5/5 [04:13<00:00, 50.68s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from common.utils_search import extract_agent_response_and_urls\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for subtopic in tqdm(plan.research_tasks, desc=\"Subtopics\"):\n",
    "    subtopic_results = {\"subtopic\": subtopic.subtopic, \"queries\": []}\n",
    "\n",
    "    for query in tqdm(subtopic.search_queries, desc=f\"Queries ({subtopic.subtopic})\", leave=False):\n",
    "        formatted_query = f\"\"\"\n",
    "        Research the following query: {query}\n",
    "        This is related to subtopic: {subtopic.subtopic}\n",
    "        Please provide the information and cite your sources using the available tools.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, formatted_query)\n",
    "\n",
    "            bing_search_agent_output, thread = invoke_agent(\n",
    "                project_client=project_client,\n",
    "                thread=thread,\n",
    "                agent=bing_search_agent\n",
    "            )\n",
    "\n",
    "            agent_response_text, extracted_urls = extract_agent_response_and_urls(project_client, thread.id, query)\n",
    "\n",
    "            # Add to our results collection\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"agent_response\": agent_response_text,\n",
    "                \"results\": extracted_urls\n",
    "            })\n",
    "\n",
    "            # Delete the thread after processing\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing query '{query}': {e}\")\n",
    "            # Optionally add error information to results\n",
    "            subtopic_results[\"queries\"].append({\n",
    "                \"query\": query,\n",
    "                \"results\": [],\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    search_results.append(subtopic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned total search queries: 25\n",
      "\n",
      "Actually total search queries: 25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Planned total search queries: {sum(1 for task in plan.research_tasks for search_query in task.search_queries)}\\n\")\n",
    "print(f\"Actually total search queries: {sum(1 for task in search_results for result in task['queries'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Content Analysis and Summarization\n",
    "\n",
    "For each search result retrieved, the SummaryAgent:\n",
    "\n",
    "1. Extracts key facts, statistics, and insights from the raw search content\n",
    "2. Preserves important technical details, dates, and domain-specific terminology\n",
    "3. Formats the summary with key insights and detailed paragraph explanations\n",
    "4. Tracks citations for proper attribution in the final report\n",
    "\n",
    "This step transforms raw search data into structured, information-rich summaries that will form the basis of our research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing subtopics: 100%|██████████| 5/5 [01:31<00:00, 18.29s/it]\n"
     ]
    }
   ],
   "source": [
    "from common.utils_summary import collect_responses_and_citations\n",
    "\n",
    "mapped_chunks = []\n",
    "\n",
    "for subtopic_result in tqdm(search_results, desc=\"Summarizing subtopics\"):\n",
    "    all_agent_responses_for_subtopic, unique_citations_for_subtopic = collect_responses_and_citations(subtopic_result)\n",
    "\n",
    "    # --- Summarize the combined agent responses ONCE per subtopic ---\n",
    "    content_to_summarize = \"\\n\\n---\\n\\n\".join(all_agent_responses_for_subtopic)\n",
    "\n",
    "    subtopic_summary = \"No content found to summarize for this subtopic.\" # Default value\n",
    "    if content_to_summarize:\n",
    "        summary_prompt = f\"Summarize the following information related to the subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}':\\n\\n{content_to_summarize}\"\n",
    "        try:\n",
    "            thread = project_client.agents.threads.create()\n",
    "            add_user_message_to_thread(project_client, thread.id, summary_prompt)\n",
    "            # Invoke the summary agent to summarize the content\n",
    "            summary_agent_output, thread = invoke_agent(\n",
    "                project_client=project_client,\n",
    "                thread=thread,\n",
    "                agent=summary_agent\n",
    "            )\n",
    "\n",
    "            # run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=summary_agent.id)\n",
    "            # subtopic_summary = get_last_message_by_role(project_client, thread.id, MessageRole.AGENT)\n",
    "            subtopic_summary = summary_agent_output.strip()  # Ensure we get the text output\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}': {e}\")\n",
    "            subtopic_summary = f\"Error during summarization for subtopic '{subtopic_result.get('subtopic', 'Unknown Subtopic')}'. Details: {e}\"\n",
    "            # Depending on requirements, you might want to raise the exception, log it, or handle it differently\n",
    "\n",
    "    # --- Convert set of tuples back to list of dictionaries (or Citation objects) ---\n",
    "    citations_list = [\n",
    "        {\"title\": title, \"url\": url}\n",
    "        for title, url in unique_citations_for_subtopic\n",
    "    ]\n",
    "\n",
    "    # --- Append the consolidated result ---\n",
    "    mapped_chunks.append({\n",
    "        \"subtopic\": subtopic_result.get(\"subtopic\", \"Unknown Subtopic\"), # Use .get for safety\n",
    "        \"summary\": subtopic_summary,\n",
    "        \"citations\": citations_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Generation and Peer Review\n",
    "\n",
    "In this final stage:\n",
    "\n",
    "1. The ResearchAgent synthesizes all summarized content into a comprehensive report\n",
    "2. The PeerReviewAgent evaluates the report based on completeness, clarity, evidence, and insight\n",
    "3. If needed, the report is revised based on feedback\n",
    "4. This cycle continues until quality standards are met\n",
    "\n",
    "The final report is structured as a cohesive academic-style document with proper citations and a references section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.data_models import ComprehensiveResearchReport, PeerReviewFeedback\n",
    "from common.utils_ai_agents import add_user_message_to_thread\n",
    "\n",
    "def loop_agents(project_client, agent_a, agent_b, initial_input, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Loop between two agents until agent B produces the target output.\n",
    "    \n",
    "    Args:\n",
    "        agent_a: Function that takes input and returns output\n",
    "        agent_b: Function that takes input and returns output\n",
    "        initial_input: Starting input for agent A\n",
    "        max_iterations: Safety limit to prevent infinite loops\n",
    "    \n",
    "    Returns:\n",
    "        The final output from agent B, or None if max iterations reached\n",
    "    \"\"\"\n",
    "\n",
    "    thread = project_client.agents.threads.create()\n",
    "    add_user_message_to_thread(project_client, thread.id, initial_input)\n",
    "\n",
    "    for it in range(max_iterations):        \n",
    "        # Agent A processes the input\n",
    "        a_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_a\n",
    "        )\n",
    "        \n",
    "        # Agent B processes A's output\n",
    "        b_output, thread = invoke_agent(\n",
    "            project_client=project_client,\n",
    "            thread=thread,\n",
    "            agent=agent_b\n",
    "        )\n",
    "\n",
    "        b_output_json = json.loads(b_output)\n",
    "        review = PeerReviewFeedback(**b_output_json)\n",
    "\n",
    "        # Check if B produced the target output\n",
    "        if review.is_satisfactory is not False:\n",
    "            print(f\"Target output reached after {it+1} iterations!\")\n",
    "            report_json = json.loads(a_output)\n",
    "            final_report = ComprehensiveResearchReport(**report_json)\n",
    "\n",
    "            # delete the thread\n",
    "            project_client.agents.threads.delete(thread_id=thread.id)\n",
    "            return final_report\n",
    "        \n",
    "        # Use B's output as input for the next iteration\n",
    "        current_input = b_output\n",
    "\n",
    "    print(f\"Max iterations ({max_iterations}) reached without finding target output\") \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target output reached after 1 iterations!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from common.utils_research import preprocess_research_data\n",
    "\n",
    "research_input = preprocess_research_data(plan, mapped_chunks)\n",
    "research_input_prompt = json.dumps(research_input, indent=2)\n",
    "\n",
    "research_query = (\n",
    "    \"Create an exceptionally comprehensive, **paragraph-focused** and detailed research report \"\n",
    "    \"using the following content. **Minimize bullet points** and ensure the final text resembles \"\n",
    "    \"a cohesive, academic-style paper:\\n\\n\"\n",
    "    f\"{research_input_prompt}\\n\\n\"\n",
    "    \"As a final reminder, don't forget to include the citation list at the end of the report.\"\n",
    ")\n",
    "\n",
    "# Run the loop\n",
    "final_report = loop_agents(\n",
    "    project_client=project_client,\n",
    "    agent_a=research_agent,\n",
    "    agent_b=peer_review_agent,\n",
    "    initial_input=research_query,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# A Comprehensive Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Definitions, Methodologies, Applications, and Future Directions\n",
       "\n",
       "## Introduction\n",
       "\n",
       "The field of artificial intelligence (AI) has undergone a remarkable transformation over the past several decades, evolving from early rule-based systems to sophisticated models capable of autonomous learning, perception, and even creative content generation. Central to this evolution are three major paradigms: classical machine learning, deep learning, and generative AI. Each of these approaches is defined by distinct theoretical foundations, methodological choices, and practical applications. As AI becomes increasingly embedded in the fabric of modern society—powering everything from medical diagnostics to autonomous vehicles and creative design—the need for a nuanced understanding of these paradigms, their differences, and their respective strengths and limitations has never been greater.\n",
       "\n",
       "This report provides an authoritative, in-depth analysis of classical machine learning, deep learning, and generative AI. It begins by establishing clear definitions and core concepts, then delves into the methodologies and algorithms that underpin each approach. The discussion proceeds to a thorough examination of real-world applications and use cases, followed by a critical assessment of the strengths, limitations, and challenges unique to each paradigm. Finally, the report situates these technologies within their historical context and explores emerging trends that are likely to shape the future of AI. Throughout, the analysis is supported by quantitative data, comparative insights, and references to credible academic and industry sources.\n",
       "\n",
       "## 1. Definitions and Core Concepts\n",
       "\n",
       "The landscape of AI and machine learning is anchored in foundational definitions and conceptual frameworks that delineate the primary approaches for enabling machines to learn from data. At its core, machine learning (ML) is a subset of AI focused on developing algorithms that allow computers to identify patterns and make predictions or decisions based on data. Within this broad domain, classical machine learning, deep learning, and generative AI represent progressively more complex and capable methodologies, each with its own defining characteristics.\n",
       "\n",
       "### 1.1 Classical Machine Learning\n",
       "\n",
       "Classical machine learning refers to a suite of statistical and algorithmic techniques designed to extract patterns from structured data—datasets organized in rows and columns, where features are explicitly defined. The hallmark of classical ML is its reliance on manual feature engineering, a process in which domain experts identify and select the most relevant variables for analysis. Common algorithms include linear regression, logistic regression, decision trees, support vector machines (SVM), k-nearest neighbors (KNN), and naive Bayes classifiers. These models are typically favored for their interpretability, computational efficiency, and effectiveness on small to medium-sized datasets. Classical ML excels in tasks such as classification (assigning categories), regression (predicting continuous values), clustering (grouping similar data points), and anomaly detection (identifying outliers) [1][2][3].\n",
       "\n",
       "### 1.2 Deep Learning\n",
       "\n",
       "Deep learning is a specialized branch of machine learning that leverages artificial neural networks (ANNs) with multiple layers—hence the term \"deep\"—to automatically learn hierarchical representations from data. Inspired by the structure and function of the human brain, deep learning models consist of interconnected layers of artificial neurons that process information through weighted connections. Unlike classical ML, deep learning obviates the need for manual feature engineering; instead, it autonomously discovers salient features directly from raw, unstructured data such as images, audio, and text. Training is typically accomplished via backpropagation, an iterative process that adjusts network weights to minimize prediction errors. Deep learning's success is closely tied to the availability of large, labeled datasets and significant computational resources, enabling breakthroughs in fields like computer vision, natural language processing, and speech recognition [2][3][4][5].\n",
       "\n",
       "### 1.3 Generative AI\n",
       "\n",
       "Generative AI stands at the intersection of deep learning and creative content generation. It encompasses a class of models designed to produce new, original data by learning the underlying patterns and distributions present in existing datasets. The technological foundations of generative AI are advanced deep learning architectures such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Large Language Models (LLMs) like GPT. These models are capable of synthesizing realistic images, coherent text, music, and even code by sampling from learned data distributions. Generative AI is revolutionizing industries by enabling tasks such as data augmentation, creative content synthesis, simulation, and more [1][4][5][6].\n",
       "\n",
       "### 1.4 Learning Paradigms and Fundamental Concepts\n",
       "\n",
       "Underlying all these approaches are various machine learning paradigms that define how algorithms interact with data:\n",
       "\n",
       "- **Supervised Learning:** Models learn to map inputs to outputs using labeled datasets. Examples include image classification and sales forecasting.\n",
       "- **Unsupervised Learning:** Models identify patterns or groupings in unlabeled data, as seen in clustering and dimensionality reduction.\n",
       "- **Semi-Supervised Learning:** Combines a small amount of labeled data with a large pool of unlabeled data to improve learning accuracy.\n",
       "- **Reinforcement Learning:** Agents learn optimal actions through trial-and-error interactions with an environment, guided by rewards and penalties.\n",
       "- **Self-Supervised Learning:** Models generate their own supervisory signals from the data, a technique gaining traction in natural language and computer vision.\n",
       "- **Transfer Learning:** Models trained on one task are adapted to perform related tasks, enhancing efficiency when data is scarce.\n",
       "\n",
       "Other core concepts traverse these paradigms, including models (algorithmic structures for prediction), features (input variables), labels (ground truth targets), loss functions (measuring prediction error), training (the process of learning from data), and generalization (the ability to perform well on unseen data) [3][4][7].\n",
       "\n",
       "In summary, the definitions and core concepts of classical machine learning, deep learning, and generative AI reflect a continuum of increasing model complexity, automation, and capability. Each paradigm offers distinct advantages for different data types, tasks, and industrial requirements, forming the backbone of contemporary AI advancement.\n",
       "\n",
       "## 2. Methodologies and Algorithms\n",
       "\n",
       "The methodologies and algorithms that underpin classical machine learning, deep learning, and generative AI are the engines driving modern artificial intelligence. While these paradigms share foundational roots, they diverge significantly in their technical strategies, data requirements, and problem-solving approaches.\n",
       "\n",
       "### 2.1 Classical Machine Learning Methodologies and Algorithms\n",
       "\n",
       "Classical machine learning methodologies are characterized by their focus on structured, tabular data and their reliance on interpretable, resource-efficient models. The process typically begins with manual feature engineering, where domain expertise is used to extract and select relevant input features. The most prominent algorithms include:\n",
       "\n",
       "- **Linear Regression:** Used for predicting continuous outcomes, fitting a linear equation to minimize squared error.\n",
       "- **Logistic Regression:** Applied to binary classification tasks, modeling the probability of class membership using the logistic function.\n",
       "- **Decision Trees:** Hierarchical models that split data based on feature values, suitable for both classification and regression.\n",
       "- **Random Forests:** Ensembles of decision trees that improve robustness and reduce overfitting by averaging multiple tree predictions.\n",
       "- **Support Vector Machines (SVM):** Optimization-based models that find the maximum margin hyperplane separating classes, supporting both linear and non-linear boundaries via kernel tricks.\n",
       "- **k-Nearest Neighbors (k-NN):** Non-parametric classifiers that assign labels based on the majority vote of nearest neighbors in feature space.\n",
       "- **Naive Bayes:** Probabilistic classifiers leveraging Bayes’ theorem, assuming feature independence.\n",
       "- **Gradient Boosting Machines (GBM):** Sequentially adds models to correct predecessor errors, optimizing loss functions via gradient descent.\n",
       "- **Principal Component Analysis (PCA):** Unsupervised dimensionality reduction technique that projects data into lower-dimensional spaces while preserving variance.\n",
       "- **Clustering (e.g., k-Means):** Unsupervised grouping of data points by similarity.\n",
       "\n",
       "These algorithms are particularly effective for small to moderate-sized datasets and are preferred when model interpretability is crucial. They are widely used as baselines or starting points in domains such as finance, healthcare, and marketing [2][3][7].\n",
       "\n",
       "### 2.2 Deep Learning Methodologies and Algorithms\n",
       "\n",
       "Deep learning methodologies build on neural network architectures with multiple computational layers, enabling the discovery of intricate patterns in unstructured data. The defining feature of deep learning is hierarchical feature learning, where features are learned directly from data rather than manually engineered. Key architectures include:\n",
       "\n",
       "- **Feedforward Neural Networks (FNNs):** The simplest deep models, processing inputs in a single direction through fully connected layers.\n",
       "- **Convolutional Neural Networks (CNNs):** Designed for grid-structured data such as images, employing convolutional and pooling layers to extract spatial features.\n",
       "- **Recurrent Neural Networks (RNNs), LSTMs, GRUs:** Suited for sequential data like speech and text, maintaining temporal context through loops and advanced memory mechanisms.\n",
       "- **Transformers:** Utilize self-attention mechanisms to process sequences in parallel, capturing global relationships between input elements. Architectures like BERT and GPT have set new benchmarks in natural language processing.\n",
       "- **Autoencoders:** Encoder-decoder networks used for non-linear dimensionality reduction and feature learning.\n",
       "- **Generative Adversarial Networks (GANs):** Consist of generator and discriminator networks engaged in adversarial training, foundational for generative AI.\n",
       "\n",
       "Training deep networks involves algorithms such as backpropagation for gradient computation, dropout for regularization, batch normalization for stabilizing learning, and transfer learning for adapting pre-trained models to new tasks. Attention mechanisms further enhance sequence-to-sequence models by focusing processing on relevant input segments [3][4][8].\n",
       "\n",
       "Deep learning’s automatic feature discovery and scalability make it indispensable for end-to-end learning in complex, data-rich environments. However, these strengths are counterbalanced by increased opacity, higher computational demands, and a dependency on large labeled datasets.\n",
       "\n",
       "### 2.3 Generative AI Methodologies and Algorithms\n",
       "\n",
       "Generative AI methodologies are centered on learning the underlying data distribution to produce new, synthetic data samples. The most advanced generative models are built upon deep learning architectures and employ probabilistic modeling and adversarial training. Key algorithms include:\n",
       "\n",
       "- **Generative Adversarial Networks (GANs):** Implement a minimax game between a generator (producing synthetic data) and a discriminator (distinguishing real from fake data), resulting in highly realistic outputs.\n",
       "- **Variational Autoencoders (VAEs):** Probabilistic models that encode data into a latent space and decode it back, enabling the sampling of new data points.\n",
       "- **Transformer-based Models (LLMs):** Large Language Models like GPT and BERT, powered by transformer architectures, excel at generating coherent language and other modalities.\n",
       "- **Diffusion Models:** Stochastic processes that iteratively denoise random noise into sample data, achieving impressive results in image generation.\n",
       "- **Agentic Retrieval:** An emerging methodology that combines conversation history, external data retrieval, and planning by LLMs to provide context-aware, factually grounded responses [9][10][11].\n",
       "\n",
       "These methods often involve learning joint or marginal probability distributions and employ complex optimization techniques, including adversarial (game-theoretic) and probabilistic training. The result is a class of models capable of generating high-fidelity content that closely mimics real-world data [4][5][6].\n",
       "\n",
       "### 2.4 Comparative Methodological Synthesis\n",
       "\n",
       "While classical ML, deep learning, and generative AI share a common lineage, their methodological choices reflect divergent priorities and technical requirements. Classical ML prioritizes interpretability and efficiency, deep learning emphasizes scalability and automatic feature extraction, and generative AI focuses on creative synthesis and probabilistic modeling. The choice of methodology is thus tightly coupled with the problem domain, data type, desired output, and operational constraints. As the field advances, hybrid models and innovative retrieval-augmented generation techniques are pushing the boundaries of what AI can achieve [9][10].\n",
       "\n",
       "## 3. Applications and Use Cases\n",
       "\n",
       "The practical impact of classical machine learning, deep learning, and generative AI is most evident in their diverse applications across industries. Each paradigm demonstrates unique strengths based on data type, interpretability, computational requirements, and desired outcomes.\n",
       "\n",
       "### 3.1 Classical Machine Learning: Structured Data and Interpretability\n",
       "\n",
       "Classical machine learning algorithms are foundational in real-world data analysis, particularly for structured or tabular datasets. Their mathematical simplicity, computational efficiency, and ease of interpretation make them ideal for tasks where transparency is essential and data scales are modest.\n",
       "\n",
       "In healthcare, classical ML models such as logistic regression are widely used for disease diagnosis and prognosis, leveraging patient records to predict the onset of conditions like diabetes or cardiovascular disease. SVMs and decision trees support medical image analysis by distinguishing between benign and malignant findings using extracted features. In finance and banking, classical ML underpins credit scoring, loan risk assessment, and fraud detection, often using clustering or anomaly detection on transaction data. The interpretability of these models is critical for regulatory compliance and decision justification [12][13].\n",
       "\n",
       "Marketing and customer analytics benefit from techniques like k-means clustering for customer segmentation, while churn prediction and targeted advertising often utilize logistic regression and naive Bayes classifiers. Manufacturing relies on regression models for predictive maintenance and quality control, supporting process optimization and cost reduction. Even in natural language processing, classical models like naive Bayes remain effective for spam detection and basic sentiment analysis [13][14].\n",
       "\n",
       "Despite the rise of more complex systems, classical algorithms retain their relevance due to their robustness on smaller, well-structured datasets and when results must be explainable—traits valuable in healthcare, finance, and regulated industries.\n",
       "\n",
       "### 3.2 Deep Learning: Unstructured Data and Complex Pattern Recognition\n",
       "\n",
       "Deep learning excels in processing unstructured, high-dimensional data such as images, audio, and natural language. Models like convolutional neural networks (CNNs) and recurrent neural networks (RNNs), supported by advances in GPU computing, have enabled transformational applications.\n",
       "\n",
       "In healthcare, deep learning is pivotal for medical imaging diagnostics—CNNs surpass classical methods in tasks like tumor detection in radiology images, providing higher accuracy by automatically learning intricate patterns. The automotive sector leverages deep learning for autonomous driving, where CNNs, LSTMs, and reinforcement learning work together for object detection, environmental perception, and real-time decision-making. Advanced driver-assistance systems (ADAS) similarly benefit from these models to enhance safety [15][16].\n",
       "\n",
       "Finance applies deep learning for high-frequency trading algorithms, complex fraud detection, and personalized financial advisory chatbots. Retail and e-commerce use deep neural networks for personalized product recommendations, demand forecasting, visual search, and sentiment analysis from customer reviews. Agricultural technology employs deep learning for crop yield prediction, pest and disease detection, and resource optimization using satellite imagery [17][18].\n",
       "\n",
       "Manufacturing embraces deep learning for automated visual inspection and predictive maintenance, processing multi-modal sensor data to foresee breakdowns. Deep learning is also foundational for advanced technology applications such as speech-to-text in voice assistants, language translation, and image/video recognition platforms vital for content moderation and media tagging [19][20].\n",
       "\n",
       "### 3.3 Generative AI: Automated Creativity and Synthetic Data\n",
       "\n",
       "Generative AI, powered by large language models (LLMs) and advanced architectures like diffusion models and GANs, is reshaping industries by automating content generation and augmenting human creativity. These models synthesize new data that closely mimics real-world examples, going beyond prediction to creation.\n",
       "\n",
       "In content creation, LLMs generate articles, marketing copy, emails, reports, and multimedia content, drastically reducing the time and effort required for design, entertainment, and advertising. AI-based copilots assist in code generation, accelerating software development and reducing manual errors. Healthcare benefits from generative models for drug discovery, synthetic data generation for research privacy, and auto-generating radiology reports or summarizing patient histories [21][22].\n",
       "\n",
       "Marketing and advertising harness generative AI for hyper-personalized campaigns, compelling social media posts, and dynamic product descriptions. Customer service is enhanced by virtual assistants and chatbots that provide real-time, context-aware support. Design and creative industries employ generative tools for ideating product designs, visual concepts, and even generating original artworks and music tracks [23][24].\n",
       "\n",
       "Emerging edge computing and IoT applications deploy generative AI models for real-time inference and privacy-preserving solutions directly on devices, minimizing latency and reducing reliance on centralized cloud infrastructure. For data augmentation and retrieval, generative AI creates synthetic training data to enhance model robustness and employs Retrieval Augmented Generation (RAG) for more effective search and summarization tasks [25].\n",
       "\n",
       "### 3.4 Comparative Nuances and Selection Criteria\n",
       "\n",
       "A comparative view crystallizes the application boundaries: classical machine learning is best suited to smaller, structured datasets and scenarios demanding transparency; deep learning takes precedence for unstructured, high-dimensional data and complex pattern extraction; and generative AI is the technology of choice for content generation, simulation, and augmentation. The selection of an AI approach depends on input data type, scale, interpretability requirements, problem complexity, and whether the core need is prediction/classification or creative synthesis [12][13][16].\n",
       "\n",
       "In summary, while emerging techniques like generative AI are revolutionizing automation and creativity, classical ML and deep learning remain indispensable for structured prediction tasks and complex pattern recognition, respectively. A nuanced understanding of application requirements and technology strengths ensures the optimal approach, maximizing operational impact across sectors.\n",
       "\n",
       "## 4. Strengths, Limitations, and Challenges\n",
       "\n",
       "Each paradigm in the machine learning spectrum offers unique operational strengths and faces domain-specific challenges. Understanding these trade-offs is essential for responsible AI adoption and future research.\n",
       "\n",
       "### 4.1 Classical Machine Learning\n",
       "\n",
       "Classical machine learning models are lauded for their high interpretability, efficiency, and low data requirements. Their transparent nature is crucial in domains like healthcare and finance, where explainability supports regulatory compliance and user trust. These models are computationally efficient and can often be trained quickly, even on small or moderate-sized datasets. Their well-established statistical underpinnings contribute to predictable behavior and reliability in structured data environments [1][2][3].\n",
       "\n",
       "However, classical approaches demand extensive manual feature engineering, relying on domain expertise to transform raw inputs into model-ready formats. This manual process can become a bottleneck as datasets grow in size and complexity. Scalability is a core challenge; classical methods may plateau in performance when confronted with high-dimensional or massive datasets, or when faced with unstructured data such as images or natural language. Their reduced flexibility limits their ability to model complex, nonlinear relationships, and they may be sensitive to outliers or noisy inputs, undermining robustness in real-world applications [3][7].\n",
       "\n",
       "### 4.2 Deep Learning\n",
       "\n",
       "Deep learning has transformed capabilities in handling unstructured data by automating feature extraction and achieving unprecedented accuracy in tasks such as image classification, natural language processing, and speech recognition. Its scalability enables performance gains as dataset sizes and computational power increase. However, these benefits come at the cost of immense data and computing requirements: deep learning models generally require millions of labeled examples and powerful hardware for both training and inference. This resource intensity can be a barrier for smaller organizations or data-scarce domains [4][5][8].\n",
       "\n",
       "Deep learning models are often criticized for their \"black box\" nature, with limited interpretability relative to classical ML. This complicates their adoption in sensitive or regulated applications. They are also prone to overfitting, especially when datasets are unbalanced or not representative, and are susceptible to perpetuating biases found in training data. Robustness issues persist, as adversarial attacks—minor, often imperceptible modifications to input data—can yield drastically incorrect predictions. The substantial energy consumption required for model training and deployment raises environmental sustainability concerns, which are increasingly salient as models scale [8][26].\n",
       "\n",
       "### 4.3 Generative AI\n",
       "\n",
       "Generative AI represents the frontier of machine learning’s creative and augmentative potential, capable of synthesizing novel content and augmenting existing datasets. Its automated feature learning offers versatility in tasks such as summarization, translation, and creative design. However, generative AI also poses formidable risks. The propagation of biases present in training data can yield biased, unfair, or inappropriate outputs, reinforcing stereotypes or systemic inequities. The ease with which convincing synthetic content can be produced propagates misinformation, fraud, and security vulnerabilities [27][28][29].\n",
       "\n",
       "Legal and ethical conundrums arise as models generate outputs that may infringe on intellectual property or disclose sensitive data, challenging current frameworks around content authenticity and copyright. Quality control remains problematic, as generative models occasionally produce nonsensical or inaccurate content, necessitating robust validation and monitoring. The “black box” challenge is even more pronounced in generative systems, intensifying regulatory and compliance headaches. Substantial computational and financial resources are required for both training and deploying these architectures, raising concerns about power consumption and environmental impact. Integration into existing digital infrastructures and measuring the trustworthiness of outputs are further challenges [27][28][29].\n",
       "\n",
       "### 4.4 Comparative Analysis\n",
       "\n",
       "A comparative analysis reveals clear trade-offs: classical ML offers efficiency and transparency on structured data but lacks adaptability; deep learning scales for complexity but at the cost of resource intensity and interpretability; and generative AI unlocks creative, open-ended applications but invites new fronts of ethical concern, security risk, and integration hurdles. Ongoing research aims to bridge the interpretability-resource utility gap, improve robustness and fairness, and develop regulatory standards that match the rapid technological pace [27][28][29].\n",
       "\n",
       "## 5. Historical Evolution and Future Trends\n",
       "\n",
       "The development of machine learning and AI reflects a trajectory spanning over seven decades, with each era characterized by distinct technological and conceptual advances. Understanding this historical context is essential for appreciating current capabilities and anticipating future directions.\n",
       "\n",
       "### 5.1 Historical Evolution\n",
       "\n",
       "#### Early Foundations (1950s–1960s)\n",
       "\n",
       "Machine learning’s origin is rooted in post-war AI research, where scientists explored whether computers could learn from data. Early programs, such as those playing checkers and chess, demonstrated machines improving performance through experience. Statistically inspired methods, notably Bayesian inference, enabled probabilistic learning and decision-making. These theoretical foundations, combined with advances in computer science, set the stage for the field [30][31][32].\n",
       "\n",
       "#### Classical Machine Learning and Growth (1970s–1990s)\n",
       "\n",
       "As computational power improved, the 1970s and 1980s saw the refinement of foundational ML algorithms, including decision trees, single-layer neural networks, and the pioneering backpropagation algorithm. The 1990s witnessed the rise of support vector machines, k-nearest neighbors, and ensemble methods like bagging and boosting. However, these classical models were critically dependent on expert-driven feature engineering [33][34][35].\n",
       "\n",
       "#### The Deep Learning Era (2000s–Present)\n",
       "\n",
       "The 21st century marked a paradigm shift as large-scale digital datasets and GPU acceleration enabled the viable training of deep neural networks. The 2012 introduction of AlexNet, a deep convolutional neural network for image recognition, catalyzed industry-wide adoption of deep learning. Systems like CNNs for vision, RNNs for sequential data, and transformers for language processing advanced the state-of-the-art in numerous domains. The move from manual to automated feature extraction distinguished this era, enabling superior performance on high-dimensional, unstructured tasks [36][37][38].\n",
       "\n",
       "#### Rise of Generative AI (2014–Present)\n",
       "\n",
       "The advent of generative models marked a major leap. GANs in 2014 unlocked the ability of AI systems to synthesize realistic images, sounds, and text. Transformer architectures (e.g., BERT, GPT, DALL-E) in the late 2010s further pushed AI’s creative boundaries, demonstrating capacity to generate coherent, original content by leveraging massive parallel architectures and extensive datasets. Generative AI not only automates creative work but also enables tasks such as AI-powered search engine overviews, real-time intelligent dialogue, and personalized content creation [39][40][41].\n",
       "\n",
       "### 5.2 Future Trends\n",
       "\n",
       "#### Explainability, Ethics, and Trust\n",
       "\n",
       "As ML and AI models grow in complexity and capability, the need for transparency, interpretability, and fairness intensifies. Ensuring AI systems can be trusted—by mitigating bias, providing robust explanations, and adhering to ethical norms—has become a central research imperative. Regulatory frameworks to govern AI development and deployment are likely to become more prominent [42][43].\n",
       "\n",
       "#### Efficiency and Sustainability\n",
       "\n",
       "A pressing trend is the drive toward greener, more computationally efficient AI. As training large models consumes extensive energy and resources, research focuses on novel architectures, pruning, quantization, and data-efficient learning strategies to minimize environmental impact and democratize access [43][44].\n",
       "\n",
       "#### Agentic and Autonomous AI\n",
       "\n",
       "AI is evolving beyond passive content generation into agentic systems—autonomous agents capable of planning, reasoning, and interacting with their environment. Approaches such as agentic retrieval allow ML systems to manage multi-hop, context-aware queries effectively, pivotal for fields like search technology, robotics, and interactive user interfaces [10][11][45].\n",
       "\n",
       "#### Hybrid, Interdisciplinary, and Context-Driven AI\n",
       "\n",
       "Future AI architectures will increasingly blend deep learning with symbolic reasoning and domain knowledge, aiming for generalization and adaptability. Progress is anticipated through interdisciplinary synthesis, drawing from neuroscience, linguistics, and economics, to achieve more robust, general artificial intelligence [46][47].\n",
       "\n",
       "#### Privacy and Federated Learning\n",
       "\n",
       "To address privacy concerns, federated and privacy-preserving learning methods are being developed. These allow models to learn across decentralized data silos without exposing sensitive information, essential for healthcare, finance, and IoT applications [48].\n",
       "\n",
       "#### Continuous and Lifelong Learning\n",
       "\n",
       "Next-generation AI systems are expected to exhibit lifelong learning—continually updating and refining themselves from new data and environmental feedback, reflecting a more human-like adaptability to changing conditions [49].\n",
       "\n",
       "### 5.3 Conclusion and Implications\n",
       "\n",
       "The historical arc of machine learning, from theoretical roots and early symbolic AI to today’s deep and generative models, illustrates a steady progression toward more autonomous, efficient, and creative systems. Each leap—classical ML to deep learning, deep learning to generative AI—has expanded what machines can do while posing new societal and ethical challenges. The future of the field will hinge on the successful integration of efficiency, interpretability, ethics, and autonomy, setting the stage for AI systems that are not only powerful and ubiquitous but also responsible, equitable, and sustainable. Open questions remain regarding regulatory frameworks, interdisciplinary breakthroughs, and new forms of human-machine collaboration, which will define the next era of machine learning’s evolution.\n",
       "\n",
       "## Data Visualizations\n",
       "\n",
       "### Timeline of Major Developments in Machine Learning and AI\n",
       "\n",
       "| Era                         | Key Developments                                             |\n",
       "|-----------------------------|--------------------------------------------------------------|\n",
       "| 1950s–1960s                 | Early AI programs, Bayesian inference, symbolic reasoning     |\n",
       "| 1970s–1980s                 | Decision trees, single-layer neural networks, backpropagation |\n",
       "| 1990s                       | SVMs, k-NN, ensemble methods, focus on feature engineering    |\n",
       "| 2000s–2010s                 | Deep neural networks, CNNs, RNNs, GPU acceleration           |\n",
       "| 2012                        | AlexNet, deep learning breakthrough in image recognition      |\n",
       "| 2014                        | GANs, start of generative AI                                 |\n",
       "| 2018–Present                | Transformers, LLMs (BERT, GPT), diffusion models, RAG        |\n",
       "\n",
       "### Comparative Table: Classical ML, Deep Learning, and Generative AI\n",
       "\n",
       "| Aspect                  | Classical ML           | Deep Learning                | Generative AI                  |\n",
       "|-------------------------|-----------------------|------------------------------|-------------------------------|\n",
       "| Data Type               | Structured/tabular    | Unstructured (images, text)  | Unstructured, creative        |\n",
       "| Feature Engineering     | Manual                | Automatic                    | Automatic                     |\n",
       "| Interpretability        | High                  | Low                          | Very low                      |\n",
       "| Data Requirements       | Low–Moderate          | High                         | Very high                     |\n",
       "| Computational Cost      | Low                   | High                         | Very high                     |\n",
       "| Typical Applications    | Classification, regression | Vision, NLP, speech    | Content creation, simulation  |\n",
       "| Key Algorithms          | Regression, SVM, trees| CNN, RNN, transformers       | GANs, VAEs, LLMs, diffusion   |\n",
       "| Main Limitation         | Scalability, flexibility| Interpretability, resources | Bias, ethics, cost, control   |\n",
       "\n",
       "## References\n",
       "\n",
       "[1] What is Generative AI? Definition, Examples, And Tools - softsonixofficial, https://www.softsonix.com/artificial-intelligence/what-is-generative-ai-definition-examples-and-tools\n",
       "\n",
       "[2] AI vs ML vs DL vs GenAI: Key Differences Explained - FS.com, https://www.fs.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-vs-generative-ai-key-differences-explained-24134.html\n",
       "\n",
       "[3] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks - IBM, https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
       "\n",
       "[4] Generative AI vs Analytical AI Compared in Detail - bluelight.co, https://bluelight.co/blog/generative-ai-vs-traditional-ai\n",
       "\n",
       "[5] Deep Learning vs. Machine Learning: A Beginner’s Guide, https://www.coursera.org/articles/ai-vs-deep-learning-vs-machine-learning-beginners-guide\n",
       "\n",
       "[6] Modern AI: GenAI vs Machine Learning vs Deep Learning vs LLMs - Cloud4C, https://www.cloud4c.com/blogs/genai-vs-machine-learning-vs-deep-learning-vs-llms\n",
       "\n",
       "[7] Chapter 4 Classical machine learning - Quantum algorithms, https://quantumalgorithms.org/chap-machinelearning.html\n",
       "\n",
       "[8] Classic and Adaptive machines - GeeksforGeeks, https://www.geeksforgeeks.org/classic-and-adaptive-machines/\n",
       "\n",
       "[9] Agentic Retrieval - Azure AI Search | Microsoft Learn, https://learn.microsoft.com/en-us/azure/search/search-agentic-retrieval-concept\n",
       "\n",
       "[10] Up to 40% better relevance for complex queries with new agentic ..., https://techcommunity.microsoft.com/blog/azure-ai-services-blog/up-to-40-better-relevance-for-complex-queries-with-new-agentic-retrieval-engine/4413832\n",
       "\n",
       "[11] Microsoft debuts Agentic Retrieval Preview in Azure AI Search to handle ..., https://windowsreport.com/microsoft-debuts-agentic-retrieval-preview-in-azure-ai-search-to-handle-complex-queries-better/\n",
       "\n",
       "[12] 10 Real-World Examples of Retrieval Augmented Generation, https://www.signitysolutions.com/blog/real-world-examples-of-retrieval-augmented-generation\n",
       "\n",
       "[13] Machine Learning Theory and Applications: Hands-on Use Cases with ..., https://ieeexplore.ieee.org/book/10444091\n",
       "\n",
       "[14] A Guided Tour Through Classical Machine Learning Algorithms, https://learn.mathnai.com/module/ml/guided-tour-classical-ml-algorithms/\n",
       "\n",
       "[15] Top 20 Deep Learning Case Studies [Detailed Analysis] [2025], https://digitaldefynd.com/IQ/deep-learning-case-studies/\n",
       "\n",
       "[16] Top 50 Deep Learning Use Case & Case Studies in 2025 - AIMultiple, https://research.aimultiple.com/deep-learning-applications/\n",
       "\n",
       "[17] Top 10 Deep Learning Applications in 2025 - iQuanta, https://www.iquanta.in/blog/top-10-deep-learning-applications-in-2025/\n",
       "\n",
       "[18] Top 20 Applications of Deep Learning in 2025 Across Industries, https://www.mygreatlearning.com/blog/deep-learning-applications/\n",
       "\n",
       "[19] Top 25 Deep Learning Applications: A Complete List - The Knowledge Academy, https://www.theknowledgeacademy.com/blog/deep-learning-applications/\n",
       "\n",
       "[20] Top 120 Generative AI Applications with Real-Life Examples - AIMultiple, https://research.aimultiple.com/generative-ai-applications/\n",
       "\n",
       "[21] Generative AI Applications: 16 Real-World Examples | RTB House, https://www.rtbhouse.com/blog/16-examples-of-generative-ai-applications\n",
       "\n",
       "[22] Real-world Applications of Generative AI at the Edge, https://www.wevolver.com/article/real-world-applications-of-generative-ai-at-the-edge\n",
       "\n",
       "[23] Top 120 Generative AI Applications with Real-Life Examples - AIMultiple, https://research.aimultiple.com/generative-ai-applications/\n",
       "\n",
       "[24] Top 25 Deep Learning Applications: A Complete List - The Knowledge Academy, https://www.theknowledgeacademy.com/blog/deep-learning-applications/\n",
       "\n",
       "[25] 10 Real-World Examples of Retrieval Augmented Generation, https://www.signitysolutions.com/blog/real-world-examples-of-retrieval-augmented-generation\n",
       "\n",
       "[26] Generative Artificial Intelligence: Current Trends, Issues, and Challenges, https://ieeexplore.ieee.org/document/10893855\n",
       "\n",
       "[27] The Challenges & Opportunities of Deploying Generative AI, https://www.arthur.ai/blog/the-challenges-and-opportunities-of-deploying-generative-ai\n",
       "\n",
       "[28] An executive perspective on top challenges in generative AI deployments, https://www.aiacceleratorinstitute.com/executive-perspective-top-challenges-generative-ai-deployment/\n",
       "\n",
       "[29] 10 Major Challenges of Generative AI & How to Overcome Them, https://www.theiotacademy.co/blog/challenges-of-generative-ai/\n",
       "\n",
       "[30] Timeline of machine learning - Wikipedia, https://en.wikipedia.org/wiki/Timeline_of_machine_learning\n",
       "\n",
       "[31] Machine Learning: History and Terminology | SpringerLink, https://link.springer.com/chapter/10.1007/978-3-031-56431-4_2\n",
       "\n",
       "[32] The Evolution of Machine Learning: A Brief History and Timeline, https://machinelearningmodels.org/the-evolution-of-machine-learning-a-brief-history-and-timeline/\n",
       "\n",
       "[33] The evolution of machine learning: past, present, and future, https://www.sciencedirect.com/science/article/pii/B9780323675383000014\n",
       "\n",
       "[34] Deep learning: Evolution and expansion - ScienceDirect, https://www.sciencedirect.com/science/article/pii/S1389041717303546\n",
       "\n",
       "[35] How Deep Learning Evolved from Traditional Machine Learning, https://www.lmsportals.com/post/how-deep-learning-evolved-from-traditional-machine-learning\n",
       "\n",
       "[36] Deep Learning Evolution: The Complete History of AI Innovation, https://infinitesights.com/deep-learning/\n",
       "\n",
       "[37] The Evolution of AI and ML: Trends, Impact, and Future Insights, https://www.netcomlearning.com/blog/the-future-of-ai-trends-every-c-level-executive-should-know\n",
       "\n",
       "[38] Tracing the evolution of AI in the past decade and forecasting the ..., https://www.sciencedirect.com/science/article/pii/S0957417422013732\n",
       "\n",
       "[39] Unveiling the evolution of generative AI (GAI): a comprehensive and ..., https://jesit.springeropen.com/articles/10.1186/s43067-024-00145-1\n",
       "\n",
       "[40] The Future of Search: When AI Moves from Retrieval to Deep Reasoning, https://www.unite.ai/the-future-of-search-when-ai-moves-from-retrieval-to-deep-reasoning/\n",
       "\n",
       "[41] AI Mode in Google Search: Updates from Google I/O 2025 - The Keyword, https://blog.google/products/search/google-search-ai-mode-update/\n",
       "\n",
       "[42] Five Trends in AI and Data Science for 2025 - MIT Sloan Management Review, https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2025/\n",
       "\n",
       "[43] Title: On the Challenges and Opportunities in Generative AI - arXiv.org, https://arxiv.org/abs/2403.00025\n",
       "\n",
       "[44] Introducing agentic retrieval in Azure AI Search: an automated query ..., https://techcommunity.microsoft.com/blog/azure-ai-services-blog/introducing-agentic-retrieval-in-azure-ai-search/4414677\n",
       "\n",
       "[45] Up to 40% better relevance for complex queries with new agentic ..., https://techcommunity.microsoft.com/blog/azure-ai-services-blog/up-to-40-better-relevance-for-complex-queries-with-new-agentic-retrieval-engine/4413832\n",
       "\n",
       "[46] The Evolution of Machine Learning: A Historical Perspective, https://machinelearninghowto.com/the-evolution-of-machine-learning/\n",
       "\n",
       "[47] [1702.07800] On the Origin of Deep Learning - arXiv.org, https://arxiv.org/abs/1702.07800\n",
       "\n",
       "[48] The Evolution of Machine Learning: A Brief History and Timeline, https://machinelearningmodels.org/the-evolution-of-machine-learning-a-brief-history-and-timeline/\n",
       "\n",
       "[49] Unveiling the evolution of generative AI (GAI): a comprehensive and ..., https://jesit.springeropen.com/articles/10.1186/s43067-024-00145-1\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(final_report.research_report))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ericsson-deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
