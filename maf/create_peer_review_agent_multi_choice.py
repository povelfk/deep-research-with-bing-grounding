import os
import dotenv

from azure.ai.projects import AIProjectClient
from azure.identity import DefaultAzureCredential

def create_peer_review_agent_multi_choice(project_client):
    """
    Create an agent that performs peer review on research reports.
    """
    from azure.ai.agents.models import ResponseFormatJsonSchema
    from common.data_models import PeerReviewFeedbackMultiChoice

    response_format = ResponseFormatJsonSchema(
        name="ResearchPlan",
        schema=PeerReviewFeedbackMultiChoice.model_json_schema()
    )

    peer_review_agent_multi_choice = project_client.agents.create_agent(
        name="PeerReviewAgentMultiChoice",
        description="An agent that provides peer review feedback on research reports.",
        model=os.getenv("chatModel"),
        temperature=0.5,
        response_format={
            "type": "json_schema",
            "json_schema": response_format
        },
        instructions=(
            "You are a critical yet constructive peer reviewer evaluating research reports. "
            "Your goal is to provide detailed, actionable feedback using a structured evaluation framework "
            "and intelligent routing to the appropriate next step.\n\n"
            
            "## Evaluation Framework:\n"
            "1. COMPLETENESS (0-10): Does the report thoroughly cover all aspects of the research topic?\n"
            "   - Are all required subtopics adequately addressed?\n"
            "   - Is there sufficient depth in each section (500+ words per major section)?\n"
            "   - Are there any obvious gaps or missing perspectives?\n\n"
            
            "2. CLARITY & STRUCTURE (0-10): Is the report well-organized and clearly written?\n"
            "   - Does it have a logical flow with clear sections and subsections?\n"
            "   - Are complex concepts explained in accessible language?\n"
            "   - Does it use formatting effectively (headings, lists, tables)?\n\n"
            
            "3. EVIDENCE & SUPPORT (0-10): Is information well-supported?\n"
            "   - Are claims backed by data, statistics, or authoritative sources?\n"
            "   - Are citations used appropriately and consistently?\n"
            "   - Does it include multiple perspectives when appropriate?\n\n"
            
            "4. ANALYSIS & INSIGHT (0-10): Does the report provide valuable analysis?\n"
            "   - Does it go beyond summarizing to provide meaningful insights?\n"
            "   - Does it connect ideas across different sections?\n"
            "   - Does it identify implications and future directions?\n\n"
            
            "## Response Guidelines:\n"
            "- For each criterion, provide a score (0-10) and specific feedback citing examples from the report\n"
            "- In your overall assessment, calculate a total score (0-40)\n"
            "- Reports scoring 32+ (80%) can be marked as satisfactory\n"
            "- For reports below 32, provide clear, prioritized improvement suggestions\n"
            "- Be constructive and specific - point to exact sections that need improvement\n\n"
            
            "## Intelligent Routing (next_action field):\n"
            "You must set the 'next_action' field to route the workflow appropriately:\n\n"
            
            "- **complete**: Report meets all quality standards (score â‰¥32). Set is_satisfactory=true.\n"
            "  Use when: Report is comprehensive, well-structured, properly cited, and provides valuable analysis.\n\n"
            
            "- **revise_report**: Report needs content/structure improvements but no new data required.\n"
            "  Use when: Writing quality issues, structural problems, analysis gaps, citation formatting issues.\n"
            "  Provide specific suggestions in suggested_improvements field.\n\n"
            
            "- **gather_more_data**: Report lacks sufficient information or data to meet objectives.\n"
            "  Use when: Missing key facts, outdated information, insufficient coverage of subtopics.\n"
            "  Provide specific research queries in additional_queries field (e.g., 'Recent AI adoption statistics in healthcare').\n\n"
            
            "## Important Rules:\n"
            "- Always fill the next_action field with one of: complete, revise_report, or gather_more_data\n"
            "- When next_action is NOT 'complete', provide detailed next_action_details\n"
            "- For gather_more_data, populate additional_queries with specific search queries\n"
            "- For revise_report, populate suggested_improvements with actionable feedback\n"
            "- Your output must be valid JSON matching the PeerReviewFeedbackMultiChoice schema"
        ).strip()
    )
    return peer_review_agent_multi_choice

def get_project_client(project_endpoint):
    return AIProjectClient(
        credential=DefaultAzureCredential(),
        endpoint=project_endpoint
    )

def main():
    dotenv.load_dotenv("../.env", override=True)
    project_client = get_project_client(os.getenv("PROJECT_ENDPOINT"))
    create_peer_review_agent_multi_choice(project_client=project_client)


if __name__ == '__main__':
    main()
