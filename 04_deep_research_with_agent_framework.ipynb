{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bdeecf",
   "metadata": {},
   "source": [
    "# **Deep Research with Agent Framework**\n",
    "\n",
    "This notebook demonstrates an agentic research workflow using **Microsoft Agent Framework** to orchestrate a multi-agent system for comprehensive web-based research. Unlike notebooks 01-03, this implementation uses Agent Framework's workflow builder for more sophisticated agent coordination and routing logic.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Workflow Orchestration** - Uses Agent Framework's WorkflowBuilder for declarative agent coordination\n",
    "- **Conditional Routing** - Implements switch-case logic for dynamic workflow paths based on peer review feedback\n",
    "- **Pure Azure AI Agents** - All agents pre-created in Azure AI Foundry (same as notebook 03)\n",
    "- **Automated Quality Control** - Peer review agent routes workflow to completion, revision, or data gathering\n",
    "- **Workflow Visualization** - Generates SVG diagrams of the agent workflow\n",
    "\n",
    "Built with Microsoft Agent Framework, Azure AI Projects, and Azure AI Agents\n",
    "\n",
    "## Required Environment Variables\n",
    "\n",
    "This notebook requires the following environment variables in your `.env` file:\n",
    "\n",
    "```bash\n",
    "# Azure AI Projects Configuration\n",
    "PROJECT_ENDPOINT=your_azure_ai_project_endpoint\n",
    "\n",
    "# Pre-created Agent IDs (must be created via 00_create_agents.py)\n",
    "PlannerAgentID=your_planner_agent_id\n",
    "BingSearchAgentID=your_bing_search_agent_id\n",
    "SummaryAgentID=your_summary_agent_id\n",
    "ResearchAgentID=your_research_agent_id\n",
    "PeerReviewAgentMultiChoiceID=your_peer_review_multi_choice_agent_id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e924cf",
   "metadata": {},
   "source": [
    "## Environment and Dependency Setup\n",
    "\n",
    "Import necessary libraries and configure the environment for Agent Framework execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00abb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4592cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and dependency setup\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True)\n",
    "\n",
    "# Enable nested async event loops (required for Jupyter notebooks)\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Agent Framework imports for workflow orchestration\n",
    "from agent_framework import WorkflowBuilder, Case, Default\n",
    "\n",
    "# Project-specific imports\n",
    "from common.data_models import NextAction\n",
    "from maf.helper import save_report\n",
    "from maf.update_agent_instructions import update_agent_instructions\n",
    "from maf.agents import cleanup_all_agents\n",
    "from maf.nodes import (\n",
    "    planner_executor,\n",
    "    search_executor,\n",
    "    summary_executor,\n",
    "    research_report_executor,\n",
    "    peer_review_executor,\n",
    "    to_routing_decision,\n",
    "    get_next_action,\n",
    "    handle_complete,\n",
    "    handle_routing_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77359d93",
   "metadata": {},
   "source": [
    "### Creating Azure AI Agents (One-time Setup)\n",
    "\n",
    "The following cell will **create all Azure AI Agents** required for this workflow. You only need to run this cell **once** to create the agents, then save their IDs to your `.env` file.\n",
    "\n",
    "After creating the agents, uncomment the fetch agents cell below and comment out this creation cell for subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2795665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from common.create_azure_ai_agents import get_project_client, create_agents\n",
    "# from maf.create_peer_review_agent_multi_choice import create_peer_review_agent_multi_choice\n",
    "\n",
    "# project_client = get_project_client(os.getenv(\"PROJECT_ENDPOINT\"))\n",
    "# create_agents(project_client) # creates all agents except the peer review agent\n",
    "# create_peer_review_agent_multi_choice(project_client) # creates the multi condition peer review agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466f6cf",
   "metadata": {},
   "source": [
    "## Workflow Setup\n",
    "\n",
    "The workflow orchestrates multiple agents in a research pipeline:\n",
    "\n",
    "1. **PlannerExecutor** â†’ Creates research plan with subtopics and queries\n",
    "2. **SearchExecutor** â†’ Executes Bing searches for each query\n",
    "3. **SummaryExecutor** â†’ Summarizes search results\n",
    "4. **ResearchReportExecutor** â†’ Generates comprehensive report\n",
    "5. **PeerReviewExecutor** â†’ Evaluates report quality and decides next action\n",
    "6. **RoutingDecision** â†’ Routes to completion, revision, or more data gathering\n",
    "\n",
    "The peer review agent uses multi-choice output to determine the workflow path:\n",
    "- `COMPLETE` â†’ Workflow finishes, report is saved\n",
    "- `REVISE_REPORT` â†’ Loops back to research report executor\n",
    "- `GATHER_MORE_DATA` â†’ Loops back to search executor for additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae18097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update all agent instructions with current date and refined prompts\n",
    "update_agent_instructions()\n",
    "\n",
    "# Build the workflow with declarative edge definitions\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(planner_executor)\n",
    "    .add_edge(planner_executor, search_executor)\n",
    "    .add_edge(search_executor, summary_executor)\n",
    "    .add_edge(summary_executor, research_report_executor)\n",
    "    .add_edge(research_report_executor, peer_review_executor)\n",
    "    .add_edge(peer_review_executor, to_routing_decision)\n",
    "    .add_switch_case_edge_group(\n",
    "        to_routing_decision,\n",
    "        [\n",
    "            Case(condition=get_next_action(NextAction.COMPLETE), target=handle_complete),\n",
    "            Case(condition=get_next_action(NextAction.REVISE_REPORT), target=research_report_executor),\n",
    "            Case(condition=get_next_action(NextAction.GATHER_MORE_DATA), target=search_executor),\n",
    "            Default(target=handle_routing_error),\n",
    "        ]\n",
    "    )\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83314d31",
   "metadata": {},
   "source": [
    "## Workflow Visualization\n",
    "\n",
    "Generate a visual representation of the agent workflow showing all nodes and routing paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3097b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Generating workflow visualization...\")\n",
    "# viz = WorkflowViz(workflow)\n",
    "\n",
    "# try:\n",
    "#     svg_file = viz.export(format=\"svg\", filename=\"workflow_graph_agent_framework.svg\")\n",
    "#     print(f\"SVG file saved to: {svg_file}\")\n",
    "# except ImportError:\n",
    "#     print(\"Tip: Install 'viz' extra to export workflow visualization: pip install agent-framework[viz] --pre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835451cf",
   "metadata": {},
   "source": [
    "## Research Query\n",
    "\n",
    "Define your research topic or question below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b3011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query=\"What are the differences between classical machine learning, deep learning and generative AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0694e18",
   "metadata": {},
   "source": [
    "## Execute Workflow\n",
    "\n",
    "Run the complete research workflow. The workflow will:\n",
    "1. Plan the research\n",
    "2. Search for information\n",
    "3. Summarize findings\n",
    "4. Generate a report\n",
    "5. Peer review and iterate until quality standards are met\n",
    "6. Save the final report\n",
    "\n",
    "The workflow automatically handles agent cleanup on completion or error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c66879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AgentLoggingMiddleware] ðŸš€ PlannerAgent starting...\n",
      "[AgentLoggingMiddleware] âœ… Agent PlannerAgent completed in 10.96s\n",
      "[SearchExecutor] Initial search execution from planner\n",
      "[SearchExecutor] Stored research plan in shared state (3 tasks, 6 queries)\n",
      "[SearchExecutor] ðŸš€ search query started...\n",
      "[SearchExecutor] ðŸš€ search query started...\n",
      "[SearchExecutor] ðŸš€ search query started...\n",
      "[SearchExecutor] ðŸš€ search query started...\n",
      "[SearchExecutor] ðŸš€ search query started...\n",
      "[SearchExecutor] ðŸš€ search query started...\n",
      "[SearchExecutor] âœ… Agent BingSearchAgent completed in 16.56s\n",
      "[SearchExecutor] âœ… Agent BingSearchAgent completed in 20.11s\n",
      "[SearchExecutor] âœ… Agent BingSearchAgent completed in 29.28s\n",
      "[SearchExecutor] âœ… Agent BingSearchAgent completed in 24.88s\n",
      "[SearchExecutor] âœ… Agent BingSearchAgent completed in 31.13s\n",
      "[SearchExecutor] âœ… Agent BingSearchAgent completed in 32.23s\n",
      "[SearchExecutor] Completed 6 searches\n",
      "[SummaryExecutor] Summarizing 3 subtopics...\n",
      "[AgentLoggingMiddleware] ðŸš€ SummaryAgent starting...\n",
      "[AgentLoggingMiddleware] ðŸš€ SummaryAgent starting...\n",
      "[AgentLoggingMiddleware] ðŸš€ SummaryAgent starting...\n",
      "[AgentLoggingMiddleware] âœ… Agent SummaryAgent completed in 25.83s\n",
      "[AgentLoggingMiddleware] âœ… Agent SummaryAgent completed in 29.19s\n",
      "[AgentLoggingMiddleware] âœ… Agent SummaryAgent completed in 33.43s\n",
      "[SummaryExecutor] Completed 3 summaries\n",
      "[ResearchReportExecutor] Initial report generation\n",
      "[AgentLoggingMiddleware] ðŸš€ ResearchReportAgent starting...\n",
      "[AgentLoggingMiddleware] âœ… Agent ResearchReportAgent completed in 73.64s\n",
      "[ResearchReportExecutor] Stored latest report in shared state\n",
      "[PeerReviewExecutor] Evaluating research report quality...\n",
      "[AgentLoggingMiddleware] ðŸš€ PeerReviewAgentMultiChoice starting...\n",
      "[AgentLoggingMiddleware] âœ… Agent PeerReviewAgentMultiChoice completed in 10.64s\n",
      "[RoutingDecision] Next action: complete\n",
      "[RoutingDecision] Is satisfactory: True\n",
      "[RoutingDecision] Details: The report is exemplary in its completeness, clarity, evidence, and analysis. Minor improvements are...\n",
      "[get_next_action] Checking complete == complete: True\n",
      "[HandleComplete] Report satisfactory - outputting final report\n",
      "\n",
      "[Main] Cleaning up agent clients...\n",
      "[Cleanup] All agent clients closed successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    events = await workflow.run(user_query)\n",
    "    outputs = events.get_outputs()\n",
    "    final_report = outputs[0]   \n",
    "    save_report(final_report)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during workflow execution: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    print(\"\\n[Main] Cleaning up agent clients...\")\n",
    "    await cleanup_all_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826140fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Comparative Analysis of Classical Machine Learning, Deep Learning, and Generative AI: Definitions, Methodologies, and Applications\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Artificial intelligence (AI) has undergone remarkable evolution over the past several decades, transitioning from rule-based expert systems to data-driven approaches that now underpin much of modern technology. Within this broad field, classical machine learning (ML), deep learning (DL), and generative AI (GenAI) represent distinct paradigms, each characterized by unique theoretical foundations, methodological approaches, and application domains. Understanding the nuanced differences and relationships among these paradigms is essential for practitioners, researchers, and decision-makers seeking to leverage AI for complex problem-solving and innovation. This report provides an in-depth, authoritative analysis of classical machine learning, deep learning, and generative AI, focusing on their definitions, methodologies, real-world applications, and distinguishing characteristics. The discussion is structured to offer a comprehensive synthesis, supported by quantitative data, technical detail, and comparative insights, with the aim of clarifying the layered progression of capabilities within artificial intelligence.\n",
       "\n",
       "## Definitions and Core Concepts\n",
       "\n",
       "### Classical Machine Learning\n",
       "\n",
       "Classical machine learning is a subset of artificial intelligence that enables systems to learn from data and improve task performance without explicit programming. Its methodology centers on statistical algorithms, including decision trees, support vector machines (SVMs), linear and logistic regression, and k-nearest neighbors (KNN). A defining feature of classical ML is manual feature engineering, which relies on domain expertise to identify and preprocess relevant data attributes. This process is crucial for extracting meaningful signals from structured datasets, such as tabular data, CSV files, or relational databases. Classical ML operates through three primary paradigms: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves training models on labeled data to map inputs to outputs, while unsupervised learning seeks to uncover patterns or clusters in unlabeled data, often using algorithms like k-means or principal component analysis (PCA). Reinforcement learning, though less commonly associated with classical ML, involves agents interacting with environments and learning optimal policies through reward feedback, exemplified by methods such as Q-learning and policy gradients[1][2][3][4][5].\n",
       "\n",
       "The theoretical backbone of classical ML encompasses concepts such as probably approximately correct (PAC) learning, VC-dimension, bias-variance trade-off, and empirical risk minimization. These principles address the ability of algorithms to generalize from training data and the mathematical limits of learnability. Classical ML excels in domains where data is structured and relationships are relatively linear or simple, with common applications in spam filtering, fraud detection, product recommendation, and predictive analytics. A key advantage is interpretability; classical models are often transparent, allowing stakeholders to understand the rationale behind predictions, which is particularly important in regulated sectors such as finance and healthcare[3][4][5].\n",
       "\n",
       "### Deep Learning\n",
       "\n",
       "Deep learning represents a transformative advance within machine learning, leveraging multi-layered artificial neural networks to perform hierarchical representation learning. Deep networks range from basic multilayer perceptrons to complex architectures such as convolutional neural networks (CNNs) for image data, recurrent neural networks (RNNs) for sequential data, and transformers for natural language processing. These networks are composed of artificial neurons whose connections and activation functions are learned during training, typically using backpropagation. Deep learning eliminates the need for manual feature engineering, enabling the automatic extraction of complex and abstract representations directly from raw, unstructured data such as images, audio waveforms, and text[6][7][8][9][10].\n",
       "\n",
       "The power of deep learning is exemplified by its universal approximation property: given sufficient depth and capacity, neural networks can theoretically approximate any continuous function. This capability underpins their success in domains like image classification, speech recognition, and language understanding. Training deep networks is technically challenging, requiring solutions to issues such as vanishing and exploding gradients, which are addressed through architectural innovations like residual connections and careful initialization. The design of network architectureâ€”including the choice of layers, connectivity, and inductive biasesâ€”directly influences performance and generalization ability. Deep learning models, however, are less interpretable than classical ML models, often functioning as â€œblack boxesâ€ whose decision-making processes are difficult to trace[6][7][8][9][10].\n",
       "\n",
       "### Generative AI\n",
       "\n",
       "Generative AI builds on the foundations of deep learning, focusing on models that can generate new data samples rather than merely making predictions or classifications. GenAI models learn the underlying probability distribution of input data and use this knowledge to synthesize realistic samples. Notable examples include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and large language models (LLMs) such as GPT. GANs consist of a generator network that creates data and a discriminator network that distinguishes real from synthetic data, iteratively improving output quality through adversarial competition. VAEs encode input data into a latent vector space from which new, coherent samples can be generated. Transformers, which utilize attention mechanisms, excel in sequential data modeling and power LLMs like GPT and BERT[6][7][8][9][10].\n",
       "\n",
       "Generative AI is distinguished by its ability to produce wholly new content, revolutionizing fields such as text generation (e.g., ChatGPT), image synthesis (e.g., DALL-E), music composition, and code generation. These models operate on vast, often multi-modal datasets and require extensive pre-training to model intricate data distributions. The interpretability of generative AI is the lowest among the three paradigms; evaluation focuses on output quality and relevance rather than transparent internal logic. GenAIâ€™s capacity to simulate and expand original data distributions fosters applications where novelty and creativity are critical, amplifying AIâ€™s role in creative and commercial domains[6][7][8][9][10].\n",
       "\n",
       "### Hierarchical Relationship and Comparison\n",
       "\n",
       "The fields of AI, ML, DL, and GenAI are hierarchically related: AI is the broadest domain, encompassing all intelligent systems; ML is a subset dedicated to data-driven learning; DL is a further specialization utilizing deep neural networks for complex representational tasks; and GenAI is an advanced extension within DL, focused exclusively on generative content creation. This layered progression reflects increasing abstraction, automation, and capability in handling unstructured, high-dimensional data, alongside evolving trade-offs in interpretability, computational demand, and application scope[1][2][6].\n",
       "\n",
       "#### Hierarchical Breakdown Table\n",
       "\n",
       "| Paradigm        | Core Algorithms/Architectures         | Data Type         | Feature Engineering | Interpretability | Typical Applications           |\n",
       "|-----------------|---------------------------------------|-------------------|---------------------|------------------|-------------------------------|\n",
       "| Classical ML    | Decision Trees, SVM, Regression       | Structured        | Manual              | High             | Fraud detection, analytics     |\n",
       "| Deep Learning   | CNN, RNN, Transformers                | Unstructured      | Automatic           | Low              | Image, speech, NLP             |\n",
       "| Generative AI   | GANs, VAEs, LLMs (GPT, BERT)          | Multi-modal       | Automatic           | Lowest           | Content creation, simulation   |\n",
       "\n",
       "This table summarizes the core distinctions and overlaps among the paradigms, illustrating their relative strengths and limitations in terms of data handling, feature engineering, interpretability, and application domains.\n",
       "\n",
       "## Key Methodological Differences and Technical Approaches\n",
       "\n",
       "### Classical Machine Learning Methodology\n",
       "\n",
       "Classical machine learning is characterized by reliance on traditional algorithms and manual feature engineering. Domain experts play a crucial role in selecting and preprocessing features from structured datasets, ensuring that models are tailored to the specific characteristics of the data. The algorithms employedâ€”such as decision trees, random forests, SVMs, KNN, and linear/logistic regressionâ€”are typically simple to moderately complex and highly interpretable. Users can trace decision-making processes back to specific input features, which is essential for transparency in applications like fraud detection, customer segmentation, and medical diagnostics. Training classical ML models is comparatively fast and requires less computational overhead than deep learning, making them suitable for small to moderate-sized datasets[11][12][13][14][15][16].\n",
       "\n",
       "Classical ML methodologies are divided into supervised learning (classification or regression with labeled data), unsupervised learning (clustering, dimensionality reduction), and reinforcement learning (policy optimization via trial and error and reward maximization). Supervised learning is the most prevalent, with models trained to predict outcomes based on historical data. Unsupervised learning is used to uncover hidden patterns, while reinforcement learning is applied in scenarios where sequential decision-making is required. The interpretability of classical ML models is a significant advantage, particularly in regulated industries where understanding the rationale behind predictions is critical[11][12][13][14][15][16].\n",
       "\n",
       "### Deep Learning Methodology\n",
       "\n",
       "Deep learning evolves from classical ML by deploying artificial neural networks with multiple layersâ€”referred to as â€œdeepâ€ architecturesâ€”to extract features and learn patterns from raw, unstructured data. Technical approaches include convolutional neural networks (CNNs) for images, recurrent neural networks (RNNs) and long short-term memory (LSTM) units for sequential data, and deep feedforward networks. Feature extraction is automatic and hierarchical, enabling the handling of complex datasets such as pixel arrays (images), waveforms (audio), and token sequences (text). Deep learning systems require immense quantities of data and high-performance computation, typically utilizing GPUs or TPUs[11][12][13][14][15][16].\n",
       "\n",
       "DL models are significantly less interpretable than classical ML models; while they offer state-of-the-art performance in tasks like object recognition, speech-to-text, natural language understanding, and autonomous control, it is difficult to ascertain precisely what drives their decisions. This opacity has led to the characterization of deep learning models as â€œblack boxes.â€ Hyperparameter tuningâ€”including the number of layers, nodes per layer, learning rates, and optimizer choicesâ€”is critical for DL model success, and empirical experimentation is a common practice in model development[11][12][13][14][15][16].\n",
       "\n",
       "### Generative AI Methodology\n",
       "\n",
       "Generative AI represents the latest wave in deep learning advancements, distinguished by its focus on producing novel, realistic outputs that mimic the distribution of the training data. Architectures such as GANs, VAEs, and especially Transformers power generative models. GANs operate with a generator network that creates data and a discriminator network that distinguishes real from synthetic data, iteratively improving output quality via adversarial competition. VAEs encode input data to a latent vector space from which new, coherent samples are generated. Transformers, utilizing attention mechanisms, excel in sequential data modeling, as seen in large language models (LLMs) like GPT and BERT[11][12][13][14][15][16].\n",
       "\n",
       "These systems operate on enormous, often multi-modal datasets (images, text, audio, video) and require extensive pre-training to model intricate data distributions. Unlike classical ML and conventional DL, generative AIâ€™s outputs are new content rather than mere predictions or classifications, enabling applications in text synthesis (e.g., ChatGPT), image creation (DALL-E), code generation, and drug discovery. The interpretability of generative AI is the lowest among the three paradigms; evaluation is focused on output quality and relevance rather than clear internal logic[11][12][13][14][15][16].\n",
       "\n",
       "### Comparative Methodological Table\n",
       "\n",
       "| Aspect              | Classical ML                  | Deep Learning                  | Generative AI                   |\n",
       "|---------------------|------------------------------|-------------------------------|---------------------------------|\n",
       "| Feature Engineering | Manual                       | Automatic                     | Automatic                       |\n",
       "| Data Requirements   | Small/Moderate, Structured   | Large, Unstructured           | Very Large, Multi-modal         |\n",
       "| Interpretability    | High                         | Low                           | Lowest                          |\n",
       "| Computational Cost  | Low                          | High                          | Very High                       |\n",
       "| Output Type         | Prediction/Classification    | Prediction/Classification     | New Data/Content Generation     |\n",
       "\n",
       "This table highlights the methodological distinctions, emphasizing the trade-offs between transparency, data requirements, computational cost, and creative capabilities.\n",
       "\n",
       "## Real-world Applications and Use Cases\n",
       "\n",
       "### Classical Machine Learning Applications\n",
       "\n",
       "Classical machine learning algorithms are most effective for structured data management and analytical tasks requiring clarity in decision logic. In healthcare, classical ML models predict disease risk and assess patient outcomes based on electronic health records or structured laboratory data. In finance, they underpin credit scoring and fraud detection workflows, especially since regulators and institutions demand interpretability in risk decisions. Agriculture benefits from classical ML through crop yield forecasting using structured datasets on soil and weather, while manufacturing operations are enhanced via predictive maintenance and quality control by analyzing equipment logs and sensor data. Transportation industries utilize classical ML for tasks such as traffic prediction and route optimization. These approaches are computationally efficient and favored where data is limited and manual feature engineering can surface important signals, though they struggle to scale with high-dimensional, unstructured inputs such as images and audio[17][18][19][20][21][22][23].\n",
       "\n",
       "### Deep Learning Applications\n",
       "\n",
       "Deep learning applies neural network architectures capable of learning hierarchical feature representations, allowing direct processing of complex, unstructured, high-volume datasets. Convolutional neural networks (CNNs) are extensively deployed in image and video analysis; self-driving vehicles use DL for real-time object detection and decision-making, while healthcare systems leverage DL for medical image interpretation, such as cancer detection from X-rays or MRIs. In natural language processing, deep learning models enable virtual assistants (such as Siri and Alexa), automated translation, and sentiment analysis engines. Recurrent networks model time-series data for tasks such as speech recognition and voice-controlled systems. Recommendation platforms (e.g., Netflix, Amazon, Spotify) exploit DL for personalized content delivery, learning user preferences from vast behavioral data. Cybersecurity applications rely on DL's anomaly detection capabilities to spot digital threats in high-dimensional, dynamic environments. However, DL demands significant computational resources and large annotated datasets, often creating interpretability challenges relative to classical ML[17][18][19][20][21][22][23].\n",
       "\n",
       "### Generative AI Applications\n",
       "\n",
       "Generative AI represents the next frontier, involving architectures such as GANs and large language models (LLMs) like GPT-4. These systems are distinct in their capacity not only to analyze but also to generate new data. Content creation is a dominant real-world use case, with tools like DALL-E synthesizing novel images, GPT creating automated written narratives (reports, articles, ad-copy), and specialized models composing music or generating digital artwork. In pharmaceuticals, generative models are leveraged to design new molecular structures, accelerating drug discovery by simulating chemical properties before lab synthesisâ€”a process that also extends to designing new materials in manufacturing. Generative AI powers personalized marketing, tailoring advertisements and campaign materials based on user data. Education benefits from automated generation of custom curricula and interactive content. Gaming and simulation industries use generative AI to create realistic virtual environments, characters, and storylines, increasing immersion and content scalability. Nonetheless, generative AI introduces concerns regarding authenticity of generated outputs, potential bias from training data, and high computational demandsâ€”problems even more pronounced than those encountered with DL[17][18][19][20][21][22][23].\n",
       "\n",
       "### Hybrid and Integrated Deployments\n",
       "\n",
       "Real-world deployments increasingly integrate these approaches, leveraging the strengths of each to solve multifaceted problems. Hybrid systems combine classical ML, DL, and generative AI to maximize value across sectors. For example, in healthcare, classical ML is used for analyzing tabular patient data, DL revolutionizes imaging diagnostics, and generative AI is now being piloted for drug and protein structure prediction. In finance, ML provides structured risk and fraud analysis, DL delivers automated market sentiment analysis, and generative AI supports scenario simulation and stress-testing through synthetic data. Manufacturing integrates classical ML for predictive maintenance, DL for defect detection in images, and generative AI for material design and process simulation[17][18][19][20][21][22][23].\n",
       "\n",
       "### Impact Assessment Matrix\n",
       "\n",
       "| Industry        | Classical ML Use Case           | Deep Learning Use Case         | Generative AI Use Case          |\n",
       "|-----------------|-------------------------------|-------------------------------|---------------------------------|\n",
       "| Healthcare      | Risk prediction, EHR analysis | Medical imaging diagnostics    | Drug design, protein synthesis  |\n",
       "| Finance         | Credit scoring, fraud detection| Market sentiment analysis      | Synthetic data, scenario simulation |\n",
       "| Manufacturing   | Predictive maintenance         | Defect detection (images)      | Material/process simulation     |\n",
       "| Agriculture     | Crop yield forecasting         | Satellite image analysis       | Synthetic weather data          |\n",
       "| Creative Arts   | Recommendation systems         | Automated tagging              | Artwork, music, text generation |\n",
       "\n",
       "This matrix illustrates the differentiated and complementary roles of each paradigm across key industries.\n",
       "\n",
       "## Timeline of Major Developments\n",
       "\n",
       "To contextualize the evolution of these paradigms, a brief timeline highlights major milestones:\n",
       "\n",
       "| Year | Milestone                                    | Paradigm         |\n",
       "|------|----------------------------------------------|------------------|\n",
       "| 1957 | Perceptron algorithm                         | Classical ML     |\n",
       "| 1986 | Backpropagation for neural networks          | Deep Learning    |\n",
       "| 1998 | LeNet (CNN for digit recognition)            | Deep Learning    |\n",
       "| 2006 | Deep belief networks                         | Deep Learning    |\n",
       "| 2014 | GANs introduced                              | Generative AI    |\n",
       "| 2017 | Transformer architecture                     | Deep Learning/GenAI |\n",
       "| 2020 | GPT-3 released                               | Generative AI    |\n",
       "| 2022 | DALL-E and Stable Diffusion                  | Generative AI    |\n",
       "\n",
       "This timeline demonstrates the rapid acceleration of innovation, particularly in deep learning and generative AI, over the past decade.\n",
       "\n",
       "## Statistical Charts: Adoption and Performance Metrics\n",
       "\n",
       "While precise adoption rates vary by industry and geography, recent surveys and market analyses indicate:\n",
       "\n",
       "- **Classical ML** remains the most widely deployed paradigm in regulated industries (finance, healthcare) due to its interpretability and efficiency.\n",
       "- **Deep Learning** dominates in sectors requiring high accuracy and processing of unstructured data, such as technology, automotive, and entertainment.\n",
       "- **Generative AI** is experiencing exponential growth in creative industries, pharmaceuticals, and marketing, with Gartner projecting that by 2025, over 30% of new drugs and materials will be discovered using generative AI techniques.\n",
       "\n",
       "Performance metrics further reinforce these trends:\n",
       "\n",
       "- Image classification accuracy has improved from ~80% (classical ML) to >98% (deep learning) on benchmark datasets.\n",
       "- Text generation quality, as measured by human evaluation, has reached near-human levels in certain domains with LLMs.\n",
       "- Generative AI models can produce millions of unique images or text samples per day, far surpassing manual content creation rates.\n",
       "\n",
       "## Synthesis and Integrated Analysis\n",
       "\n",
       "The evolution from classical machine learning to deep learning and generative AI marks a profound shift in the capabilities, methodologies, and application domains of artificial intelligence. Classical ML stands for simplicity, transparency, and human-guided feature design on modest, structured datasets. It remains indispensable in domains where interpretability and efficiency are paramount. Deep learning brings powerful, automated representation learning to vast, unstructured domains, achieving state-of-the-art performance in image, speech, and language tasks, albeit at the cost of interpretability and requiring substantial computational resources. Generative AI opens creative and simulation frontiers, producing high-fidelity new content by mastering data distribution, with applications ranging from automated writing and image synthesis to drug discovery and personalized marketing.\n",
       "\n",
       "The methodological differences among these paradigms inform engineering practices, model deployment strategies, and ethical considerations in contemporary AI. Practitioners must evaluate trade-offs between transparency, data requirements, computational cost, model complexity, and creative capabilities when selecting the appropriate approach for real-world problems. Increasingly, hybrid systems harness strengths across the spectrumâ€”interpretability, scalability, creativityâ€”while mitigating single-model limitations. The convergence of these technologies is driving a new wave of cross-industry innovation, with use cases rapidly evolving as computational and methodological advances open new possibilities.\n",
       "\n",
       "Open questions remain regarding responsible adoption, explainability, and the ethical implications of generative models, framing the next phase of inquiry at the intersection of technical prowess and societal trust. As AI continues to advance, the judicious selection and integration of classical ML, deep learning, and generative AI will be critical for addressing data characteristics, operational requirements, and sector-specific challenges.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, classical machine learning, deep learning, and generative AI represent a layered progression of capabilities within artificial intelligence, each with distinct definitions, methodologies, and application domains. Classical ML offers interpretability and efficiency for structured data tasks, deep learning excels in unstructured, high-dimensional domains through automatic representation learning, and generative AI revolutionizes content creation and simulation by mastering data distribution. The integration of these paradigms is shaping the future of AI, driving innovation across industries and raising important questions about transparency, ethics, and societal impact. Continued research and thoughtful deployment will be essential to harness the full potential of these transformative technologies.\n",
       "\n",
       "## References\n",
       "\n",
       "[1] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks, https://www.geeksforgeeks.org/machine-learning/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks/\n",
       "[2] AI, Machine Learning & Deep Learning: A Concept Hierarchy, https://circuitlabs.net/ai-machine-learning-deep-learning-a-concept-hierarchy/\n",
       "[3] Core Concepts of Machine Learning (classical) | GRAUSOFT, https://grausoft.net/core-concepts-of-machine-learning/\n",
       "[4] Machine learning - Wikipedia, https://en.wikipedia.org/wiki/Machine_learning\n",
       "[5] Fundamentals of Machine Learning and Artificial Intelligence, https://www.coursera.org/learn/fundamentals-of-machine-learning-and-artificial-intelligence\n",
       "[6] AI vs ML vs DL vs GenAI: Key Differences Explained - FS.com, https://www.fs.com/blog/artificial-intelligence-vs-machine-learning-vs-deep-learning-vs-generative-ai-key-differences-explained-24134.html\n",
       "[7] Deep Learning: Foundations and Concepts | SpringerLink, https://link.springer.com/book/10.1007/978-3-031-45468-4\n",
       "[8] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks | IBM, https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
       "[9] [2106.10165] The Principles of Deep Learning Theory - arXiv.org, https://arxiv.org/abs/2106.10165\n",
       "[10] Understanding Machine Learning Principles: Learning, Inference ..., https://www.mdpi.com/2227-7390/13/3/451\n",
       "[11] Machine Learning and Deep Learning: A Comparative Review, https://link.springer.com/chapter/10.1007/978-981-33-6307-6_15\n",
       "[12] AI vs ML vs DL: A practical guide with real-world engineering examples, https://allthingsopen.org/articles/ai-vs-ml-vs-dl-practical-guide-real-examples\n",
       "[13] Machine Learning vs Deep Learning vs Generative AI - What are the ..., https://www.freecodecamp.org/news/machine-learning-vs-deep-learning-vs-generative-ai/\n",
       "[14] AI vs. Machine Learning vs. Deep Learning vs. Neural Networks | IBM, https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
       "[15] Comparison Analysis of Traditional Machine Learning and Deep Learning ..., https://arxiv.org/abs/2204.05983\n",
       "[16] Difference Between Machine Learning and Deep Learning, https://www.geeksforgeeks.org/artificial-intelligence/difference-between-machine-learning-and-deep-learning/\n",
       "[17] Machine Learning Theory and Applications: Hands-on Use Cases with ..., https://ieeexplore.ieee.org/book/10444091\n",
       "[18] Innovations in Machine and Deep Learning: Case Studies and Applications ..., https://link.springer.com/book/10.1007/978-3-031-40688-1\n",
       "[19] Machine Learning and Deep Learning Applications-A Vision, https://www.sciencedirect.com/science/article/pii/S2666285X21000042\n",
       "[20] Machine Learning and Deep Learning Paradigms: From Techniques to ..., https://www.mdpi.com/2073-431X/14/3/93\n",
       "[21] Deep Learning Examples: Practical Applications in Real Life, https://www.geeksforgeeks.org/deep-learning/deep-learning-examples/\n",
       "[22] Comparing Deep Learning and Traditional Machine Learning, https://theceoviews.com/comparing-deep-learning-and-traditional-machine-learning/\n",
       "[23] Machine Learning: Algorithms, Real-World Applications and Research ..., https://link.springer.com/article/10.1007/s42979-021-00592-x\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(final_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab01428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
